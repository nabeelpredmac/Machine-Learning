{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset locations\n",
    "\n",
    "#http://grail.cs.washington.edu/projects/deepexpr/FERG_DB_256.zip   - FERG-DB animated image dataset\n",
    "#http://download.visgraf.impa.br/roopesh.p@predmac.com_20190709_0823.zip  - FacesDB dataset of human\n",
    "#https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data  - FER2013 dataset from kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.applications import VGG16\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainset and Testset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-neutral, 1-happy, 2-sad, 3-surprise, 4-angry, 5-disguest, 6-fear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data2/facedb/s001/tif/s001-00_img.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data2/facedb/s001/tif/s001-00_img_aug0.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data2/facedb/s001/tif/s001-00_img_aug1.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data2/facedb/s001/tif/s001-00_img_aug2.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data2/facedb/s001/tif/s001-00_img_aug3.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       location  labels\n",
       "0       ./data2/facedb/s001/tif/s001-00_img.tif       0\n",
       "1  ./data2/facedb/s001/tif/s001-00_img_aug0.tif       0\n",
       "2  ./data2/facedb/s001/tif/s001-00_img_aug1.tif       0\n",
       "3  ./data2/facedb/s001/tif/s001-00_img_aug2.tif       0\n",
       "4  ./data2/facedb/s001/tif/s001-00_img_aug3.tif       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1,39):\n",
    "    human_reaction = glob.glob(\"./data2/facedb/s0\"+str(i).zfill(2)+\"/tif/*\")\n",
    "    tmp = pd.DataFrame({'location':human_reaction,\n",
    "                        'labels':[int(human_reaction[i].split('/')[-1].split('-')[1][0:2]) for i in range(len(human_reaction))]},\n",
    "                       index =range(len(human_reaction)) )\n",
    "    full_df = full_df.append(tmp)\n",
    "    \n",
    "full_df['labels'] = full_df.labels.astype('int')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>./data2/facedb/s038/tif/s038-06_img_aug8.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>./data2/facedb/s038/tif/s038-06_img_aug9.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>./data2/facedb/s038/tif/s038-01_img_aug4.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>./data2/facedb/s038/tif/s038-03_img.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>./data2/facedb/s038/tif/s038-04_img_aug4.tif</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        location  labels\n",
       "72  ./data2/facedb/s038/tif/s038-06_img_aug8.tif       6\n",
       "73  ./data2/facedb/s038/tif/s038-06_img_aug9.tif       6\n",
       "74  ./data2/facedb/s038/tif/s038-01_img_aug4.tif       1\n",
       "75       ./data2/facedb/s038/tif/s038-03_img.tif       3\n",
       "76  ./data2/facedb/s038/tif/s038-04_img_aug4.tif       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2772, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./data2/facedb/s023/tif/s023-01_img_aug9.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>./data2/facedb/s027/tif/s027-03_img_aug8.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>./data2/facedb/s017/tif/s017-06_img_aug7.tif</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>./data2/facedb/s029/tif/s029-05_img.tif</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data2/facedb/s016/tif/s016-00_img_aug0.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        location  labels\n",
       "20  ./data2/facedb/s023/tif/s023-01_img_aug9.tif       1\n",
       "40  ./data2/facedb/s027/tif/s027-03_img_aug8.tif       3\n",
       "71  ./data2/facedb/s017/tif/s017-06_img_aug7.tif       6\n",
       "52       ./data2/facedb/s029/tif/s029-05_img.tif       5\n",
       "1   ./data2/facedb/s016/tif/s016-00_img_aug0.tif       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = full_df.sample(len(full_df))\n",
    "full_df.shape\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emotion_label(x):\n",
    "    if x=='NE':\n",
    "        return 0\n",
    "    if x=='HA':\n",
    "        return 1\n",
    "    if x=='SA':\n",
    "        return 2\n",
    "    if x=='SU':\n",
    "        return 3\n",
    "    if x=='AN':\n",
    "        return 4\n",
    "    if x=='DI':\n",
    "        return 5\n",
    "    if x=='FE':\n",
    "        return 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data2/japanese_women/KA.AN1.39.tiff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data2/japanese_women/KA.AN1.39_aug0.tiff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data2/japanese_women/KA.AN1.39_aug1.tiff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data2/japanese_women/KA.AN1.39_aug2.tiff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data2/japanese_women/KA.AN1.39_aug3.tiff</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     location  labels\n",
       "0       ./data2/japanese_women/KA.AN1.39.tiff       4\n",
       "1  ./data2/japanese_women/KA.AN1.39_aug0.tiff       4\n",
       "2  ./data2/japanese_women/KA.AN1.39_aug1.tiff       4\n",
       "3  ./data2/japanese_women/KA.AN1.39_aug2.tiff       4\n",
       "4  ./data2/japanese_women/KA.AN1.39_aug3.tiff       4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df2 = pd.DataFrame()\n",
    "\n",
    "#for i in range(1,39):\n",
    "human_reaction = glob.glob(\"./data2/japanese_women/*\")\n",
    "tmp = pd.DataFrame({'location':human_reaction,\n",
    "                    'labels':[emotion_label(human_reaction[i].split('/')[-1].split('.')[1][0:2]) for i in range(len(human_reaction))]},\n",
    "                   index =range(len(human_reaction)) )\n",
    "full_df2 = full_df2.append(tmp)\n",
    "#full_df2 = full_df2.dropna()    \n",
    "full_df2['labels'] = full_df2.labels.astype('int')\n",
    "full_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>./data2/japanese_women/KM.NE2.2_aug5.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>./data2/japanese_women/KM.NE2.2_aug6.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>./data2/japanese_women/KM.NE2.2_aug7.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>./data2/japanese_women/KM.NE2.2_aug8.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>./data2/japanese_women/KM.NE2.2_aug9.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       location  labels\n",
       "2338  ./data2/japanese_women/KM.NE2.2_aug5.tiff       0\n",
       "2339  ./data2/japanese_women/KM.NE2.2_aug6.tiff       0\n",
       "2340  ./data2/japanese_women/KM.NE2.2_aug7.tiff       0\n",
       "2341  ./data2/japanese_women/KM.NE2.2_aug8.tiff       0\n",
       "2342  ./data2/japanese_women/KM.NE2.2_aug9.tiff       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SU'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_reaction[20].split('/')[-1].split('.')[1][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2343, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label2(x):\n",
    "    if x=='neutral':\n",
    "        return 0\n",
    "    if x=='happy':\n",
    "        return 1\n",
    "    if x=='sadness':\n",
    "        return 2\n",
    "    if x=='surprise':\n",
    "        return 3\n",
    "    if x=='anger':\n",
    "        return 4\n",
    "    if x=='disgust':\n",
    "        return 5\n",
    "    if x=='fear':\n",
    "        return 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data2/CK+_modified/anger/S010_004_00000017.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data2/CK+_modified/anger/S010_004_00000017_a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data2/CK+_modified/anger/S010_004_00000017_a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data2/CK+_modified/anger/S010_004_00000017_a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data2/CK+_modified/anger/S010_004_00000017_a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location  labels\n",
       "0   ./data2/CK+_modified/anger/S010_004_00000017.png       4\n",
       "1  ./data2/CK+_modified/anger/S010_004_00000017_a...       4\n",
       "2  ./data2/CK+_modified/anger/S010_004_00000017_a...       4\n",
       "3  ./data2/CK+_modified/anger/S010_004_00000017_a...       4\n",
       "4  ./data2/CK+_modified/anger/S010_004_00000017_a...       4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df3 = pd.DataFrame()\n",
    "\n",
    "#for i in range(1,39):\n",
    "human_reaction = glob.glob(\"./data2/CK+_modified/*/*\")\n",
    "tmp = pd.DataFrame({'location':human_reaction,\n",
    "                    'labels':[emotion_label2(human_reaction[i].split('/')[-2]) for i in range(len(human_reaction))]},\n",
    "                   index =range(len(human_reaction)) )\n",
    "full_df3 = full_df3.append(tmp)\n",
    "full_df3 = full_df3.dropna()    \n",
    "full_df3['labels'] = full_df3.labels.astype('int')\n",
    "full_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13838, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data2/search_faces/anger/human_angry_faces_2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data2/search_faces/anger/human_angry_faces_3...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data2/search_faces/anger/human_angry_faces_1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data2/search_faces/anger/human_angry_faces_1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data2/search_faces/anger/human_angry_faces_1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location  labels\n",
       "0  ./data2/search_faces/anger/human_angry_faces_2...       4\n",
       "1  ./data2/search_faces/anger/human_angry_faces_3...       4\n",
       "2  ./data2/search_faces/anger/human_angry_faces_1...       4\n",
       "3  ./data2/search_faces/anger/human_angry_faces_1...       4\n",
       "4  ./data2/search_faces/anger/human_angry_faces_1...       4"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df4 = pd.DataFrame()\n",
    "\n",
    "#for i in range(1,39):\n",
    "human_reaction = glob.glob(\"./data2/search_faces/*/*\")\n",
    "tmp = pd.DataFrame({'location':human_reaction,\n",
    "                    'labels':[emotion_label2(human_reaction[i].split('/')[-2]) for i in range(len(human_reaction))]},\n",
    "                   index =range(len(human_reaction)) )\n",
    "full_df4 = full_df4.append(tmp)\n",
    "full_df4 = full_df4.dropna()    \n",
    "full_df4['labels'] = full_df4.labels.astype('int')\n",
    "full_df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>./data2/search_faces/surprise/human_surprise_f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>./data2/search_faces/surprise/human_surprise_f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>./data2/search_faces/surprise/human_surprise_f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>./data2/search_faces/surprise/human_surprise_f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>./data2/search_faces/surprise/human_surprise_f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              location  labels\n",
       "243  ./data2/search_faces/surprise/human_surprise_f...       3\n",
       "244  ./data2/search_faces/surprise/human_surprise_f...       3\n",
       "245  ./data2/search_faces/surprise/human_surprise_f...       3\n",
       "246  ./data2/search_faces/surprise/human_surprise_f...       3\n",
       "247  ./data2/search_faces/surprise/human_surprise_f...       3"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 1, 0, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df3.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.labels.nunique(), full_df2.labels.nunique(), full_df3.labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df = full_df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    352\n",
       "1    341\n",
       "2    341\n",
       "3    330\n",
       "4    330\n",
       "0    330\n",
       "5    319\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df2.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2816\n",
       "0    2739\n",
       "1    2398\n",
       "5    2167\n",
       "4    1617\n",
       "2    1221\n",
       "6     880\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df3.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    75\n",
       "4    60\n",
       "3    38\n",
       "2    38\n",
       "0    38\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df4.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    352\n",
       "1    341\n",
       "2    341\n",
       "3    330\n",
       "4    330\n",
       "0    330\n",
       "5    319\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df2.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3542\n",
       "0    3465\n",
       "1    3135\n",
       "5    2882\n",
       "4    2343\n",
       "2    1958\n",
       "6    1628\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = full_df.append(full_df2)\n",
    "full_df = full_df.append(full_df3)\n",
    "full_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = full_df[full_df.labels==0].iloc[0:1958,]\n",
    "tmp2 = full_df[full_df.labels==1].iloc[0:1958,]\n",
    "tmp3 = full_df[full_df.labels==2].iloc[0:1958,]\n",
    "tmp4 = full_df[full_df.labels==3].iloc[0:1958,]\n",
    "tmp5 = full_df[full_df.labels==4].iloc[0:1958,]\n",
    "full_df = pd.DataFrame()\n",
    "full_df = full_df.append(tmp1)\n",
    "full_df = full_df.append(tmp2)\n",
    "full_df = full_df.append(tmp3)\n",
    "full_df = full_df.append(tmp4)\n",
    "full_df = full_df.append(tmp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.sample(len(full_df))\n",
    "split = int(len(full_df)*.8)\n",
    "train_df = full_df.iloc[0:split,]\n",
    "test_df  = full_df.iloc[split:len(full_df),] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7832, 2), (1958, 2))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convt_to_gray(df):\n",
    "    count = 0\n",
    "    for i in range(len(df)):\n",
    "        #print(i)\n",
    "        path1 = df[\"location\"].iloc[i]\n",
    "        img = cv2.imread(path1)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(path1, gray)\n",
    "        count += 1\n",
    "    print(\"Total number of images converted and saved = \"+str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convt_to_gray_by_path(img_path):\n",
    "    #for i in range(len(df)):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(img_path, gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convt_to_gray_by_path('./data2/CK+_modified/anger/S010_004_00000019.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convt_to_gray(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convt_to_gray(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images converted and saved = 247\n"
     ]
    }
   ],
   "source": [
    "convt_to_gray(full_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data2/search_faces/happy/human_happy_faces_6.jpg'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df4.loc[109,'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow('a',img)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Detecting face in image using HAAR then crop it then resize then save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect the face in image using HAAR cascade then crop it then resize it and finally save it.\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "#download this xml file from link: https://github.com/opencv/opencv/tree/master/data/haarcascades.\n",
    "def face_det_crop_resize(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        face_clip = img[y:y+h, x:x+w]  #cropping the face in image\n",
    "        cv2.imwrite(img_path, cv2.resize(face_clip, (350, 350)))  #resizing image then saving it\n",
    "    if(len(faces)==0):\n",
    "        cv2.imwrite(img_path, cv2.resize(img, (350, 350)))  #resizing image then saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_det_crop_resize('./data2/CK+_modified/anger/S010_004_00000017.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(train_df))):\n",
    "#     img_path = train_df.location.iloc[i]\n",
    "#     face_det_crop_resize(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(test_df))):\n",
    "#     img_path = test_df.location.iloc[i]\n",
    "#     face_det_crop_resize(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(full_df4))):\n",
    "#     img_path = full_df4.location.iloc[i]\n",
    "#     face_det_crop_resize(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck features for Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu1/anaconda3/envs/fer_env/lib/python3.7/site-packages/ipykernel/__main__.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7832, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainCombined_Labels = pd.get_dummies(train_df[\"labels\"]).as_matrix()\n",
    "TrainCombined_Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainCombined_batch_pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCombinedTrainBatch(batch_size):\n",
    "    global TrainCombined_batch_pointer\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    for i in range(batch_size):\n",
    "        path1 = train_df.iloc[TrainCombined_batch_pointer + i][\"location\"]\n",
    "        read_image = cv2.imread(path1)\n",
    "        read_image_final = read_image/255.0  #here, we are normalizing the images\n",
    "        batch_images.append(read_image_final)\n",
    "        \n",
    "        batch_labels.append(TrainCombined_Labels[TrainCombined_batch_pointer + i]) #appending corresponding labels\n",
    "        \n",
    "    TrainCombined_batch_pointer += batch_size\n",
    "        \n",
    "    return np.array(batch_images), np.array(batch_labels),read_image_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainCombined_batch_pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 10\n",
    "# x, y,read_image_final = loadCombinedTrainBatch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loaded\n",
      "Creating bottleneck features for batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/782 [00:01<18:22,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 1 created and saved\n",
      "\n",
      "Batch 2 loaded\n",
      "Creating bottleneck features for batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/782 [00:02<18:34,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 2 created and saved\n",
      "\n",
      "Batch 3 loaded\n",
      "Creating bottleneck features for batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/782 [00:04<18:41,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 3 created and saved\n",
      "\n",
      "Batch 4 loaded\n",
      "Creating bottleneck features for batch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/782 [00:05<18:43,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 4 created and saved\n",
      "\n",
      "Batch 5 loaded\n",
      "Creating bottleneck features for batch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 5/782 [00:07<18:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 5 created and saved\n",
      "\n",
      "Batch 6 loaded\n",
      "Creating bottleneck features for batch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/782 [00:08<19:32,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 6 created and saved\n",
      "\n",
      "Batch 7 loaded\n",
      "Creating bottleneck features for batch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/782 [00:10<20:44,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 7 created and saved\n",
      "\n",
      "Batch 8 loaded\n",
      "Creating bottleneck features for batch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 8/782 [00:12<21:26,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 8 created and saved\n",
      "\n",
      "Batch 9 loaded\n",
      "Creating bottleneck features for batch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/782 [00:14<21:47,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 9 created and saved\n",
      "\n",
      "Batch 10 loaded\n",
      "Creating bottleneck features for batch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 10/782 [00:16<22:08,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 10 created and saved\n",
      "\n",
      "Batch 11 loaded\n",
      "Creating bottleneck features for batch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 11/782 [00:17<22:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 11 created and saved\n",
      "\n",
      "Batch 12 loaded\n",
      "Creating bottleneck features for batch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 12/782 [00:19<22:18,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 12 created and saved\n",
      "\n",
      "Batch 13 loaded\n",
      "Creating bottleneck features for batch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 13/782 [00:21<22:26,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 13 created and saved\n",
      "\n",
      "Batch 14 loaded\n",
      "Creating bottleneck features for batch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 14/782 [00:23<23:05,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 14 created and saved\n",
      "\n",
      "Batch 15 loaded\n",
      "Creating bottleneck features for batch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 15/782 [00:25<23:26,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 15 created and saved\n",
      "\n",
      "Batch 16 loaded\n",
      "Creating bottleneck features for batch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 16/782 [00:26<23:18,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 16 created and saved\n",
      "\n",
      "Batch 17 loaded\n",
      "Creating bottleneck features for batch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 17/782 [00:28<23:09,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 17 created and saved\n",
      "\n",
      "Batch 18 loaded\n",
      "Creating bottleneck features for batch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 18/782 [00:30<22:54,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 18 created and saved\n",
      "\n",
      "Batch 19 loaded\n",
      "Creating bottleneck features for batch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 19/782 [00:32<22:56,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 19 created and saved\n",
      "\n",
      "Batch 20 loaded\n",
      "Creating bottleneck features for batch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 20/782 [00:34<23:04,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 20 created and saved\n",
      "\n",
      "Batch 21 loaded\n",
      "Creating bottleneck features for batch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 21/782 [00:35<22:46,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 21 created and saved\n",
      "\n",
      "Batch 22 loaded\n",
      "Creating bottleneck features for batch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 22/782 [00:37<22:37,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 22 created and saved\n",
      "\n",
      "Batch 23 loaded\n",
      "Creating bottleneck features for batch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 23/782 [00:39<22:20,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 23 created and saved\n",
      "\n",
      "Batch 24 loaded\n",
      "Creating bottleneck features for batch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 24/782 [00:41<22:16,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 24 created and saved\n",
      "\n",
      "Batch 25 loaded\n",
      "Creating bottleneck features for batch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 25/782 [00:42<22:13,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 25 created and saved\n",
      "\n",
      "Batch 26 loaded\n",
      "Creating bottleneck features for batch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 26/782 [00:44<22:17,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 26 created and saved\n",
      "\n",
      "Batch 27 loaded\n",
      "Creating bottleneck features for batch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 27/782 [00:46<22:27,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 27 created and saved\n",
      "\n",
      "Batch 28 loaded\n",
      "Creating bottleneck features for batch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 28/782 [00:48<22:51,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 28 created and saved\n",
      "\n",
      "Batch 29 loaded\n",
      "Creating bottleneck features for batch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 29/782 [00:50<22:29,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 29 created and saved\n",
      "\n",
      "Batch 30 loaded\n",
      "Creating bottleneck features for batch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 30/782 [00:52<22:35,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 30 created and saved\n",
      "\n",
      "Batch 31 loaded\n",
      "Creating bottleneck features for batch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 31/782 [00:53<22:36,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 31 created and saved\n",
      "\n",
      "Batch 32 loaded\n",
      "Creating bottleneck features for batch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 32/782 [00:55<22:30,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 32 created and saved\n",
      "\n",
      "Batch 33 loaded\n",
      "Creating bottleneck features for batch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 33/782 [00:57<22:54,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 33 created and saved\n",
      "\n",
      "Batch 34 loaded\n",
      "Creating bottleneck features for batch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 34/782 [00:59<22:46,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 34 created and saved\n",
      "\n",
      "Batch 35 loaded\n",
      "Creating bottleneck features for batch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 35/782 [01:01<22:36,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 35 created and saved\n",
      "\n",
      "Batch 36 loaded\n",
      "Creating bottleneck features for batch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 36/782 [01:02<22:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 36 created and saved\n",
      "\n",
      "Batch 37 loaded\n",
      "Creating bottleneck features for batch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 37/782 [01:04<22:04,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 37 created and saved\n",
      "\n",
      "Batch 38 loaded\n",
      "Creating bottleneck features for batch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 38/782 [01:06<22:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 38 created and saved\n",
      "\n",
      "Batch 39 loaded\n",
      "Creating bottleneck features for batch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 39/782 [01:08<21:55,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 39 created and saved\n",
      "\n",
      "Batch 40 loaded\n",
      "Creating bottleneck features for batch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 40/782 [01:09<22:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 40 created and saved\n",
      "\n",
      "Batch 41 loaded\n",
      "Creating bottleneck features for batch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 41/782 [01:11<22:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 41 created and saved\n",
      "\n",
      "Batch 42 loaded\n",
      "Creating bottleneck features for batch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 42/782 [01:13<21:45,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 42 created and saved\n",
      "\n",
      "Batch 43 loaded\n",
      "Creating bottleneck features for batch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 43/782 [01:15<21:37,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 43 created and saved\n",
      "\n",
      "Batch 44 loaded\n",
      "Creating bottleneck features for batch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 44/782 [01:16<21:34,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 44 created and saved\n",
      "\n",
      "Batch 45 loaded\n",
      "Creating bottleneck features for batch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 45/782 [01:18<21:28,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 45 created and saved\n",
      "\n",
      "Batch 46 loaded\n",
      "Creating bottleneck features for batch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 46/782 [01:20<21:31,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 46 created and saved\n",
      "\n",
      "Batch 47 loaded\n",
      "Creating bottleneck features for batch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 47/782 [01:22<21:57,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 47 created and saved\n",
      "\n",
      "Batch 48 loaded\n",
      "Creating bottleneck features for batch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 48/782 [01:24<21:57,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 48 created and saved\n",
      "\n",
      "Batch 49 loaded\n",
      "Creating bottleneck features for batch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 49/782 [01:26<22:54,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 49 created and saved\n",
      "\n",
      "Batch 50 loaded\n",
      "Creating bottleneck features for batch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 50/782 [01:27<22:32,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 50 created and saved\n",
      "\n",
      "Batch 51 loaded\n",
      "Creating bottleneck features for batch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 51/782 [01:29<22:12,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 51 created and saved\n",
      "\n",
      "Batch 52 loaded\n",
      "Creating bottleneck features for batch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 52/782 [01:31<22:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 52 created and saved\n",
      "\n",
      "Batch 53 loaded\n",
      "Creating bottleneck features for batch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 53/782 [01:33<21:47,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 53 created and saved\n",
      "\n",
      "Batch 54 loaded\n",
      "Creating bottleneck features for batch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 54/782 [01:34<21:28,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 54 created and saved\n",
      "\n",
      "Batch 55 loaded\n",
      "Creating bottleneck features for batch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 55/782 [01:36<21:26,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 55 created and saved\n",
      "\n",
      "Batch 56 loaded\n",
      "Creating bottleneck features for batch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 56/782 [01:38<21:19,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 56 created and saved\n",
      "\n",
      "Batch 57 loaded\n",
      "Creating bottleneck features for batch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 57/782 [01:40<21:12,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 57 created and saved\n",
      "\n",
      "Batch 58 loaded\n",
      "Creating bottleneck features for batch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 58/782 [01:42<21:14,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 58 created and saved\n",
      "\n",
      "Batch 59 loaded\n",
      "Creating bottleneck features for batch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 59/782 [01:43<21:11,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 59 created and saved\n",
      "\n",
      "Batch 60 loaded\n",
      "Creating bottleneck features for batch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 60/782 [01:45<21:14,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 60 created and saved\n",
      "\n",
      "Batch 61 loaded\n",
      "Creating bottleneck features for batch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 61/782 [01:47<21:28,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 61 created and saved\n",
      "\n",
      "Batch 62 loaded\n",
      "Creating bottleneck features for batch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 62/782 [01:49<21:17,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 62 created and saved\n",
      "\n",
      "Batch 63 loaded\n",
      "Creating bottleneck features for batch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 63/782 [01:50<21:29,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 63 created and saved\n",
      "\n",
      "Batch 64 loaded\n",
      "Creating bottleneck features for batch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 64/782 [01:52<21:23,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 64 created and saved\n",
      "\n",
      "Batch 65 loaded\n",
      "Creating bottleneck features for batch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 65/782 [01:54<21:19,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 65 created and saved\n",
      "\n",
      "Batch 66 loaded\n",
      "Creating bottleneck features for batch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 66/782 [01:56<21:09,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 66 created and saved\n",
      "\n",
      "Batch 67 loaded\n",
      "Creating bottleneck features for batch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 67/782 [01:58<21:13,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 67 created and saved\n",
      "\n",
      "Batch 68 loaded\n",
      "Creating bottleneck features for batch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 68/782 [01:59<21:17,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 68 created and saved\n",
      "\n",
      "Batch 69 loaded\n",
      "Creating bottleneck features for batch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 69/782 [02:01<21:13,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 69 created and saved\n",
      "\n",
      "Batch 70 loaded\n",
      "Creating bottleneck features for batch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 70/782 [02:03<21:12,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 70 created and saved\n",
      "\n",
      "Batch 71 loaded\n",
      "Creating bottleneck features for batch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 71/782 [02:05<21:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 71 created and saved\n",
      "\n",
      "Batch 72 loaded\n",
      "Creating bottleneck features for batch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 72/782 [02:06<21:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 72 created and saved\n",
      "\n",
      "Batch 73 loaded\n",
      "Creating bottleneck features for batch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 73/782 [02:08<20:57,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 73 created and saved\n",
      "\n",
      "Batch 74 loaded\n",
      "Creating bottleneck features for batch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 74/782 [02:10<20:54,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 74 created and saved\n",
      "\n",
      "Batch 75 loaded\n",
      "Creating bottleneck features for batch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 75/782 [02:12<20:52,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 75 created and saved\n",
      "\n",
      "Batch 76 loaded\n",
      "Creating bottleneck features for batch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 76/782 [02:14<20:52,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 76 created and saved\n",
      "\n",
      "Batch 77 loaded\n",
      "Creating bottleneck features for batch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 77/782 [02:15<20:51,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 77 created and saved\n",
      "\n",
      "Batch 78 loaded\n",
      "Creating bottleneck features for batch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 78/782 [02:17<20:47,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 78 created and saved\n",
      "\n",
      "Batch 79 loaded\n",
      "Creating bottleneck features for batch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 79/782 [02:19<20:46,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 79 created and saved\n",
      "\n",
      "Batch 80 loaded\n",
      "Creating bottleneck features for batch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 80/782 [02:21<20:35,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 80 created and saved\n",
      "\n",
      "Batch 81 loaded\n",
      "Creating bottleneck features for batch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 81/782 [02:22<20:35,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 81 created and saved\n",
      "\n",
      "Batch 82 loaded\n",
      "Creating bottleneck features for batch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 82/782 [02:24<20:37,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 82 created and saved\n",
      "\n",
      "Batch 83 loaded\n",
      "Creating bottleneck features for batch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 83/782 [02:26<20:44,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 83 created and saved\n",
      "\n",
      "Batch 84 loaded\n",
      "Creating bottleneck features for batch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 84/782 [02:28<21:28,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 84 created and saved\n",
      "\n",
      "Batch 85 loaded\n",
      "Creating bottleneck features for batch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 85/782 [02:30<21:37,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 85 created and saved\n",
      "\n",
      "Batch 86 loaded\n",
      "Creating bottleneck features for batch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 86/782 [02:32<21:24,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 86 created and saved\n",
      "\n",
      "Batch 87 loaded\n",
      "Creating bottleneck features for batch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 87/782 [02:33<21:14,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 87 created and saved\n",
      "\n",
      "Batch 88 loaded\n",
      "Creating bottleneck features for batch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 88/782 [02:35<21:06,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 88 created and saved\n",
      "\n",
      "Batch 89 loaded\n",
      "Creating bottleneck features for batch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 89/782 [02:37<20:55,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 89 created and saved\n",
      "\n",
      "Batch 90 loaded\n",
      "Creating bottleneck features for batch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 90/782 [02:39<20:47,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 90 created and saved\n",
      "\n",
      "Batch 91 loaded\n",
      "Creating bottleneck features for batch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 91/782 [02:41<20:45,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 91 created and saved\n",
      "\n",
      "Batch 92 loaded\n",
      "Creating bottleneck features for batch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 92/782 [02:43<21:04,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 92 created and saved\n",
      "\n",
      "Batch 93 loaded\n",
      "Creating bottleneck features for batch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 93/782 [02:44<20:53,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 93 created and saved\n",
      "\n",
      "Batch 94 loaded\n",
      "Creating bottleneck features for batch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 94/782 [02:46<20:46,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 94 created and saved\n",
      "\n",
      "Batch 95 loaded\n",
      "Creating bottleneck features for batch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 95/782 [02:48<20:53,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 95 created and saved\n",
      "\n",
      "Batch 96 loaded\n",
      "Creating bottleneck features for batch 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 96/782 [02:50<20:42,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 96 created and saved\n",
      "\n",
      "Batch 97 loaded\n",
      "Creating bottleneck features for batch 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 97/782 [02:52<20:25,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 97 created and saved\n",
      "\n",
      "Batch 98 loaded\n",
      "Creating bottleneck features for batch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 98/782 [02:53<20:26,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 98 created and saved\n",
      "\n",
      "Batch 99 loaded\n",
      "Creating bottleneck features for batch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 99/782 [02:55<20:23,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 99 created and saved\n",
      "\n",
      "Batch 100 loaded\n",
      "Creating bottleneck features for batch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 100/782 [02:57<20:19,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 100 created and saved\n",
      "\n",
      "Batch 101 loaded\n",
      "Creating bottleneck features for batch 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 101/782 [02:59<20:20,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 101 created and saved\n",
      "\n",
      "Batch 102 loaded\n",
      "Creating bottleneck features for batch 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 102/782 [03:01<20:36,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 102 created and saved\n",
      "\n",
      "Batch 103 loaded\n",
      "Creating bottleneck features for batch 103\n",
      "Bottleneck features for batch 167 created and saved\n",
      "\n",
      "Batch 168 loaded\n",
      "Creating bottleneck features for batch 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 168/782 [04:58<17:55,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 168 created and saved\n",
      "\n",
      "Batch 169 loaded\n",
      "Creating bottleneck features for batch 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 169/782 [05:00<17:57,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 169 created and saved\n",
      "\n",
      "Batch 170 loaded\n",
      "Creating bottleneck features for batch 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 170/782 [05:02<17:57,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 170 created and saved\n",
      "\n",
      "Batch 171 loaded\n",
      "Creating bottleneck features for batch 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 171/782 [05:04<17:50,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 171 created and saved\n",
      "\n",
      "Batch 172 loaded\n",
      "Creating bottleneck features for batch 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 172/782 [05:06<18:08,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 172 created and saved\n",
      "\n",
      "Batch 173 loaded\n",
      "Creating bottleneck features for batch 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 173/782 [05:07<17:54,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 173 created and saved\n",
      "\n",
      "Batch 174 loaded\n",
      "Creating bottleneck features for batch 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 174/782 [05:09<17:54,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 174 created and saved\n",
      "\n",
      "Batch 175 loaded\n",
      "Creating bottleneck features for batch 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 175/782 [05:11<17:50,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 175 created and saved\n",
      "\n",
      "Batch 176 loaded\n",
      "Creating bottleneck features for batch 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 176/782 [05:13<17:48,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 176 created and saved\n",
      "\n",
      "Batch 177 loaded\n",
      "Creating bottleneck features for batch 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 177/782 [05:14<17:50,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 177 created and saved\n",
      "\n",
      "Batch 178 loaded\n",
      "Creating bottleneck features for batch 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 178/782 [05:16<17:46,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 178 created and saved\n",
      "\n",
      "Batch 179 loaded\n",
      "Creating bottleneck features for batch 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 179/782 [05:18<17:36,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 179 created and saved\n",
      "\n",
      "Batch 180 loaded\n",
      "Creating bottleneck features for batch 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 180/782 [05:20<17:36,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 180 created and saved\n",
      "\n",
      "Batch 181 loaded\n",
      "Creating bottleneck features for batch 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 181/782 [05:21<17:18,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 181 created and saved\n",
      "\n",
      "Batch 182 loaded\n",
      "Creating bottleneck features for batch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 182/782 [05:23<17:14,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 182 created and saved\n",
      "\n",
      "Batch 183 loaded\n",
      "Creating bottleneck features for batch 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 183/782 [05:25<17:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 183 created and saved\n",
      "\n",
      "Batch 184 loaded\n",
      "Creating bottleneck features for batch 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 184/782 [05:26<17:19,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 184 created and saved\n",
      "\n",
      "Batch 185 loaded\n",
      "Creating bottleneck features for batch 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 185/782 [05:28<17:11,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 185 created and saved\n",
      "\n",
      "Batch 186 loaded\n",
      "Creating bottleneck features for batch 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 186/782 [05:30<17:16,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 186 created and saved\n",
      "\n",
      "Batch 187 loaded\n",
      "Creating bottleneck features for batch 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 187/782 [05:32<17:27,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 187 created and saved\n",
      "\n",
      "Batch 188 loaded\n",
      "Creating bottleneck features for batch 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 188/782 [05:33<17:21,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 188 created and saved\n",
      "\n",
      "Batch 189 loaded\n",
      "Creating bottleneck features for batch 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 189/782 [05:35<17:37,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 189 created and saved\n",
      "\n",
      "Batch 190 loaded\n",
      "Creating bottleneck features for batch 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 190/782 [05:37<17:22,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 190 created and saved\n",
      "\n",
      "Batch 191 loaded\n",
      "Creating bottleneck features for batch 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 191/782 [05:39<17:20,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 191 created and saved\n",
      "\n",
      "Batch 192 loaded\n",
      "Creating bottleneck features for batch 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 192/782 [05:41<17:22,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 192 created and saved\n",
      "\n",
      "Batch 193 loaded\n",
      "Creating bottleneck features for batch 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 193/782 [05:42<17:19,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 193 created and saved\n",
      "\n",
      "Batch 194 loaded\n",
      "Creating bottleneck features for batch 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 194/782 [05:44<17:17,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 194 created and saved\n",
      "\n",
      "Batch 195 loaded\n",
      "Creating bottleneck features for batch 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 195/782 [05:46<17:18,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 195 created and saved\n",
      "\n",
      "Batch 196 loaded\n",
      "Creating bottleneck features for batch 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 196/782 [05:48<17:09,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 196 created and saved\n",
      "\n",
      "Batch 197 loaded\n",
      "Creating bottleneck features for batch 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 197/782 [05:49<17:16,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 197 created and saved\n",
      "\n",
      "Batch 198 loaded\n",
      "Creating bottleneck features for batch 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 198/782 [05:51<17:18,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 198 created and saved\n",
      "\n",
      "Batch 199 loaded\n",
      "Creating bottleneck features for batch 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 199/782 [05:53<17:14,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 199 created and saved\n",
      "\n",
      "Batch 200 loaded\n",
      "Creating bottleneck features for batch 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 200/782 [05:55<17:10,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 200 created and saved\n",
      "\n",
      "Batch 201 loaded\n",
      "Creating bottleneck features for batch 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 201/782 [05:57<17:22,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 201 created and saved\n",
      "\n",
      "Batch 202 loaded\n",
      "Creating bottleneck features for batch 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 202/782 [05:58<17:14,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 202 created and saved\n",
      "\n",
      "Batch 203 loaded\n",
      "Creating bottleneck features for batch 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 203/782 [06:00<17:08,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 203 created and saved\n",
      "\n",
      "Batch 204 loaded\n",
      "Creating bottleneck features for batch 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 204/782 [06:02<17:06,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 204 created and saved\n",
      "\n",
      "Batch 205 loaded\n",
      "Creating bottleneck features for batch 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 205/782 [06:04<16:54,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 205 created and saved\n",
      "\n",
      "Batch 206 loaded\n",
      "Creating bottleneck features for batch 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 206/782 [06:05<16:48,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 206 created and saved\n",
      "\n",
      "Batch 207 loaded\n",
      "Creating bottleneck features for batch 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 207/782 [06:07<16:51,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 207 created and saved\n",
      "\n",
      "Batch 208 loaded\n",
      "Creating bottleneck features for batch 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 208/782 [06:09<16:49,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 208 created and saved\n",
      "\n",
      "Batch 209 loaded\n",
      "Creating bottleneck features for batch 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 209/782 [06:11<16:51,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 209 created and saved\n",
      "\n",
      "Batch 210 loaded\n",
      "Creating bottleneck features for batch 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 210/782 [06:12<16:36,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 210 created and saved\n",
      "\n",
      "Batch 211 loaded\n",
      "Creating bottleneck features for batch 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 211/782 [06:14<16:23,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 211 created and saved\n",
      "\n",
      "Batch 212 loaded\n",
      "Creating bottleneck features for batch 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 212/782 [06:16<16:29,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 212 created and saved\n",
      "\n",
      "Batch 213 loaded\n",
      "Creating bottleneck features for batch 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 213/782 [06:18<16:32,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 213 created and saved\n",
      "\n",
      "Batch 214 loaded\n",
      "Creating bottleneck features for batch 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 214/782 [06:19<16:41,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 214 created and saved\n",
      "\n",
      "Batch 215 loaded\n",
      "Creating bottleneck features for batch 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 215/782 [06:21<16:45,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 215 created and saved\n",
      "\n",
      "Batch 216 loaded\n",
      "Creating bottleneck features for batch 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 216/782 [06:23<16:32,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 216 created and saved\n",
      "\n",
      "Batch 217 loaded\n",
      "Creating bottleneck features for batch 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 217/782 [06:25<16:27,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 217 created and saved\n",
      "\n",
      "Batch 218 loaded\n",
      "Creating bottleneck features for batch 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 218/782 [06:26<16:17,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 218 created and saved\n",
      "\n",
      "Batch 219 loaded\n",
      "Creating bottleneck features for batch 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 219/782 [06:28<16:27,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 219 created and saved\n",
      "\n",
      "Batch 220 loaded\n",
      "Creating bottleneck features for batch 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 220/782 [06:30<16:23,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 220 created and saved\n",
      "\n",
      "Batch 221 loaded\n",
      "Creating bottleneck features for batch 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 221/782 [06:32<16:13,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 221 created and saved\n",
      "\n",
      "Batch 222 loaded\n",
      "Creating bottleneck features for batch 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 222/782 [06:33<16:04,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 222 created and saved\n",
      "\n",
      "Batch 223 loaded\n",
      "Creating bottleneck features for batch 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 223/782 [06:35<15:58,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 223 created and saved\n",
      "\n",
      "Batch 224 loaded\n",
      "Creating bottleneck features for batch 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 224/782 [06:37<15:56,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 224 created and saved\n",
      "\n",
      "Batch 225 loaded\n",
      "Creating bottleneck features for batch 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 225/782 [06:38<16:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 225 created and saved\n",
      "\n",
      "Batch 226 loaded\n",
      "Creating bottleneck features for batch 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 226/782 [06:40<16:09,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 226 created and saved\n",
      "\n",
      "Batch 227 loaded\n",
      "Creating bottleneck features for batch 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 227/782 [06:42<16:08,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 227 created and saved\n",
      "\n",
      "Batch 228 loaded\n",
      "Creating bottleneck features for batch 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 228/782 [06:44<16:09,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 228 created and saved\n",
      "\n",
      "Batch 229 loaded\n",
      "Creating bottleneck features for batch 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 229/782 [06:45<16:08,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 229 created and saved\n",
      "\n",
      "Batch 230 loaded\n",
      "Creating bottleneck features for batch 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 230/782 [06:47<16:02,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 230 created and saved\n",
      "\n",
      "Batch 231 loaded\n",
      "Creating bottleneck features for batch 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 231/782 [06:49<15:50,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 231 created and saved\n",
      "\n",
      "Batch 232 loaded\n",
      "Creating bottleneck features for batch 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 232/782 [06:51<16:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 232 created and saved\n",
      "\n",
      "Batch 233 loaded\n",
      "Creating bottleneck features for batch 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 233/782 [06:52<16:09,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 233 created and saved\n",
      "\n",
      "Batch 234 loaded\n",
      "Creating bottleneck features for batch 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 234/782 [06:54<15:51,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 234 created and saved\n",
      "\n",
      "Batch 235 loaded\n",
      "Creating bottleneck features for batch 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 235/782 [06:56<15:54,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 235 created and saved\n",
      "\n",
      "Batch 236 loaded\n",
      "Creating bottleneck features for batch 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 236/782 [06:58<16:07,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 236 created and saved\n",
      "\n",
      "Batch 237 loaded\n",
      "Creating bottleneck features for batch 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 237/782 [06:59<15:58,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 237 created and saved\n",
      "\n",
      "Batch 238 loaded\n",
      "Creating bottleneck features for batch 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 238/782 [07:01<15:49,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 238 created and saved\n",
      "\n",
      "Batch 239 loaded\n",
      "Creating bottleneck features for batch 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 239/782 [07:03<15:45,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 239 created and saved\n",
      "\n",
      "Batch 240 loaded\n",
      "Creating bottleneck features for batch 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 240/782 [07:05<15:47,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 240 created and saved\n",
      "\n",
      "Batch 241 loaded\n",
      "Creating bottleneck features for batch 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 241/782 [07:06<15:45,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 241 created and saved\n",
      "\n",
      "Batch 242 loaded\n",
      "Creating bottleneck features for batch 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 242/782 [07:08<15:46,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 242 created and saved\n",
      "\n",
      "Batch 243 loaded\n",
      "Creating bottleneck features for batch 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 243/782 [07:10<15:45,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 243 created and saved\n",
      "\n",
      "Batch 244 loaded\n",
      "Creating bottleneck features for batch 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 244/782 [07:12<15:40,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 244 created and saved\n",
      "\n",
      "Batch 245 loaded\n",
      "Creating bottleneck features for batch 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 245/782 [07:13<15:36,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 245 created and saved\n",
      "\n",
      "Batch 246 loaded\n",
      "Creating bottleneck features for batch 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 246/782 [07:15<15:39,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 246 created and saved\n",
      "\n",
      "Batch 247 loaded\n",
      "Creating bottleneck features for batch 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 247/782 [07:17<15:35,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 247 created and saved\n",
      "\n",
      "Batch 248 loaded\n",
      "Creating bottleneck features for batch 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 248/782 [07:19<15:43,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 248 created and saved\n",
      "\n",
      "Batch 249 loaded\n",
      "Creating bottleneck features for batch 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 249/782 [07:20<15:36,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 249 created and saved\n",
      "\n",
      "Batch 250 loaded\n",
      "Creating bottleneck features for batch 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 250/782 [07:22<15:32,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 250 created and saved\n",
      "\n",
      "Batch 251 loaded\n",
      "Creating bottleneck features for batch 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 251/782 [07:24<15:27,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 251 created and saved\n",
      "\n",
      "Batch 252 loaded\n",
      "Creating bottleneck features for batch 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 252/782 [07:26<15:18,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 252 created and saved\n",
      "\n",
      "Batch 253 loaded\n",
      "Creating bottleneck features for batch 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 253/782 [07:27<15:14,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 253 created and saved\n",
      "\n",
      "Batch 254 loaded\n",
      "Creating bottleneck features for batch 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 254/782 [07:29<15:19,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 254 created and saved\n",
      "\n",
      "Batch 255 loaded\n",
      "Creating bottleneck features for batch 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 255/782 [07:31<15:18,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 255 created and saved\n",
      "\n",
      "Batch 256 loaded\n",
      "Creating bottleneck features for batch 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 256/782 [07:33<15:27,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 256 created and saved\n",
      "\n",
      "Batch 257 loaded\n",
      "Creating bottleneck features for batch 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 257/782 [07:34<15:31,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 257 created and saved\n",
      "\n",
      "Batch 258 loaded\n",
      "Creating bottleneck features for batch 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 258/782 [07:36<15:12,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 258 created and saved\n",
      "\n",
      "Batch 259 loaded\n",
      "Creating bottleneck features for batch 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 259/782 [07:38<15:02,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 259 created and saved\n",
      "\n",
      "Batch 260 loaded\n",
      "Creating bottleneck features for batch 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 260/782 [07:40<15:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 260 created and saved\n",
      "\n",
      "Batch 261 loaded\n",
      "Creating bottleneck features for batch 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 261/782 [07:41<15:11,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 261 created and saved\n",
      "\n",
      "Batch 262 loaded\n",
      "Creating bottleneck features for batch 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 262/782 [07:43<15:10,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 262 created and saved\n",
      "\n",
      "Batch 263 loaded\n",
      "Creating bottleneck features for batch 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 263/782 [07:45<15:08,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 263 created and saved\n",
      "\n",
      "Batch 264 loaded\n",
      "Creating bottleneck features for batch 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 264/782 [07:47<15:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 264 created and saved\n",
      "\n",
      "Batch 265 loaded\n",
      "Creating bottleneck features for batch 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 265/782 [07:48<14:58,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 265 created and saved\n",
      "\n",
      "Batch 266 loaded\n",
      "Creating bottleneck features for batch 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 266/782 [07:50<14:57,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 266 created and saved\n",
      "\n",
      "Batch 267 loaded\n",
      "Creating bottleneck features for batch 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 267/782 [07:52<14:57,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 267 created and saved\n",
      "\n",
      "Batch 268 loaded\n",
      "Creating bottleneck features for batch 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 268/782 [07:54<15:01,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 268 created and saved\n",
      "\n",
      "Batch 269 loaded\n",
      "Creating bottleneck features for batch 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 269/782 [07:55<15:04,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 269 created and saved\n",
      "\n",
      "Batch 270 loaded\n",
      "Creating bottleneck features for batch 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 270/782 [07:57<15:07,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 270 created and saved\n",
      "\n",
      "Batch 271 loaded\n",
      "Creating bottleneck features for batch 271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 271/782 [07:59<15:05,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 271 created and saved\n",
      "\n",
      "Batch 272 loaded\n",
      "Creating bottleneck features for batch 272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 272/782 [08:01<14:53,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 272 created and saved\n",
      "\n",
      "Batch 273 loaded\n",
      "Creating bottleneck features for batch 273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 273/782 [08:02<14:42,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 273 created and saved\n",
      "\n",
      "Batch 274 loaded\n",
      "Creating bottleneck features for batch 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 274/782 [08:04<14:31,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 274 created and saved\n",
      "\n",
      "Batch 275 loaded\n",
      "Creating bottleneck features for batch 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 275/782 [08:06<14:29,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 275 created and saved\n",
      "\n",
      "Batch 276 loaded\n",
      "Creating bottleneck features for batch 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 276/782 [08:08<14:41,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 276 created and saved\n",
      "\n",
      "Batch 277 loaded\n",
      "Creating bottleneck features for batch 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 277/782 [08:09<14:32,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 277 created and saved\n",
      "\n",
      "Batch 278 loaded\n",
      "Creating bottleneck features for batch 278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 278/782 [08:11<14:32,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 278 created and saved\n",
      "\n",
      "Batch 279 loaded\n",
      "Creating bottleneck features for batch 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 279/782 [08:13<14:31,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 279 created and saved\n",
      "\n",
      "Batch 280 loaded\n",
      "Creating bottleneck features for batch 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 280/782 [08:14<14:29,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 280 created and saved\n",
      "\n",
      "Batch 281 loaded\n",
      "Creating bottleneck features for batch 281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 281/782 [08:16<14:23,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 281 created and saved\n",
      "\n",
      "Batch 282 loaded\n",
      "Creating bottleneck features for batch 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 282/782 [08:18<14:16,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 282 created and saved\n",
      "\n",
      "Batch 283 loaded\n",
      "Creating bottleneck features for batch 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 283/782 [08:20<14:18,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 283 created and saved\n",
      "\n",
      "Batch 284 loaded\n",
      "Creating bottleneck features for batch 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 284/782 [08:21<14:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 284 created and saved\n",
      "\n",
      "Batch 285 loaded\n",
      "Creating bottleneck features for batch 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 285/782 [08:23<14:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 285 created and saved\n",
      "\n",
      "Batch 286 loaded\n",
      "Creating bottleneck features for batch 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 286/782 [08:25<14:24,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 286 created and saved\n",
      "\n",
      "Batch 287 loaded\n",
      "Creating bottleneck features for batch 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 287/782 [08:27<14:30,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 287 created and saved\n",
      "\n",
      "Batch 288 loaded\n",
      "Creating bottleneck features for batch 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 288/782 [08:28<14:18,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 288 created and saved\n",
      "\n",
      "Batch 289 loaded\n",
      "Creating bottleneck features for batch 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 289/782 [08:30<14:23,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 289 created and saved\n",
      "\n",
      "Batch 290 loaded\n",
      "Creating bottleneck features for batch 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 290/782 [08:32<14:20,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 290 created and saved\n",
      "\n",
      "Batch 291 loaded\n",
      "Creating bottleneck features for batch 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 291/782 [08:34<14:18,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 291 created and saved\n",
      "\n",
      "Batch 292 loaded\n",
      "Creating bottleneck features for batch 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 292/782 [08:35<14:14,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 292 created and saved\n",
      "\n",
      "Batch 293 loaded\n",
      "Creating bottleneck features for batch 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 293/782 [08:37<14:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 293 created and saved\n",
      "\n",
      "Batch 294 loaded\n",
      "Creating bottleneck features for batch 294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 294/782 [08:39<13:53,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 294 created and saved\n",
      "\n",
      "Batch 295 loaded\n",
      "Creating bottleneck features for batch 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 295/782 [08:40<13:54,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 295 created and saved\n",
      "\n",
      "Batch 296 loaded\n",
      "Creating bottleneck features for batch 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 296/782 [08:42<13:52,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 296 created and saved\n",
      "\n",
      "Batch 297 loaded\n",
      "Creating bottleneck features for batch 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 297/782 [08:44<13:51,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 297 created and saved\n",
      "\n",
      "Batch 298 loaded\n",
      "Creating bottleneck features for batch 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 298/782 [08:46<13:53,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 298 created and saved\n",
      "\n",
      "Batch 299 loaded\n",
      "Creating bottleneck features for batch 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 299/782 [08:47<13:59,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 299 created and saved\n",
      "\n",
      "Batch 300 loaded\n",
      "Creating bottleneck features for batch 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 300/782 [08:49<13:49,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 300 created and saved\n",
      "\n",
      "Batch 301 loaded\n",
      "Creating bottleneck features for batch 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 301/782 [08:51<13:57,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 301 created and saved\n",
      "\n",
      "Batch 302 loaded\n",
      "Creating bottleneck features for batch 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 302/782 [08:53<14:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 302 created and saved\n",
      "\n",
      "Batch 303 loaded\n",
      "Creating bottleneck features for batch 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 303/782 [08:54<14:01,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 303 created and saved\n",
      "\n",
      "Batch 304 loaded\n",
      "Creating bottleneck features for batch 304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 304/782 [08:56<13:44,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 304 created and saved\n",
      "\n",
      "Batch 305 loaded\n",
      "Creating bottleneck features for batch 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 305/782 [08:58<13:32,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 305 created and saved\n",
      "\n",
      "Batch 306 loaded\n",
      "Creating bottleneck features for batch 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 306/782 [08:59<13:26,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 306 created and saved\n",
      "\n",
      "Batch 307 loaded\n",
      "Creating bottleneck features for batch 307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 307/782 [09:01<13:30,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 307 created and saved\n",
      "\n",
      "Batch 308 loaded\n",
      "Creating bottleneck features for batch 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 308/782 [09:03<13:30,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 308 created and saved\n",
      "\n",
      "Batch 309 loaded\n",
      "Creating bottleneck features for batch 309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 309/782 [09:04<13:10,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 309 created and saved\n",
      "\n",
      "Batch 310 loaded\n",
      "Creating bottleneck features for batch 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 310/782 [09:06<13:16,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 310 created and saved\n",
      "\n",
      "Batch 311 loaded\n",
      "Creating bottleneck features for batch 311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 311/782 [09:08<13:11,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 311 created and saved\n",
      "\n",
      "Batch 312 loaded\n",
      "Creating bottleneck features for batch 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 312/782 [09:09<13:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 312 created and saved\n",
      "\n",
      "Batch 313 loaded\n",
      "Creating bottleneck features for batch 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 313/782 [09:11<13:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 313 created and saved\n",
      "\n",
      "Batch 314 loaded\n",
      "Creating bottleneck features for batch 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 314/782 [09:13<13:21,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 314 created and saved\n",
      "\n",
      "Batch 315 loaded\n",
      "Creating bottleneck features for batch 315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 315/782 [09:15<13:19,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 315 created and saved\n",
      "\n",
      "Batch 316 loaded\n",
      "Creating bottleneck features for batch 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 316/782 [09:16<13:33,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 316 created and saved\n",
      "\n",
      "Batch 317 loaded\n",
      "Creating bottleneck features for batch 317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 317/782 [09:18<13:37,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 317 created and saved\n",
      "\n",
      "Batch 318 loaded\n",
      "Creating bottleneck features for batch 318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 318/782 [09:20<13:35,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 318 created and saved\n",
      "\n",
      "Batch 319 loaded\n",
      "Creating bottleneck features for batch 319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 319/782 [09:22<13:25,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 319 created and saved\n",
      "\n",
      "Batch 320 loaded\n",
      "Creating bottleneck features for batch 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 320/782 [09:23<13:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 320 created and saved\n",
      "\n",
      "Batch 321 loaded\n",
      "Creating bottleneck features for batch 321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 321/782 [09:25<13:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 321 created and saved\n",
      "\n",
      "Batch 322 loaded\n",
      "Creating bottleneck features for batch 322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 322/782 [09:27<13:13,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 322 created and saved\n",
      "\n",
      "Batch 323 loaded\n",
      "Creating bottleneck features for batch 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 323/782 [09:29<13:06,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 323 created and saved\n",
      "\n",
      "Batch 324 loaded\n",
      "Creating bottleneck features for batch 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 324/782 [09:30<13:11,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 324 created and saved\n",
      "\n",
      "Batch 325 loaded\n",
      "Creating bottleneck features for batch 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 325/782 [09:32<13:09,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 325 created and saved\n",
      "\n",
      "Batch 326 loaded\n",
      "Creating bottleneck features for batch 326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 326/782 [09:34<12:57,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 326 created and saved\n",
      "\n",
      "Batch 327 loaded\n",
      "Creating bottleneck features for batch 327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 327/782 [09:35<12:48,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 327 created and saved\n",
      "\n",
      "Batch 328 loaded\n",
      "Creating bottleneck features for batch 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 328/782 [09:37<12:58,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 328 created and saved\n",
      "\n",
      "Batch 329 loaded\n",
      "Creating bottleneck features for batch 329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 329/782 [09:39<12:57,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 329 created and saved\n",
      "\n",
      "Batch 330 loaded\n",
      "Creating bottleneck features for batch 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 330/782 [09:41<12:57,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 330 created and saved\n",
      "\n",
      "Batch 331 loaded\n",
      "Creating bottleneck features for batch 331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 331/782 [09:42<12:53,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 331 created and saved\n",
      "\n",
      "Batch 332 loaded\n",
      "Creating bottleneck features for batch 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 332/782 [09:44<12:59,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 332 created and saved\n",
      "\n",
      "Batch 333 loaded\n",
      "Creating bottleneck features for batch 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 333/782 [09:46<12:53,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 333 created and saved\n",
      "\n",
      "Batch 334 loaded\n",
      "Creating bottleneck features for batch 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 334/782 [09:48<14:05,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 334 created and saved\n",
      "\n",
      "Batch 335 loaded\n",
      "Creating bottleneck features for batch 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 335/782 [09:50<13:35,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 335 created and saved\n",
      "\n",
      "Batch 336 loaded\n",
      "Creating bottleneck features for batch 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 336/782 [09:51<13:21,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 336 created and saved\n",
      "\n",
      "Batch 337 loaded\n",
      "Creating bottleneck features for batch 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 337/782 [09:53<13:09,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 337 created and saved\n",
      "\n",
      "Batch 338 loaded\n",
      "Creating bottleneck features for batch 338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 338/782 [09:55<13:04,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 338 created and saved\n",
      "\n",
      "Batch 339 loaded\n",
      "Creating bottleneck features for batch 339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 339/782 [09:57<12:52,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 339 created and saved\n",
      "\n",
      "Batch 340 loaded\n",
      "Creating bottleneck features for batch 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 340/782 [09:58<12:45,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 340 created and saved\n",
      "\n",
      "Batch 341 loaded\n",
      "Creating bottleneck features for batch 341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 341/782 [10:00<12:38,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 341 created and saved\n",
      "\n",
      "Batch 342 loaded\n",
      "Creating bottleneck features for batch 342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 342/782 [10:02<12:37,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 342 created and saved\n",
      "\n",
      "Batch 343 loaded\n",
      "Creating bottleneck features for batch 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 343/782 [10:03<12:30,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 343 created and saved\n",
      "\n",
      "Batch 344 loaded\n",
      "Creating bottleneck features for batch 344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 344/782 [10:05<12:33,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 344 created and saved\n",
      "\n",
      "Batch 345 loaded\n",
      "Creating bottleneck features for batch 345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 345/782 [10:07<12:27,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 345 created and saved\n",
      "\n",
      "Batch 346 loaded\n",
      "Creating bottleneck features for batch 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 346/782 [10:09<12:29,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 346 created and saved\n",
      "\n",
      "Batch 347 loaded\n",
      "Creating bottleneck features for batch 347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 347/782 [10:10<12:29,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 347 created and saved\n",
      "\n",
      "Batch 348 loaded\n",
      "Creating bottleneck features for batch 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 348/782 [10:12<12:29,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 348 created and saved\n",
      "\n",
      "Batch 349 loaded\n",
      "Creating bottleneck features for batch 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 349/782 [10:14<12:37,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 349 created and saved\n",
      "\n",
      "Batch 350 loaded\n",
      "Creating bottleneck features for batch 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 350/782 [10:16<12:29,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 350 created and saved\n",
      "\n",
      "Batch 351 loaded\n",
      "Creating bottleneck features for batch 351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 351/782 [10:17<12:31,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 351 created and saved\n",
      "\n",
      "Batch 352 loaded\n",
      "Creating bottleneck features for batch 352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 352/782 [10:19<12:54,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 352 created and saved\n",
      "\n",
      "Batch 353 loaded\n",
      "Creating bottleneck features for batch 353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 353/782 [10:21<12:40,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 353 created and saved\n",
      "\n",
      "Batch 354 loaded\n",
      "Creating bottleneck features for batch 354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 354/782 [10:23<12:25,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 354 created and saved\n",
      "\n",
      "Batch 355 loaded\n",
      "Creating bottleneck features for batch 355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 355/782 [10:24<12:24,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 355 created and saved\n",
      "\n",
      "Batch 356 loaded\n",
      "Creating bottleneck features for batch 356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 356/782 [10:26<12:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 356 created and saved\n",
      "\n",
      "Batch 357 loaded\n",
      "Creating bottleneck features for batch 357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 357/782 [10:28<12:09,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 357 created and saved\n",
      "\n",
      "Batch 358 loaded\n",
      "Creating bottleneck features for batch 358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 358/782 [10:30<12:15,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 358 created and saved\n",
      "\n",
      "Batch 359 loaded\n",
      "Creating bottleneck features for batch 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 359/782 [10:31<12:15,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 359 created and saved\n",
      "\n",
      "Batch 360 loaded\n",
      "Creating bottleneck features for batch 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 360/782 [10:33<12:21,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 360 created and saved\n",
      "\n",
      "Batch 361 loaded\n",
      "Creating bottleneck features for batch 361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 361/782 [10:35<12:17,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 361 created and saved\n",
      "\n",
      "Batch 362 loaded\n",
      "Creating bottleneck features for batch 362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 362/782 [10:37<12:11,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 362 created and saved\n",
      "\n",
      "Batch 363 loaded\n",
      "Creating bottleneck features for batch 363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 363/782 [10:38<12:11,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 363 created and saved\n",
      "\n",
      "Batch 364 loaded\n",
      "Creating bottleneck features for batch 364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 364/782 [10:40<12:09,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 364 created and saved\n",
      "\n",
      "Batch 365 loaded\n",
      "Creating bottleneck features for batch 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 365/782 [10:42<11:58,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 365 created and saved\n",
      "\n",
      "Batch 366 loaded\n",
      "Creating bottleneck features for batch 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 366/782 [10:43<11:57,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 366 created and saved\n",
      "\n",
      "Batch 367 loaded\n",
      "Creating bottleneck features for batch 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 367/782 [10:45<11:47,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 367 created and saved\n",
      "\n",
      "Batch 368 loaded\n",
      "Creating bottleneck features for batch 368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 368/782 [10:47<11:42,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 368 created and saved\n",
      "\n",
      "Batch 369 loaded\n",
      "Creating bottleneck features for batch 369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 369/782 [10:48<11:41,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 369 created and saved\n",
      "\n",
      "Batch 370 loaded\n",
      "Creating bottleneck features for batch 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 370/782 [10:52<15:02,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 370 created and saved\n",
      "\n",
      "Batch 371 loaded\n",
      "Creating bottleneck features for batch 371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 371/782 [10:54<14:07,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 371 created and saved\n",
      "\n",
      "Batch 372 loaded\n",
      "Creating bottleneck features for batch 372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 372/782 [10:55<13:18,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 372 created and saved\n",
      "\n",
      "Batch 373 loaded\n",
      "Creating bottleneck features for batch 373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 373/782 [10:57<12:48,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 373 created and saved\n",
      "\n",
      "Batch 374 loaded\n",
      "Creating bottleneck features for batch 374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 374/782 [10:59<12:24,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 374 created and saved\n",
      "\n",
      "Batch 375 loaded\n",
      "Creating bottleneck features for batch 375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 375/782 [11:00<12:07,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 375 created and saved\n",
      "\n",
      "Batch 376 loaded\n",
      "Creating bottleneck features for batch 376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 376/782 [11:02<11:49,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 376 created and saved\n",
      "\n",
      "Batch 377 loaded\n",
      "Creating bottleneck features for batch 377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 377/782 [11:04<11:49,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 377 created and saved\n",
      "\n",
      "Batch 378 loaded\n",
      "Creating bottleneck features for batch 378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 378/782 [11:05<11:40,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 378 created and saved\n",
      "\n",
      "Batch 379 loaded\n",
      "Creating bottleneck features for batch 379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 379/782 [11:07<11:30,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 379 created and saved\n",
      "\n",
      "Batch 380 loaded\n",
      "Creating bottleneck features for batch 380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 380/782 [11:09<11:29,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 380 created and saved\n",
      "\n",
      "Batch 381 loaded\n",
      "Creating bottleneck features for batch 381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 381/782 [11:11<11:26,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 381 created and saved\n",
      "\n",
      "Batch 382 loaded\n",
      "Creating bottleneck features for batch 382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 382/782 [11:12<11:29,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 382 created and saved\n",
      "\n",
      "Batch 383 loaded\n",
      "Creating bottleneck features for batch 383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 383/782 [11:14<11:19,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 383 created and saved\n",
      "\n",
      "Batch 384 loaded\n",
      "Creating bottleneck features for batch 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 384/782 [11:16<11:16,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 384 created and saved\n",
      "\n",
      "Batch 385 loaded\n",
      "Creating bottleneck features for batch 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 385/782 [11:17<11:21,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 385 created and saved\n",
      "\n",
      "Batch 386 loaded\n",
      "Creating bottleneck features for batch 386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 386/782 [11:19<11:16,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 386 created and saved\n",
      "\n",
      "Batch 387 loaded\n",
      "Creating bottleneck features for batch 387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 387/782 [11:21<11:15,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 387 created and saved\n",
      "\n",
      "Batch 388 loaded\n",
      "Creating bottleneck features for batch 388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 388/782 [11:23<11:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 388 created and saved\n",
      "\n",
      "Batch 389 loaded\n",
      "Creating bottleneck features for batch 389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 389/782 [11:24<11:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 389 created and saved\n",
      "\n",
      "Batch 390 loaded\n",
      "Creating bottleneck features for batch 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 390/782 [11:26<11:18,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 390 created and saved\n",
      "\n",
      "Batch 391 loaded\n",
      "Creating bottleneck features for batch 391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 391/782 [11:28<11:13,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 391 created and saved\n",
      "\n",
      "Batch 392 loaded\n",
      "Creating bottleneck features for batch 392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 392/782 [11:29<11:12,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 392 created and saved\n",
      "\n",
      "Batch 393 loaded\n",
      "Creating bottleneck features for batch 393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 393/782 [11:31<11:11,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 393 created and saved\n",
      "\n",
      "Batch 394 loaded\n",
      "Creating bottleneck features for batch 394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 394/782 [11:33<11:14,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 394 created and saved\n",
      "\n",
      "Batch 395 loaded\n",
      "Creating bottleneck features for batch 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 395/782 [11:35<11:07,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 395 created and saved\n",
      "\n",
      "Batch 396 loaded\n",
      "Creating bottleneck features for batch 396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 396/782 [11:36<11:05,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 396 created and saved\n",
      "\n",
      "Batch 397 loaded\n",
      "Creating bottleneck features for batch 397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 397/782 [11:38<11:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 397 created and saved\n",
      "\n",
      "Batch 398 loaded\n",
      "Creating bottleneck features for batch 398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 398/782 [11:40<11:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 398 created and saved\n",
      "\n",
      "Batch 399 loaded\n",
      "Creating bottleneck features for batch 399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 399/782 [11:42<10:58,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 399 created and saved\n",
      "\n",
      "Batch 400 loaded\n",
      "Creating bottleneck features for batch 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 400/782 [11:43<10:49,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 400 created and saved\n",
      "\n",
      "Batch 401 loaded\n",
      "Creating bottleneck features for batch 401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 401/782 [11:45<10:46,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 401 created and saved\n",
      "\n",
      "Batch 402 loaded\n",
      "Creating bottleneck features for batch 402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 402/782 [11:47<10:45,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 402 created and saved\n",
      "\n",
      "Batch 403 loaded\n",
      "Creating bottleneck features for batch 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 403/782 [11:48<10:46,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 403 created and saved\n",
      "\n",
      "Batch 404 loaded\n",
      "Creating bottleneck features for batch 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 404/782 [11:50<10:45,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 404 created and saved\n",
      "\n",
      "Batch 405 loaded\n",
      "Creating bottleneck features for batch 405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 405/782 [11:52<10:46,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 405 created and saved\n",
      "\n",
      "Batch 406 loaded\n",
      "Creating bottleneck features for batch 406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 406/782 [11:53<10:42,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 406 created and saved\n",
      "\n",
      "Batch 407 loaded\n",
      "Creating bottleneck features for batch 407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 407/782 [11:55<10:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 407 created and saved\n",
      "\n",
      "Batch 408 loaded\n",
      "Creating bottleneck features for batch 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 408/782 [11:57<10:35,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 408 created and saved\n",
      "\n",
      "Batch 409 loaded\n",
      "Creating bottleneck features for batch 409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 409/782 [11:59<10:43,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 409 created and saved\n",
      "\n",
      "Batch 410 loaded\n",
      "Creating bottleneck features for batch 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 410/782 [12:00<10:42,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 410 created and saved\n",
      "\n",
      "Batch 411 loaded\n",
      "Creating bottleneck features for batch 411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 411/782 [12:02<10:35,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 411 created and saved\n",
      "\n",
      "Batch 412 loaded\n",
      "Creating bottleneck features for batch 412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 412/782 [12:04<10:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 412 created and saved\n",
      "\n",
      "Batch 413 loaded\n",
      "Creating bottleneck features for batch 413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 413/782 [12:05<10:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 413 created and saved\n",
      "\n",
      "Batch 414 loaded\n",
      "Creating bottleneck features for batch 414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 414/782 [12:07<10:38,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 414 created and saved\n",
      "\n",
      "Batch 415 loaded\n",
      "Creating bottleneck features for batch 415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 415/782 [12:09<10:32,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 415 created and saved\n",
      "\n",
      "Batch 416 loaded\n",
      "Creating bottleneck features for batch 416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 416/782 [12:11<10:33,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 416 created and saved\n",
      "\n",
      "Batch 417 loaded\n",
      "Creating bottleneck features for batch 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 417/782 [12:12<10:32,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 417 created and saved\n",
      "\n",
      "Batch 418 loaded\n",
      "Creating bottleneck features for batch 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 418/782 [12:14<10:34,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 418 created and saved\n",
      "\n",
      "Batch 419 loaded\n",
      "Creating bottleneck features for batch 419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 419/782 [12:16<10:25,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 419 created and saved\n",
      "\n",
      "Batch 420 loaded\n",
      "Creating bottleneck features for batch 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 420/782 [12:18<10:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 420 created and saved\n",
      "\n",
      "Batch 421 loaded\n",
      "Creating bottleneck features for batch 421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 421/782 [12:19<10:23,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 421 created and saved\n",
      "\n",
      "Batch 422 loaded\n",
      "Creating bottleneck features for batch 422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 422/782 [12:21<10:22,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 422 created and saved\n",
      "\n",
      "Batch 423 loaded\n",
      "Creating bottleneck features for batch 423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 423/782 [12:23<10:23,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 423 created and saved\n",
      "\n",
      "Batch 424 loaded\n",
      "Creating bottleneck features for batch 424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 424/782 [12:24<10:13,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 424 created and saved\n",
      "\n",
      "Batch 425 loaded\n",
      "Creating bottleneck features for batch 425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 425/782 [12:27<12:09,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 425 created and saved\n",
      "\n",
      "Batch 426 loaded\n",
      "Creating bottleneck features for batch 426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 426/782 [12:29<11:35,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 426 created and saved\n",
      "\n",
      "Batch 427 loaded\n",
      "Creating bottleneck features for batch 427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 427/782 [12:31<11:09,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 427 created and saved\n",
      "\n",
      "Batch 428 loaded\n",
      "Creating bottleneck features for batch 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 428/782 [12:33<10:51,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 428 created and saved\n",
      "\n",
      "Batch 429 loaded\n",
      "Creating bottleneck features for batch 429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 429/782 [12:34<10:41,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 429 created and saved\n",
      "\n",
      "Batch 430 loaded\n",
      "Creating bottleneck features for batch 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 430/782 [12:36<10:29,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 430 created and saved\n",
      "\n",
      "Batch 431 loaded\n",
      "Creating bottleneck features for batch 431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 431/782 [12:38<10:27,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 431 created and saved\n",
      "\n",
      "Batch 432 loaded\n",
      "Creating bottleneck features for batch 432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 432/782 [12:39<10:17,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 432 created and saved\n",
      "\n",
      "Batch 433 loaded\n",
      "Creating bottleneck features for batch 433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 433/782 [12:41<10:07,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 433 created and saved\n",
      "\n",
      "Batch 434 loaded\n",
      "Creating bottleneck features for batch 434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 434/782 [12:43<10:01,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 434 created and saved\n",
      "\n",
      "Batch 435 loaded\n",
      "Creating bottleneck features for batch 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 435/782 [12:45<09:59,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 435 created and saved\n",
      "\n",
      "Batch 436 loaded\n",
      "Creating bottleneck features for batch 436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 436/782 [12:46<09:52,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 436 created and saved\n",
      "\n",
      "Batch 437 loaded\n",
      "Creating bottleneck features for batch 437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 437/782 [12:48<09:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 437 created and saved\n",
      "\n",
      "Batch 438 loaded\n",
      "Creating bottleneck features for batch 438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 438/782 [12:50<09:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 438 created and saved\n",
      "\n",
      "Batch 439 loaded\n",
      "Creating bottleneck features for batch 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 439/782 [12:51<09:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 439 created and saved\n",
      "\n",
      "Batch 440 loaded\n",
      "Creating bottleneck features for batch 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 440/782 [12:53<09:56,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 440 created and saved\n",
      "\n",
      "Batch 441 loaded\n",
      "Creating bottleneck features for batch 441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 441/782 [12:55<09:47,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 441 created and saved\n",
      "\n",
      "Batch 442 loaded\n",
      "Creating bottleneck features for batch 442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 442/782 [12:57<09:46,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 442 created and saved\n",
      "\n",
      "Batch 443 loaded\n",
      "Creating bottleneck features for batch 443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 443/782 [12:58<09:51,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 443 created and saved\n",
      "\n",
      "Batch 444 loaded\n",
      "Creating bottleneck features for batch 444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 444/782 [13:00<09:46,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 444 created and saved\n",
      "\n",
      "Batch 445 loaded\n",
      "Creating bottleneck features for batch 445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 445/782 [13:02<09:45,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 445 created and saved\n",
      "\n",
      "Batch 446 loaded\n",
      "Creating bottleneck features for batch 446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 446/782 [13:04<09:38,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 446 created and saved\n",
      "\n",
      "Batch 447 loaded\n",
      "Creating bottleneck features for batch 447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 447/782 [13:05<09:35,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 447 created and saved\n",
      "\n",
      "Batch 448 loaded\n",
      "Creating bottleneck features for batch 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 448/782 [13:07<09:37,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 448 created and saved\n",
      "\n",
      "Batch 449 loaded\n",
      "Creating bottleneck features for batch 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 449/782 [13:09<09:38,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 449 created and saved\n",
      "\n",
      "Batch 450 loaded\n",
      "Creating bottleneck features for batch 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 450/782 [13:11<09:40,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 450 created and saved\n",
      "\n",
      "Batch 451 loaded\n",
      "Creating bottleneck features for batch 451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 451/782 [13:12<09:31,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 451 created and saved\n",
      "\n",
      "Batch 452 loaded\n",
      "Creating bottleneck features for batch 452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 452/782 [13:14<09:29,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 452 created and saved\n",
      "\n",
      "Batch 453 loaded\n",
      "Creating bottleneck features for batch 453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 453/782 [13:16<09:25,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 453 created and saved\n",
      "\n",
      "Batch 454 loaded\n",
      "Creating bottleneck features for batch 454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 454/782 [13:17<09:21,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 454 created and saved\n",
      "\n",
      "Batch 455 loaded\n",
      "Creating bottleneck features for batch 455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 455/782 [13:19<09:17,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 455 created and saved\n",
      "\n",
      "Batch 456 loaded\n",
      "Creating bottleneck features for batch 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 456/782 [13:21<09:09,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 456 created and saved\n",
      "\n",
      "Batch 457 loaded\n",
      "Creating bottleneck features for batch 457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 457/782 [13:22<09:09,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 457 created and saved\n",
      "\n",
      "Batch 458 loaded\n",
      "Creating bottleneck features for batch 458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 458/782 [13:24<09:09,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 458 created and saved\n",
      "\n",
      "Batch 459 loaded\n",
      "Creating bottleneck features for batch 459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 459/782 [13:26<09:05,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 459 created and saved\n",
      "\n",
      "Batch 460 loaded\n",
      "Creating bottleneck features for batch 460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 460/782 [13:27<09:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 460 created and saved\n",
      "\n",
      "Batch 461 loaded\n",
      "Creating bottleneck features for batch 461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 461/782 [13:29<09:14,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 461 created and saved\n",
      "\n",
      "Batch 462 loaded\n",
      "Creating bottleneck features for batch 462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 462/782 [13:31<09:07,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 462 created and saved\n",
      "\n",
      "Batch 463 loaded\n",
      "Creating bottleneck features for batch 463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 463/782 [13:33<09:04,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 463 created and saved\n",
      "\n",
      "Batch 464 loaded\n",
      "Creating bottleneck features for batch 464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 464/782 [13:34<09:07,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 464 created and saved\n",
      "\n",
      "Batch 465 loaded\n",
      "Creating bottleneck features for batch 465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 465/782 [13:36<09:01,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 465 created and saved\n",
      "\n",
      "Batch 466 loaded\n",
      "Creating bottleneck features for batch 466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 466/782 [13:38<09:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 466 created and saved\n",
      "\n",
      "Batch 467 loaded\n",
      "Creating bottleneck features for batch 467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 467/782 [13:39<08:54,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 467 created and saved\n",
      "\n",
      "Batch 468 loaded\n",
      "Creating bottleneck features for batch 468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 468/782 [13:41<08:55,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 468 created and saved\n",
      "\n",
      "Batch 469 loaded\n",
      "Creating bottleneck features for batch 469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 469/782 [13:43<09:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 469 created and saved\n",
      "\n",
      "Batch 470 loaded\n",
      "Creating bottleneck features for batch 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 470/782 [13:45<08:56,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 470 created and saved\n",
      "\n",
      "Batch 471 loaded\n",
      "Creating bottleneck features for batch 471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 471/782 [13:46<08:53,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 471 created and saved\n",
      "\n",
      "Batch 472 loaded\n",
      "Creating bottleneck features for batch 472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 472/782 [13:48<08:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 472 created and saved\n",
      "\n",
      "Batch 473 loaded\n",
      "Creating bottleneck features for batch 473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 473/782 [13:50<08:39,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 473 created and saved\n",
      "\n",
      "Batch 474 loaded\n",
      "Creating bottleneck features for batch 474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 474/782 [13:51<08:34,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 474 created and saved\n",
      "\n",
      "Batch 475 loaded\n",
      "Creating bottleneck features for batch 475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 475/782 [13:53<08:42,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 475 created and saved\n",
      "\n",
      "Batch 476 loaded\n",
      "Creating bottleneck features for batch 476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 476/782 [13:55<08:40,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 476 created and saved\n",
      "\n",
      "Batch 477 loaded\n",
      "Creating bottleneck features for batch 477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 477/782 [13:57<08:42,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 477 created and saved\n",
      "\n",
      "Batch 478 loaded\n",
      "Creating bottleneck features for batch 478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 478/782 [13:58<08:44,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 478 created and saved\n",
      "\n",
      "Batch 479 loaded\n",
      "Creating bottleneck features for batch 479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████▏   | 479/782 [14:00<08:38,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 479 created and saved\n",
      "\n",
      "Batch 480 loaded\n",
      "Creating bottleneck features for batch 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████▏   | 480/782 [14:02<08:41,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 480 created and saved\n",
      "\n",
      "Batch 481 loaded\n",
      "Creating bottleneck features for batch 481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 481/782 [14:03<08:39,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 481 created and saved\n",
      "\n",
      "Batch 482 loaded\n",
      "Creating bottleneck features for batch 482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 482/782 [14:05<08:33,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 482 created and saved\n",
      "\n",
      "Batch 483 loaded\n",
      "Creating bottleneck features for batch 483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 483/782 [14:07<08:29,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 483 created and saved\n",
      "\n",
      "Batch 484 loaded\n",
      "Creating bottleneck features for batch 484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 484/782 [14:09<08:32,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 484 created and saved\n",
      "\n",
      "Batch 485 loaded\n",
      "Creating bottleneck features for batch 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 485/782 [14:10<08:27,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 485 created and saved\n",
      "\n",
      "Batch 486 loaded\n",
      "Creating bottleneck features for batch 486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 486/782 [14:12<08:30,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 486 created and saved\n",
      "\n",
      "Batch 487 loaded\n",
      "Creating bottleneck features for batch 487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 487/782 [14:14<08:22,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 487 created and saved\n",
      "\n",
      "Batch 488 loaded\n",
      "Creating bottleneck features for batch 488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 488/782 [14:15<08:24,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 488 created and saved\n",
      "\n",
      "Batch 489 loaded\n",
      "Creating bottleneck features for batch 489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 489/782 [14:17<08:27,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 489 created and saved\n",
      "\n",
      "Batch 490 loaded\n",
      "Creating bottleneck features for batch 490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 490/782 [14:19<08:27,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 490 created and saved\n",
      "\n",
      "Batch 491 loaded\n",
      "Creating bottleneck features for batch 491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 491/782 [14:21<08:17,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 491 created and saved\n",
      "\n",
      "Batch 492 loaded\n",
      "Creating bottleneck features for batch 492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 492/782 [14:22<08:11,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 492 created and saved\n",
      "\n",
      "Batch 493 loaded\n",
      "Creating bottleneck features for batch 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 493/782 [14:24<08:01,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 493 created and saved\n",
      "\n",
      "Batch 494 loaded\n",
      "Creating bottleneck features for batch 494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 494/782 [14:26<08:04,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 494 created and saved\n",
      "\n",
      "Batch 495 loaded\n",
      "Creating bottleneck features for batch 495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 495/782 [14:27<08:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 495 created and saved\n",
      "\n",
      "Batch 496 loaded\n",
      "Creating bottleneck features for batch 496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 496/782 [14:29<08:08,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 496 created and saved\n",
      "\n",
      "Batch 497 loaded\n",
      "Creating bottleneck features for batch 497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 497/782 [14:31<08:08,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 497 created and saved\n",
      "\n",
      "Batch 498 loaded\n",
      "Creating bottleneck features for batch 498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 498/782 [14:32<08:06,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 498 created and saved\n",
      "\n",
      "Batch 499 loaded\n",
      "Creating bottleneck features for batch 499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 499/782 [14:34<07:59,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 499 created and saved\n",
      "\n",
      "Batch 500 loaded\n",
      "Creating bottleneck features for batch 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 500/782 [14:36<08:01,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 500 created and saved\n",
      "\n",
      "Batch 501 loaded\n",
      "Creating bottleneck features for batch 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 501/782 [14:38<07:59,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 501 created and saved\n",
      "\n",
      "Batch 502 loaded\n",
      "Creating bottleneck features for batch 502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 502/782 [14:39<08:01,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 502 created and saved\n",
      "\n",
      "Batch 503 loaded\n",
      "Creating bottleneck features for batch 503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 503/782 [14:41<08:05,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 503 created and saved\n",
      "\n",
      "Batch 504 loaded\n",
      "Creating bottleneck features for batch 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 504/782 [14:43<08:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 504 created and saved\n",
      "\n",
      "Batch 505 loaded\n",
      "Creating bottleneck features for batch 505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 505/782 [14:45<08:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 505 created and saved\n",
      "\n",
      "Batch 506 loaded\n",
      "Creating bottleneck features for batch 506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 506/782 [14:46<07:56,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 506 created and saved\n",
      "\n",
      "Batch 507 loaded\n",
      "Creating bottleneck features for batch 507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 507/782 [14:48<07:50,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 507 created and saved\n",
      "\n",
      "Batch 508 loaded\n",
      "Creating bottleneck features for batch 508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 508/782 [14:50<07:44,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 508 created and saved\n",
      "\n",
      "Batch 509 loaded\n",
      "Creating bottleneck features for batch 509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 509/782 [14:51<07:42,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 509 created and saved\n",
      "\n",
      "Batch 510 loaded\n",
      "Creating bottleneck features for batch 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 510/782 [14:53<07:41,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 510 created and saved\n",
      "\n",
      "Batch 511 loaded\n",
      "Creating bottleneck features for batch 511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 511/782 [14:55<07:39,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 511 created and saved\n",
      "\n",
      "Batch 512 loaded\n",
      "Creating bottleneck features for batch 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 512/782 [14:56<07:42,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 512 created and saved\n",
      "\n",
      "Batch 513 loaded\n",
      "Creating bottleneck features for batch 513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 513/782 [14:58<07:36,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 513 created and saved\n",
      "\n",
      "Batch 514 loaded\n",
      "Creating bottleneck features for batch 514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 514/782 [15:00<07:40,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 514 created and saved\n",
      "\n",
      "Batch 515 loaded\n",
      "Creating bottleneck features for batch 515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 515/782 [15:02<07:36,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 515 created and saved\n",
      "\n",
      "Batch 516 loaded\n",
      "Creating bottleneck features for batch 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 516/782 [15:03<07:35,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 516 created and saved\n",
      "\n",
      "Batch 517 loaded\n",
      "Creating bottleneck features for batch 517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 517/782 [15:05<07:31,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 517 created and saved\n",
      "\n",
      "Batch 518 loaded\n",
      "Creating bottleneck features for batch 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 518/782 [15:07<07:27,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 518 created and saved\n",
      "\n",
      "Batch 519 loaded\n",
      "Creating bottleneck features for batch 519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 519/782 [15:08<07:28,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 519 created and saved\n",
      "\n",
      "Batch 520 loaded\n",
      "Creating bottleneck features for batch 520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 520/782 [15:10<07:26,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 520 created and saved\n",
      "\n",
      "Batch 521 loaded\n",
      "Creating bottleneck features for batch 521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 521/782 [15:12<07:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 521 created and saved\n",
      "\n",
      "Batch 522 loaded\n",
      "Creating bottleneck features for batch 522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 522/782 [15:13<07:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 522 created and saved\n",
      "\n",
      "Batch 523 loaded\n",
      "Creating bottleneck features for batch 523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 523/782 [15:15<07:17,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 523 created and saved\n",
      "\n",
      "Batch 524 loaded\n",
      "Creating bottleneck features for batch 524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 524/782 [15:17<07:15,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 524 created and saved\n",
      "\n",
      "Batch 525 loaded\n",
      "Creating bottleneck features for batch 525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 525/782 [15:18<07:15,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 525 created and saved\n",
      "\n",
      "Batch 526 loaded\n",
      "Creating bottleneck features for batch 526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 526/782 [15:20<07:19,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 526 created and saved\n",
      "\n",
      "Batch 527 loaded\n",
      "Creating bottleneck features for batch 527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 527/782 [15:22<07:13,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 527 created and saved\n",
      "\n",
      "Batch 528 loaded\n",
      "Creating bottleneck features for batch 528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 528/782 [15:24<07:12,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 528 created and saved\n",
      "\n",
      "Batch 529 loaded\n",
      "Creating bottleneck features for batch 529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 529/782 [15:25<07:17,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 529 created and saved\n",
      "\n",
      "Batch 530 loaded\n",
      "Creating bottleneck features for batch 530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 530/782 [15:27<07:14,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 530 created and saved\n",
      "\n",
      "Batch 531 loaded\n",
      "Creating bottleneck features for batch 531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 531/782 [15:29<07:06,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 531 created and saved\n",
      "\n",
      "Batch 532 loaded\n",
      "Creating bottleneck features for batch 532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 532/782 [15:31<07:08,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 532 created and saved\n",
      "\n",
      "Batch 533 loaded\n",
      "Creating bottleneck features for batch 533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 533/782 [15:32<07:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 533 created and saved\n",
      "\n",
      "Batch 534 loaded\n",
      "Creating bottleneck features for batch 534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 534/782 [15:34<07:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 534 created and saved\n",
      "\n",
      "Batch 535 loaded\n",
      "Creating bottleneck features for batch 535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 535/782 [15:36<07:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 535 created and saved\n",
      "\n",
      "Batch 536 loaded\n",
      "Creating bottleneck features for batch 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 536/782 [15:37<07:06,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 536 created and saved\n",
      "\n",
      "Batch 537 loaded\n",
      "Creating bottleneck features for batch 537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 537/782 [15:39<07:04,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 537 created and saved\n",
      "\n",
      "Batch 538 loaded\n",
      "Creating bottleneck features for batch 538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 538/782 [15:41<07:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 538 created and saved\n",
      "\n",
      "Batch 539 loaded\n",
      "Creating bottleneck features for batch 539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 539/782 [15:43<06:57,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 539 created and saved\n",
      "\n",
      "Batch 540 loaded\n",
      "Creating bottleneck features for batch 540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 540/782 [15:44<06:51,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 540 created and saved\n",
      "\n",
      "Batch 541 loaded\n",
      "Creating bottleneck features for batch 541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 541/782 [15:46<06:54,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 541 created and saved\n",
      "\n",
      "Batch 542 loaded\n",
      "Creating bottleneck features for batch 542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 542/782 [15:48<06:51,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 542 created and saved\n",
      "\n",
      "Batch 543 loaded\n",
      "Creating bottleneck features for batch 543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 543/782 [15:49<06:50,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 543 created and saved\n",
      "\n",
      "Batch 544 loaded\n",
      "Creating bottleneck features for batch 544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 544/782 [15:51<06:50,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 544 created and saved\n",
      "\n",
      "Batch 545 loaded\n",
      "Creating bottleneck features for batch 545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 545/782 [15:53<06:45,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 545 created and saved\n",
      "\n",
      "Batch 546 loaded\n",
      "Creating bottleneck features for batch 546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 546/782 [15:55<06:41,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 546 created and saved\n",
      "\n",
      "Batch 547 loaded\n",
      "Creating bottleneck features for batch 547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 547/782 [15:56<06:39,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 547 created and saved\n",
      "\n",
      "Batch 548 loaded\n",
      "Creating bottleneck features for batch 548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 548/782 [15:58<06:38,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 548 created and saved\n",
      "\n",
      "Batch 549 loaded\n",
      "Creating bottleneck features for batch 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 549/782 [16:00<06:35,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 549 created and saved\n",
      "\n",
      "Batch 550 loaded\n",
      "Creating bottleneck features for batch 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 550/782 [16:01<06:30,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 550 created and saved\n",
      "\n",
      "Batch 551 loaded\n",
      "Creating bottleneck features for batch 551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 551/782 [16:03<06:25,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 551 created and saved\n",
      "\n",
      "Batch 552 loaded\n",
      "Creating bottleneck features for batch 552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 552/782 [16:05<06:29,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 552 created and saved\n",
      "\n",
      "Batch 553 loaded\n",
      "Creating bottleneck features for batch 553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 553/782 [16:06<06:24,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 553 created and saved\n",
      "\n",
      "Batch 554 loaded\n",
      "Creating bottleneck features for batch 554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 554/782 [16:08<06:28,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 554 created and saved\n",
      "\n",
      "Batch 555 loaded\n",
      "Creating bottleneck features for batch 555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 555/782 [16:10<06:31,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 555 created and saved\n",
      "\n",
      "Batch 556 loaded\n",
      "Creating bottleneck features for batch 556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 556/782 [16:11<06:26,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 556 created and saved\n",
      "\n",
      "Batch 557 loaded\n",
      "Creating bottleneck features for batch 557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 557/782 [16:13<06:26,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 557 created and saved\n",
      "\n",
      "Batch 558 loaded\n",
      "Creating bottleneck features for batch 558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 558/782 [16:15<06:27,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 558 created and saved\n",
      "\n",
      "Batch 559 loaded\n",
      "Creating bottleneck features for batch 559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 559/782 [16:17<06:28,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 559 created and saved\n",
      "\n",
      "Batch 560 loaded\n",
      "Creating bottleneck features for batch 560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 560/782 [16:18<06:25,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 560 created and saved\n",
      "\n",
      "Batch 561 loaded\n",
      "Creating bottleneck features for batch 561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 561/782 [16:20<06:20,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 561 created and saved\n",
      "\n",
      "Batch 562 loaded\n",
      "Creating bottleneck features for batch 562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 562/782 [16:22<06:20,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 562 created and saved\n",
      "\n",
      "Batch 563 loaded\n",
      "Creating bottleneck features for batch 563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 563/782 [16:24<06:14,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 563 created and saved\n",
      "\n",
      "Batch 564 loaded\n",
      "Creating bottleneck features for batch 564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 564/782 [16:25<06:11,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 564 created and saved\n",
      "\n",
      "Batch 565 loaded\n",
      "Creating bottleneck features for batch 565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 565/782 [16:27<06:10,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 565 created and saved\n",
      "\n",
      "Batch 566 loaded\n",
      "Creating bottleneck features for batch 566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 566/782 [16:29<06:08,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 566 created and saved\n",
      "\n",
      "Batch 567 loaded\n",
      "Creating bottleneck features for batch 567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 567/782 [16:30<06:06,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 567 created and saved\n",
      "\n",
      "Batch 568 loaded\n",
      "Creating bottleneck features for batch 568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 568/782 [16:32<06:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 568 created and saved\n",
      "\n",
      "Batch 569 loaded\n",
      "Creating bottleneck features for batch 569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 569/782 [16:34<06:04,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 569 created and saved\n",
      "\n",
      "Batch 570 loaded\n",
      "Creating bottleneck features for batch 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 570/782 [16:36<06:24,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 570 created and saved\n",
      "\n",
      "Batch 571 loaded\n",
      "Creating bottleneck features for batch 571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 571/782 [16:38<06:18,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 571 created and saved\n",
      "\n",
      "Batch 572 loaded\n",
      "Creating bottleneck features for batch 572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 572/782 [16:39<06:12,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 572 created and saved\n",
      "\n",
      "Batch 573 loaded\n",
      "Creating bottleneck features for batch 573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 573/782 [16:41<06:08,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 573 created and saved\n",
      "\n",
      "Batch 574 loaded\n",
      "Creating bottleneck features for batch 574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 574/782 [16:43<06:02,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 574 created and saved\n",
      "\n",
      "Batch 575 loaded\n",
      "Creating bottleneck features for batch 575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 575/782 [16:45<06:05,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 575 created and saved\n",
      "\n",
      "Batch 576 loaded\n",
      "Creating bottleneck features for batch 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 576/782 [16:46<06:02,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 576 created and saved\n",
      "\n",
      "Batch 577 loaded\n",
      "Creating bottleneck features for batch 577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 577/782 [16:48<06:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 577 created and saved\n",
      "\n",
      "Batch 578 loaded\n",
      "Creating bottleneck features for batch 578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 578/782 [16:50<05:59,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 578 created and saved\n",
      "\n",
      "Batch 579 loaded\n",
      "Creating bottleneck features for batch 579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 579/782 [16:52<05:55,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 579 created and saved\n",
      "\n",
      "Batch 580 loaded\n",
      "Creating bottleneck features for batch 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 580/782 [16:53<05:51,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 580 created and saved\n",
      "\n",
      "Batch 581 loaded\n",
      "Creating bottleneck features for batch 581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 581/782 [16:55<05:46,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 581 created and saved\n",
      "\n",
      "Batch 582 loaded\n",
      "Creating bottleneck features for batch 582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 582/782 [16:57<05:48,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 582 created and saved\n",
      "\n",
      "Batch 583 loaded\n",
      "Creating bottleneck features for batch 583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 583/782 [16:58<05:45,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 583 created and saved\n",
      "\n",
      "Batch 584 loaded\n",
      "Creating bottleneck features for batch 584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 584/782 [17:00<05:41,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 584 created and saved\n",
      "\n",
      "Batch 585 loaded\n",
      "Creating bottleneck features for batch 585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 585/782 [17:02<05:38,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 585 created and saved\n",
      "\n",
      "Batch 586 loaded\n",
      "Creating bottleneck features for batch 586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 586/782 [17:04<05:33,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 586 created and saved\n",
      "\n",
      "Batch 587 loaded\n",
      "Creating bottleneck features for batch 587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 587/782 [17:05<05:33,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 587 created and saved\n",
      "\n",
      "Batch 588 loaded\n",
      "Creating bottleneck features for batch 588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 588/782 [17:07<05:46,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 588 created and saved\n",
      "\n",
      "Batch 589 loaded\n",
      "Creating bottleneck features for batch 589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 589/782 [17:09<05:39,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 589 created and saved\n",
      "\n",
      "Batch 590 loaded\n",
      "Creating bottleneck features for batch 590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 590/782 [17:11<05:37,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 590 created and saved\n",
      "\n",
      "Batch 591 loaded\n",
      "Creating bottleneck features for batch 591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 591/782 [17:12<05:33,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 591 created and saved\n",
      "\n",
      "Batch 592 loaded\n",
      "Creating bottleneck features for batch 592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 592/782 [17:14<05:27,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 592 created and saved\n",
      "\n",
      "Batch 593 loaded\n",
      "Creating bottleneck features for batch 593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 593/782 [17:16<05:23,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 593 created and saved\n",
      "\n",
      "Batch 594 loaded\n",
      "Creating bottleneck features for batch 594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 594/782 [17:17<05:18,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 594 created and saved\n",
      "\n",
      "Batch 595 loaded\n",
      "Creating bottleneck features for batch 595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 595/782 [17:19<05:19,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 595 created and saved\n",
      "\n",
      "Batch 596 loaded\n",
      "Creating bottleneck features for batch 596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 596/782 [17:21<05:21,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 596 created and saved\n",
      "\n",
      "Batch 597 loaded\n",
      "Creating bottleneck features for batch 597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 597/782 [17:23<05:15,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 597 created and saved\n",
      "\n",
      "Batch 598 loaded\n",
      "Creating bottleneck features for batch 598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 598/782 [17:24<05:17,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 598 created and saved\n",
      "\n",
      "Batch 599 loaded\n",
      "Creating bottleneck features for batch 599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 599/782 [17:26<05:18,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 599 created and saved\n",
      "\n",
      "Batch 600 loaded\n",
      "Creating bottleneck features for batch 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 600/782 [17:28<05:13,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 600 created and saved\n",
      "\n",
      "Batch 601 loaded\n",
      "Creating bottleneck features for batch 601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 601/782 [17:30<05:10,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 601 created and saved\n",
      "\n",
      "Batch 602 loaded\n",
      "Creating bottleneck features for batch 602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 602/782 [17:31<05:07,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 602 created and saved\n",
      "\n",
      "Batch 603 loaded\n",
      "Creating bottleneck features for batch 603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 603/782 [17:33<05:04,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 603 created and saved\n",
      "\n",
      "Batch 604 loaded\n",
      "Creating bottleneck features for batch 604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 604/782 [17:35<05:05,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 604 created and saved\n",
      "\n",
      "Batch 605 loaded\n",
      "Creating bottleneck features for batch 605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 605/782 [17:36<05:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 605 created and saved\n",
      "\n",
      "Batch 606 loaded\n",
      "Creating bottleneck features for batch 606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 606/782 [17:38<05:22,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 606 created and saved\n",
      "\n",
      "Batch 607 loaded\n",
      "Creating bottleneck features for batch 607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 607/782 [17:40<05:11,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 607 created and saved\n",
      "\n",
      "Batch 608 loaded\n",
      "Creating bottleneck features for batch 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 608/782 [17:42<05:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 608 created and saved\n",
      "\n",
      "Batch 609 loaded\n",
      "Creating bottleneck features for batch 609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 609/782 [17:44<05:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 609 created and saved\n",
      "\n",
      "Batch 610 loaded\n",
      "Creating bottleneck features for batch 610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 610/782 [17:45<04:55,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 610 created and saved\n",
      "\n",
      "Batch 611 loaded\n",
      "Creating bottleneck features for batch 611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 611/782 [17:47<04:53,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 611 created and saved\n",
      "\n",
      "Batch 612 loaded\n",
      "Creating bottleneck features for batch 612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 612/782 [17:49<04:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 612 created and saved\n",
      "\n",
      "Batch 613 loaded\n",
      "Creating bottleneck features for batch 613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 613/782 [17:50<04:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 613 created and saved\n",
      "\n",
      "Batch 614 loaded\n",
      "Creating bottleneck features for batch 614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 614/782 [17:52<04:45,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 614 created and saved\n",
      "\n",
      "Batch 615 loaded\n",
      "Creating bottleneck features for batch 615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 615/782 [17:54<04:44,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 615 created and saved\n",
      "\n",
      "Batch 616 loaded\n",
      "Creating bottleneck features for batch 616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 616/782 [17:55<04:41,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 616 created and saved\n",
      "\n",
      "Batch 617 loaded\n",
      "Creating bottleneck features for batch 617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 617/782 [17:57<04:43,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 617 created and saved\n",
      "\n",
      "Batch 618 loaded\n",
      "Creating bottleneck features for batch 618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 618/782 [17:59<04:38,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 618 created and saved\n",
      "\n",
      "Batch 619 loaded\n",
      "Creating bottleneck features for batch 619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 619/782 [18:01<04:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 619 created and saved\n",
      "\n",
      "Batch 620 loaded\n",
      "Creating bottleneck features for batch 620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 620/782 [18:02<04:36,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 620 created and saved\n",
      "\n",
      "Batch 621 loaded\n",
      "Creating bottleneck features for batch 621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 621/782 [18:04<04:35,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 621 created and saved\n",
      "\n",
      "Batch 622 loaded\n",
      "Creating bottleneck features for batch 622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 622/782 [18:06<04:31,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 622 created and saved\n",
      "\n",
      "Batch 623 loaded\n",
      "Creating bottleneck features for batch 623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 623/782 [18:07<04:29,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 623 created and saved\n",
      "\n",
      "Batch 624 loaded\n",
      "Creating bottleneck features for batch 624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 624/782 [18:09<04:38,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 624 created and saved\n",
      "\n",
      "Batch 625 loaded\n",
      "Creating bottleneck features for batch 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 625/782 [18:11<04:37,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 625 created and saved\n",
      "\n",
      "Batch 626 loaded\n",
      "Creating bottleneck features for batch 626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 626/782 [18:13<04:30,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 626 created and saved\n",
      "\n",
      "Batch 627 loaded\n",
      "Creating bottleneck features for batch 627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 627/782 [18:14<04:27,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 627 created and saved\n",
      "\n",
      "Batch 628 loaded\n",
      "Creating bottleneck features for batch 628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 628/782 [18:16<04:26,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 628 created and saved\n",
      "\n",
      "Batch 629 loaded\n",
      "Creating bottleneck features for batch 629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 629/782 [18:18<04:22,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 629 created and saved\n",
      "\n",
      "Batch 630 loaded\n",
      "Creating bottleneck features for batch 630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 630/782 [18:20<04:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 630 created and saved\n",
      "\n",
      "Batch 631 loaded\n",
      "Creating bottleneck features for batch 631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 631/782 [18:21<04:19,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 631 created and saved\n",
      "\n",
      "Batch 632 loaded\n",
      "Creating bottleneck features for batch 632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 632/782 [18:23<04:14,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 632 created and saved\n",
      "\n",
      "Batch 633 loaded\n",
      "Creating bottleneck features for batch 633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 633/782 [18:25<04:14,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 633 created and saved\n",
      "\n",
      "Batch 634 loaded\n",
      "Creating bottleneck features for batch 634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 634/782 [18:27<04:19,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 634 created and saved\n",
      "\n",
      "Batch 635 loaded\n",
      "Creating bottleneck features for batch 635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 635/782 [18:28<04:14,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 635 created and saved\n",
      "\n",
      "Batch 636 loaded\n",
      "Creating bottleneck features for batch 636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 636/782 [18:30<04:12,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 636 created and saved\n",
      "\n",
      "Batch 637 loaded\n",
      "Creating bottleneck features for batch 637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 637/782 [18:32<04:10,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 637 created and saved\n",
      "\n",
      "Batch 638 loaded\n",
      "Creating bottleneck features for batch 638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 638/782 [18:33<04:11,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 638 created and saved\n",
      "\n",
      "Batch 639 loaded\n",
      "Creating bottleneck features for batch 639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 639/782 [18:35<04:05,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 639 created and saved\n",
      "\n",
      "Batch 640 loaded\n",
      "Creating bottleneck features for batch 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 640/782 [18:37<04:06,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 640 created and saved\n",
      "\n",
      "Batch 641 loaded\n",
      "Creating bottleneck features for batch 641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 641/782 [18:39<04:06,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 641 created and saved\n",
      "\n",
      "Batch 642 loaded\n",
      "Creating bottleneck features for batch 642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 642/782 [18:40<04:01,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 642 created and saved\n",
      "\n",
      "Batch 643 loaded\n",
      "Creating bottleneck features for batch 643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 643/782 [18:42<03:59,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 643 created and saved\n",
      "\n",
      "Batch 644 loaded\n",
      "Creating bottleneck features for batch 644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 644/782 [18:44<03:58,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 644 created and saved\n",
      "\n",
      "Batch 645 loaded\n",
      "Creating bottleneck features for batch 645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 645/782 [18:45<03:55,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 645 created and saved\n",
      "\n",
      "Batch 646 loaded\n",
      "Creating bottleneck features for batch 646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 646/782 [18:48<04:42,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 646 created and saved\n",
      "\n",
      "Batch 647 loaded\n",
      "Creating bottleneck features for batch 647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 647/782 [18:50<04:23,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 647 created and saved\n",
      "\n",
      "Batch 648 loaded\n",
      "Creating bottleneck features for batch 648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 648/782 [18:52<04:10,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 648 created and saved\n",
      "\n",
      "Batch 649 loaded\n",
      "Creating bottleneck features for batch 649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 649/782 [18:53<04:02,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 649 created and saved\n",
      "\n",
      "Batch 650 loaded\n",
      "Creating bottleneck features for batch 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 650/782 [18:55<03:57,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 650 created and saved\n",
      "\n",
      "Batch 651 loaded\n",
      "Creating bottleneck features for batch 651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 651/782 [18:57<03:51,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 651 created and saved\n",
      "\n",
      "Batch 652 loaded\n",
      "Creating bottleneck features for batch 652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 652/782 [18:59<03:48,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 652 created and saved\n",
      "\n",
      "Batch 653 loaded\n",
      "Creating bottleneck features for batch 653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 653/782 [19:00<03:43,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 653 created and saved\n",
      "\n",
      "Batch 654 loaded\n",
      "Creating bottleneck features for batch 654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 654/782 [19:02<03:39,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 654 created and saved\n",
      "\n",
      "Batch 655 loaded\n",
      "Creating bottleneck features for batch 655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 655/782 [19:04<03:35,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 655 created and saved\n",
      "\n",
      "Batch 656 loaded\n",
      "Creating bottleneck features for batch 656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 656/782 [19:05<03:35,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 656 created and saved\n",
      "\n",
      "Batch 657 loaded\n",
      "Creating bottleneck features for batch 657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 657/782 [19:07<03:33,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 657 created and saved\n",
      "\n",
      "Batch 658 loaded\n",
      "Creating bottleneck features for batch 658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 658/782 [19:09<03:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 658 created and saved\n",
      "\n",
      "Batch 659 loaded\n",
      "Creating bottleneck features for batch 659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 659/782 [19:11<03:30,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 659 created and saved\n",
      "\n",
      "Batch 660 loaded\n",
      "Creating bottleneck features for batch 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 660/782 [19:12<03:30,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 660 created and saved\n",
      "\n",
      "Batch 661 loaded\n",
      "Creating bottleneck features for batch 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 661/782 [19:14<03:28,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 661 created and saved\n",
      "\n",
      "Batch 662 loaded\n",
      "Creating bottleneck features for batch 662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 662/782 [19:16<03:22,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 662 created and saved\n",
      "\n",
      "Batch 663 loaded\n",
      "Creating bottleneck features for batch 663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 663/782 [19:17<03:22,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 663 created and saved\n",
      "\n",
      "Batch 664 loaded\n",
      "Creating bottleneck features for batch 664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 664/782 [19:19<03:30,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 664 created and saved\n",
      "\n",
      "Batch 665 loaded\n",
      "Creating bottleneck features for batch 665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 665/782 [19:21<03:25,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 665 created and saved\n",
      "\n",
      "Batch 666 loaded\n",
      "Creating bottleneck features for batch 666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 666/782 [19:23<03:21,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 666 created and saved\n",
      "\n",
      "Batch 667 loaded\n",
      "Creating bottleneck features for batch 667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 667/782 [19:24<03:19,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 667 created and saved\n",
      "\n",
      "Batch 668 loaded\n",
      "Creating bottleneck features for batch 668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 668/782 [19:26<03:15,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 668 created and saved\n",
      "\n",
      "Batch 669 loaded\n",
      "Creating bottleneck features for batch 669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 669/782 [19:28<03:14,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 669 created and saved\n",
      "\n",
      "Batch 670 loaded\n",
      "Creating bottleneck features for batch 670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 670/782 [19:29<03:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 670 created and saved\n",
      "\n",
      "Batch 671 loaded\n",
      "Creating bottleneck features for batch 671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 671/782 [19:31<03:09,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 671 created and saved\n",
      "\n",
      "Batch 672 loaded\n",
      "Creating bottleneck features for batch 672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 672/782 [19:33<03:06,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 672 created and saved\n",
      "\n",
      "Batch 673 loaded\n",
      "Creating bottleneck features for batch 673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 673/782 [19:35<03:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 673 created and saved\n",
      "\n",
      "Batch 674 loaded\n",
      "Creating bottleneck features for batch 674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 674/782 [19:36<03:01,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 674 created and saved\n",
      "\n",
      "Batch 675 loaded\n",
      "Creating bottleneck features for batch 675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 675/782 [19:38<02:59,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 675 created and saved\n",
      "\n",
      "Batch 676 loaded\n",
      "Creating bottleneck features for batch 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 676/782 [19:40<02:59,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 676 created and saved\n",
      "\n",
      "Batch 677 loaded\n",
      "Creating bottleneck features for batch 677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 677/782 [19:41<02:56,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 677 created and saved\n",
      "\n",
      "Batch 678 loaded\n",
      "Creating bottleneck features for batch 678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 678/782 [19:43<02:55,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 678 created and saved\n",
      "\n",
      "Batch 679 loaded\n",
      "Creating bottleneck features for batch 679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 679/782 [19:45<02:54,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 679 created and saved\n",
      "\n",
      "Batch 680 loaded\n",
      "Creating bottleneck features for batch 680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 680/782 [19:46<02:52,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 680 created and saved\n",
      "\n",
      "Batch 681 loaded\n",
      "Creating bottleneck features for batch 681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 681/782 [19:48<02:50,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 681 created and saved\n",
      "\n",
      "Batch 682 loaded\n",
      "Creating bottleneck features for batch 682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 682/782 [19:50<02:48,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 682 created and saved\n",
      "\n",
      "Batch 683 loaded\n",
      "Creating bottleneck features for batch 683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 683/782 [19:51<02:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 683 created and saved\n",
      "\n",
      "Batch 684 loaded\n",
      "Creating bottleneck features for batch 684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 684/782 [19:53<02:45,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 684 created and saved\n",
      "\n",
      "Batch 685 loaded\n",
      "Creating bottleneck features for batch 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 685/782 [19:55<02:45,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 685 created and saved\n",
      "\n",
      "Batch 686 loaded\n",
      "Creating bottleneck features for batch 686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 686/782 [19:57<02:45,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 686 created and saved\n",
      "\n",
      "Batch 687 loaded\n",
      "Creating bottleneck features for batch 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 687/782 [19:58<02:42,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 687 created and saved\n",
      "\n",
      "Batch 688 loaded\n",
      "Creating bottleneck features for batch 688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 688/782 [20:00<02:40,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 688 created and saved\n",
      "\n",
      "Batch 689 loaded\n",
      "Creating bottleneck features for batch 689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 689/782 [20:02<02:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 689 created and saved\n",
      "\n",
      "Batch 690 loaded\n",
      "Creating bottleneck features for batch 690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 690/782 [20:03<02:36,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 690 created and saved\n",
      "\n",
      "Batch 691 loaded\n",
      "Creating bottleneck features for batch 691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 691/782 [20:05<02:34,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 691 created and saved\n",
      "\n",
      "Batch 692 loaded\n",
      "Creating bottleneck features for batch 692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 692/782 [20:07<02:33,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 692 created and saved\n",
      "\n",
      "Batch 693 loaded\n",
      "Creating bottleneck features for batch 693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 693/782 [20:08<02:31,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 693 created and saved\n",
      "\n",
      "Batch 694 loaded\n",
      "Creating bottleneck features for batch 694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 694/782 [20:10<02:29,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 694 created and saved\n",
      "\n",
      "Batch 695 loaded\n",
      "Creating bottleneck features for batch 695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 695/782 [20:12<02:28,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 695 created and saved\n",
      "\n",
      "Batch 696 loaded\n",
      "Creating bottleneck features for batch 696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 696/782 [20:14<02:25,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 696 created and saved\n",
      "\n",
      "Batch 697 loaded\n",
      "Creating bottleneck features for batch 697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 697/782 [20:15<02:23,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 697 created and saved\n",
      "\n",
      "Batch 698 loaded\n",
      "Creating bottleneck features for batch 698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 698/782 [20:17<02:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 698 created and saved\n",
      "\n",
      "Batch 699 loaded\n",
      "Creating bottleneck features for batch 699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 699/782 [20:19<02:18,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 699 created and saved\n",
      "\n",
      "Batch 700 loaded\n",
      "Creating bottleneck features for batch 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 700/782 [20:20<02:17,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 700 created and saved\n",
      "\n",
      "Batch 701 loaded\n",
      "Creating bottleneck features for batch 701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 701/782 [20:22<02:14,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 701 created and saved\n",
      "\n",
      "Batch 702 loaded\n",
      "Creating bottleneck features for batch 702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 702/782 [20:24<02:13,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 702 created and saved\n",
      "\n",
      "Batch 703 loaded\n",
      "Creating bottleneck features for batch 703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 703/782 [20:25<02:14,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 703 created and saved\n",
      "\n",
      "Batch 704 loaded\n",
      "Creating bottleneck features for batch 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 704/782 [20:27<02:14,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 704 created and saved\n",
      "\n",
      "Batch 705 loaded\n",
      "Creating bottleneck features for batch 705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 705/782 [20:29<02:13,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 705 created and saved\n",
      "\n",
      "Batch 706 loaded\n",
      "Creating bottleneck features for batch 706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 706/782 [20:31<02:10,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 706 created and saved\n",
      "\n",
      "Batch 707 loaded\n",
      "Creating bottleneck features for batch 707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 707/782 [20:32<02:08,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 707 created and saved\n",
      "\n",
      "Batch 708 loaded\n",
      "Creating bottleneck features for batch 708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 708/782 [20:34<02:06,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 708 created and saved\n",
      "\n",
      "Batch 709 loaded\n",
      "Creating bottleneck features for batch 709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 709/782 [20:36<02:07,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 709 created and saved\n",
      "\n",
      "Batch 710 loaded\n",
      "Creating bottleneck features for batch 710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 710/782 [20:38<02:05,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 710 created and saved\n",
      "\n",
      "Batch 711 loaded\n",
      "Creating bottleneck features for batch 711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 711/782 [20:39<02:02,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 711 created and saved\n",
      "\n",
      "Batch 712 loaded\n",
      "Creating bottleneck features for batch 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 712/782 [20:41<02:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 712 created and saved\n",
      "\n",
      "Batch 713 loaded\n",
      "Creating bottleneck features for batch 713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 713/782 [20:43<01:57,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 713 created and saved\n",
      "\n",
      "Batch 714 loaded\n",
      "Creating bottleneck features for batch 714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 714/782 [20:44<01:54,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 714 created and saved\n",
      "\n",
      "Batch 715 loaded\n",
      "Creating bottleneck features for batch 715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 715/782 [20:46<01:54,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 715 created and saved\n",
      "\n",
      "Batch 716 loaded\n",
      "Creating bottleneck features for batch 716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 716/782 [20:48<01:53,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 716 created and saved\n",
      "\n",
      "Batch 717 loaded\n",
      "Creating bottleneck features for batch 717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 717/782 [20:49<01:51,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 717 created and saved\n",
      "\n",
      "Batch 718 loaded\n",
      "Creating bottleneck features for batch 718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 718/782 [20:51<01:49,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 718 created and saved\n",
      "\n",
      "Batch 719 loaded\n",
      "Creating bottleneck features for batch 719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 719/782 [20:53<01:46,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 719 created and saved\n",
      "\n",
      "Batch 720 loaded\n",
      "Creating bottleneck features for batch 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 720/782 [20:54<01:45,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 720 created and saved\n",
      "\n",
      "Batch 721 loaded\n",
      "Creating bottleneck features for batch 721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 721/782 [20:56<01:43,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 721 created and saved\n",
      "\n",
      "Batch 722 loaded\n",
      "Creating bottleneck features for batch 722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 722/782 [20:58<01:41,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 722 created and saved\n",
      "\n",
      "Batch 723 loaded\n",
      "Creating bottleneck features for batch 723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 723/782 [21:00<01:39,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 723 created and saved\n",
      "\n",
      "Batch 724 loaded\n",
      "Creating bottleneck features for batch 724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 724/782 [21:01<01:38,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 724 created and saved\n",
      "\n",
      "Batch 725 loaded\n",
      "Creating bottleneck features for batch 725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 725/782 [21:03<01:36,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 725 created and saved\n",
      "\n",
      "Batch 726 loaded\n",
      "Creating bottleneck features for batch 726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 726/782 [21:05<01:35,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 726 created and saved\n",
      "\n",
      "Batch 727 loaded\n",
      "Creating bottleneck features for batch 727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 727/782 [21:06<01:34,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 727 created and saved\n",
      "\n",
      "Batch 728 loaded\n",
      "Creating bottleneck features for batch 728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 728/782 [21:08<01:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 728 created and saved\n",
      "\n",
      "Batch 729 loaded\n",
      "Creating bottleneck features for batch 729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 729/782 [21:10<01:31,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 729 created and saved\n",
      "\n",
      "Batch 730 loaded\n",
      "Creating bottleneck features for batch 730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 730/782 [21:12<01:29,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 730 created and saved\n",
      "\n",
      "Batch 731 loaded\n",
      "Creating bottleneck features for batch 731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 731/782 [21:13<01:27,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 731 created and saved\n",
      "\n",
      "Batch 732 loaded\n",
      "Creating bottleneck features for batch 732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 732/782 [21:15<01:25,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 732 created and saved\n",
      "\n",
      "Batch 733 loaded\n",
      "Creating bottleneck features for batch 733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 733/782 [21:17<01:23,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 733 created and saved\n",
      "\n",
      "Batch 734 loaded\n",
      "Creating bottleneck features for batch 734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 734/782 [21:18<01:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 734 created and saved\n",
      "\n",
      "Batch 735 loaded\n",
      "Creating bottleneck features for batch 735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 735/782 [21:20<01:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 735 created and saved\n",
      "\n",
      "Batch 736 loaded\n",
      "Creating bottleneck features for batch 736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 736/782 [21:22<01:17,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 736 created and saved\n",
      "\n",
      "Batch 737 loaded\n",
      "Creating bottleneck features for batch 737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 737/782 [21:23<01:17,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 737 created and saved\n",
      "\n",
      "Batch 738 loaded\n",
      "Creating bottleneck features for batch 738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 738/782 [21:25<01:14,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 738 created and saved\n",
      "\n",
      "Batch 739 loaded\n",
      "Creating bottleneck features for batch 739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 739/782 [21:27<01:13,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 739 created and saved\n",
      "\n",
      "Batch 740 loaded\n",
      "Creating bottleneck features for batch 740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 740/782 [21:29<01:11,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 740 created and saved\n",
      "\n",
      "Batch 741 loaded\n",
      "Creating bottleneck features for batch 741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 741/782 [21:30<01:09,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 741 created and saved\n",
      "\n",
      "Batch 742 loaded\n",
      "Creating bottleneck features for batch 742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 742/782 [21:32<01:08,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 742 created and saved\n",
      "\n",
      "Batch 743 loaded\n",
      "Creating bottleneck features for batch 743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 743/782 [21:34<01:05,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 743 created and saved\n",
      "\n",
      "Batch 744 loaded\n",
      "Creating bottleneck features for batch 744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 744/782 [21:35<01:04,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 744 created and saved\n",
      "\n",
      "Batch 745 loaded\n",
      "Creating bottleneck features for batch 745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 745/782 [21:37<01:02,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 745 created and saved\n",
      "\n",
      "Batch 746 loaded\n",
      "Creating bottleneck features for batch 746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 746/782 [21:39<01:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 746 created and saved\n",
      "\n",
      "Batch 747 loaded\n",
      "Creating bottleneck features for batch 747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 747/782 [21:40<00:59,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 747 created and saved\n",
      "\n",
      "Batch 748 loaded\n",
      "Creating bottleneck features for batch 748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 748/782 [21:42<00:57,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 748 created and saved\n",
      "\n",
      "Batch 749 loaded\n",
      "Creating bottleneck features for batch 749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 749/782 [21:44<00:56,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 749 created and saved\n",
      "\n",
      "Batch 750 loaded\n",
      "Creating bottleneck features for batch 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 750/782 [21:46<00:55,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 750 created and saved\n",
      "\n",
      "Batch 751 loaded\n",
      "Creating bottleneck features for batch 751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 751/782 [21:47<00:53,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 751 created and saved\n",
      "\n",
      "Batch 752 loaded\n",
      "Creating bottleneck features for batch 752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 752/782 [21:49<00:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 752 created and saved\n",
      "\n",
      "Batch 753 loaded\n",
      "Creating bottleneck features for batch 753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 753/782 [21:51<00:50,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 753 created and saved\n",
      "\n",
      "Batch 754 loaded\n",
      "Creating bottleneck features for batch 754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 754/782 [21:52<00:48,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 754 created and saved\n",
      "\n",
      "Batch 755 loaded\n",
      "Creating bottleneck features for batch 755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 755/782 [21:54<00:46,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 755 created and saved\n",
      "\n",
      "Batch 756 loaded\n",
      "Creating bottleneck features for batch 756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 756/782 [21:56<00:44,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 756 created and saved\n",
      "\n",
      "Batch 757 loaded\n",
      "Creating bottleneck features for batch 757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 757/782 [21:58<00:42,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 757 created and saved\n",
      "\n",
      "Batch 758 loaded\n",
      "Creating bottleneck features for batch 758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 758/782 [21:59<00:40,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 758 created and saved\n",
      "\n",
      "Batch 759 loaded\n",
      "Creating bottleneck features for batch 759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 759/782 [22:01<00:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 759 created and saved\n",
      "\n",
      "Batch 760 loaded\n",
      "Creating bottleneck features for batch 760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 760/782 [22:03<00:37,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 760 created and saved\n",
      "\n",
      "Batch 761 loaded\n",
      "Creating bottleneck features for batch 761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 761/782 [22:04<00:35,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 761 created and saved\n",
      "\n",
      "Batch 762 loaded\n",
      "Creating bottleneck features for batch 762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 762/782 [22:06<00:33,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 762 created and saved\n",
      "\n",
      "Batch 763 loaded\n",
      "Creating bottleneck features for batch 763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 763/782 [22:08<00:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 763 created and saved\n",
      "\n",
      "Batch 764 loaded\n",
      "Creating bottleneck features for batch 764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 764/782 [22:10<00:30,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 764 created and saved\n",
      "\n",
      "Batch 765 loaded\n",
      "Creating bottleneck features for batch 765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 765/782 [22:11<00:29,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 765 created and saved\n",
      "\n",
      "Batch 766 loaded\n",
      "Creating bottleneck features for batch 766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 766/782 [22:13<00:27,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 766 created and saved\n",
      "\n",
      "Batch 767 loaded\n",
      "Creating bottleneck features for batch 767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 767/782 [22:15<00:25,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 767 created and saved\n",
      "\n",
      "Batch 768 loaded\n",
      "Creating bottleneck features for batch 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 768/782 [22:16<00:23,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 768 created and saved\n",
      "\n",
      "Batch 769 loaded\n",
      "Creating bottleneck features for batch 769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 769/782 [22:18<00:21,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 769 created and saved\n",
      "\n",
      "Batch 770 loaded\n",
      "Creating bottleneck features for batch 770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 770/782 [22:20<00:20,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 770 created and saved\n",
      "\n",
      "Batch 771 loaded\n",
      "Creating bottleneck features for batch 771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 771/782 [22:21<00:18,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 771 created and saved\n",
      "\n",
      "Batch 772 loaded\n",
      "Creating bottleneck features for batch 772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 772/782 [22:23<00:16,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 772 created and saved\n",
      "\n",
      "Batch 773 loaded\n",
      "Creating bottleneck features for batch 773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 773/782 [22:25<00:15,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 773 created and saved\n",
      "\n",
      "Batch 774 loaded\n",
      "Creating bottleneck features for batch 774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 774/782 [22:26<00:13,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 774 created and saved\n",
      "\n",
      "Batch 775 loaded\n",
      "Creating bottleneck features for batch 775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 775/782 [22:28<00:11,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 775 created and saved\n",
      "\n",
      "Batch 776 loaded\n",
      "Creating bottleneck features for batch 776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 776/782 [22:30<00:10,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 776 created and saved\n",
      "\n",
      "Batch 777 loaded\n",
      "Creating bottleneck features for batch 777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 777/782 [22:32<00:08,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 777 created and saved\n",
      "\n",
      "Batch 778 loaded\n",
      "Creating bottleneck features for batch 778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 778/782 [22:33<00:06,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 778 created and saved\n",
      "\n",
      "Batch 779 loaded\n",
      "Creating bottleneck features for batch 779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 779/782 [22:35<00:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 779 created and saved\n",
      "\n",
      "Batch 780 loaded\n",
      "Creating bottleneck features for batch 780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 780/782 [22:37<00:03,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 780 created and saved\n",
      "\n",
      "Batch 781 loaded\n",
      "Creating bottleneck features for batch 781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 781/782 [22:38<00:01,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 781 created and saved\n",
      "\n",
      "Batch 782 loaded\n",
      "Creating bottleneck features for batch 782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 782/782 [22:40<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 782 created and saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#creating bottleneck features for train data using VGG-16- Image-net model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "SAVEDIR = \"./outputs_facedb/Bottleneck_Features/\"\n",
    "SAVEDIR_LABELS = \"./outputs_facedb/Bottleneck_Labels/\"\n",
    "batch_size = 10\n",
    "for i in tqdm(range(int(len(train_df)/batch_size)-1)):\n",
    "    #try:\n",
    "    x, y,_ = loadCombinedTrainBatch(batch_size)\n",
    "    print(\"Batch {} loaded\".format(i+1))\n",
    "\n",
    "    np.save(os.path.join(SAVEDIR_LABELS, \"bottleneck_labels_{}\".format(i+1)), y)\n",
    "\n",
    "    print(\"Creating bottleneck features for batch {}\". format(i+1))\n",
    "    bottleneck_features = model.predict(x)\n",
    "    np.save(os.path.join(SAVEDIR, \"bottleneck_{}\".format(i+1)), bottleneck_features)\n",
    "    print(\"Bottleneck features for batch {} created and saved\\n\".format(i+1))\n",
    "    #except:\n",
    "    #    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck features for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu1/anaconda3/envs/fer_env/lib/python3.7/site-packages/ipykernel/__main__.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1958, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestCombined_Labels = pd.get_dummies(test_df[\"labels\"]).as_matrix()\n",
    "TestCombined_Labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./data2/facedb/s017/tif/s017-02_img_aug1.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>./data2/facedb/s004/tif/s004-03_img_aug2.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>./data2/japanese_women/NA.SA1.205_aug6.tiff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>./data2/CK+_modified/sadness/S106_002_00000014...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./data2/facedb/s007/tif/s007-00_img_aug9.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               location  labels\n",
       "23         ./data2/facedb/s017/tif/s017-02_img_aug1.tif       2\n",
       "34         ./data2/facedb/s004/tif/s004-03_img_aug2.tif       3\n",
       "75          ./data2/japanese_women/NA.SA1.205_aug6.tiff       2\n",
       "9874  ./data2/CK+_modified/sadness/S106_002_00000014...       2\n",
       "10         ./data2/facedb/s007/tif/s007-00_img_aug9.tif       0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestCombined_batch_pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCombinedTestBatch(batch_size):\n",
    "    global TestCombined_batch_pointer\n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    for i in range(batch_size):\n",
    "        path1 = test_df.iloc[TestCombined_batch_pointer + i][\"location\"]\n",
    "        read_image = cv2.imread(path1)\n",
    "        read_image_final = read_image/255.0  #here, we are normalizing the images\n",
    "        batch_images.append(read_image_final)\n",
    "        \n",
    "        batch_labels.append(TestCombined_Labels[TestCombined_batch_pointer + i]) #appending corresponding labels\n",
    "        \n",
    "    TestCombined_batch_pointer += batch_size\n",
    "        \n",
    "    return np.array(batch_images), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loaded\n",
      "Creating bottleneck features for batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/194 [00:01<05:13,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 1 created and saved\n",
      "\n",
      "Batch 2 loaded\n",
      "Creating bottleneck features for batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/194 [00:03<05:15,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 2 created and saved\n",
      "\n",
      "Batch 3 loaded\n",
      "Creating bottleneck features for batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/194 [00:05<05:18,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 3 created and saved\n",
      "\n",
      "Batch 4 loaded\n",
      "Creating bottleneck features for batch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 4/194 [00:06<05:20,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 4 created and saved\n",
      "\n",
      "Batch 5 loaded\n",
      "Creating bottleneck features for batch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/194 [00:08<05:17,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 5 created and saved\n",
      "\n",
      "Batch 6 loaded\n",
      "Creating bottleneck features for batch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/194 [00:10<05:14,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 6 created and saved\n",
      "\n",
      "Batch 7 loaded\n",
      "Creating bottleneck features for batch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 7/194 [00:11<05:17,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 7 created and saved\n",
      "\n",
      "Batch 8 loaded\n",
      "Creating bottleneck features for batch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/194 [00:13<05:14,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 8 created and saved\n",
      "\n",
      "Batch 9 loaded\n",
      "Creating bottleneck features for batch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 9/194 [00:15<05:11,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 9 created and saved\n",
      "\n",
      "Batch 10 loaded\n",
      "Creating bottleneck features for batch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 10/194 [00:16<05:10,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 10 created and saved\n",
      "\n",
      "Batch 11 loaded\n",
      "Creating bottleneck features for batch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 11/194 [00:18<05:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 11 created and saved\n",
      "\n",
      "Batch 12 loaded\n",
      "Creating bottleneck features for batch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 12/194 [00:20<05:07,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 12 created and saved\n",
      "\n",
      "Batch 13 loaded\n",
      "Creating bottleneck features for batch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 13/194 [00:21<05:07,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 13 created and saved\n",
      "\n",
      "Batch 14 loaded\n",
      "Creating bottleneck features for batch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 14/194 [00:23<05:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 14 created and saved\n",
      "\n",
      "Batch 15 loaded\n",
      "Creating bottleneck features for batch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 15/194 [00:25<05:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 15 created and saved\n",
      "\n",
      "Batch 16 loaded\n",
      "Creating bottleneck features for batch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 16/194 [00:27<05:07,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 16 created and saved\n",
      "\n",
      "Batch 17 loaded\n",
      "Creating bottleneck features for batch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 17/194 [00:28<05:02,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 17 created and saved\n",
      "\n",
      "Batch 18 loaded\n",
      "Creating bottleneck features for batch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 18/194 [00:30<04:59,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 18 created and saved\n",
      "\n",
      "Batch 19 loaded\n",
      "Creating bottleneck features for batch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 19/194 [00:32<04:59,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 19 created and saved\n",
      "\n",
      "Batch 20 loaded\n",
      "Creating bottleneck features for batch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 20/194 [00:33<04:55,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 20 created and saved\n",
      "\n",
      "Batch 21 loaded\n",
      "Creating bottleneck features for batch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 21/194 [00:35<04:53,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 21 created and saved\n",
      "\n",
      "Batch 22 loaded\n",
      "Creating bottleneck features for batch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 22/194 [00:37<04:48,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 22 created and saved\n",
      "\n",
      "Batch 23 loaded\n",
      "Creating bottleneck features for batch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 23/194 [00:38<04:48,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 23 created and saved\n",
      "\n",
      "Batch 24 loaded\n",
      "Creating bottleneck features for batch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 24/194 [00:40<04:46,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 24 created and saved\n",
      "\n",
      "Batch 25 loaded\n",
      "Creating bottleneck features for batch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 25/194 [00:42<04:46,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 25 created and saved\n",
      "\n",
      "Batch 26 loaded\n",
      "Creating bottleneck features for batch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 26/194 [00:44<04:48,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 26 created and saved\n",
      "\n",
      "Batch 27 loaded\n",
      "Creating bottleneck features for batch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 27/194 [00:45<04:47,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 27 created and saved\n",
      "\n",
      "Batch 28 loaded\n",
      "Creating bottleneck features for batch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 28/194 [00:47<04:44,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 28 created and saved\n",
      "\n",
      "Batch 29 loaded\n",
      "Creating bottleneck features for batch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 29/194 [00:49<04:42,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 29 created and saved\n",
      "\n",
      "Batch 30 loaded\n",
      "Creating bottleneck features for batch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 30/194 [00:50<04:40,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 30 created and saved\n",
      "\n",
      "Batch 31 loaded\n",
      "Creating bottleneck features for batch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 31/194 [00:52<04:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 31 created and saved\n",
      "\n",
      "Batch 32 loaded\n",
      "Creating bottleneck features for batch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 32/194 [00:54<04:52,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 32 created and saved\n",
      "\n",
      "Batch 33 loaded\n",
      "Creating bottleneck features for batch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 33/194 [00:56<04:42,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 33 created and saved\n",
      "\n",
      "Batch 34 loaded\n",
      "Creating bottleneck features for batch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 34/194 [00:58<04:38,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 34 created and saved\n",
      "\n",
      "Batch 35 loaded\n",
      "Creating bottleneck features for batch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 35/194 [00:59<04:35,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 35 created and saved\n",
      "\n",
      "Batch 36 loaded\n",
      "Creating bottleneck features for batch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 36/194 [01:01<04:32,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 36 created and saved\n",
      "\n",
      "Batch 37 loaded\n",
      "Creating bottleneck features for batch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 37/194 [01:03<04:33,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 37 created and saved\n",
      "\n",
      "Batch 38 loaded\n",
      "Creating bottleneck features for batch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 38/194 [01:04<04:28,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 38 created and saved\n",
      "\n",
      "Batch 39 loaded\n",
      "Creating bottleneck features for batch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 39/194 [01:06<04:24,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 39 created and saved\n",
      "\n",
      "Batch 40 loaded\n",
      "Creating bottleneck features for batch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 40/194 [01:08<04:23,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 40 created and saved\n",
      "\n",
      "Batch 41 loaded\n",
      "Creating bottleneck features for batch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 41/194 [01:10<04:21,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 41 created and saved\n",
      "\n",
      "Batch 42 loaded\n",
      "Creating bottleneck features for batch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 42/194 [01:11<04:19,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 42 created and saved\n",
      "\n",
      "Batch 43 loaded\n",
      "Creating bottleneck features for batch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 43/194 [01:13<04:18,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 43 created and saved\n",
      "\n",
      "Batch 44 loaded\n",
      "Creating bottleneck features for batch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 44/194 [01:15<04:15,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 44 created and saved\n",
      "\n",
      "Batch 45 loaded\n",
      "Creating bottleneck features for batch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 45/194 [01:16<04:14,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 45 created and saved\n",
      "\n",
      "Batch 46 loaded\n",
      "Creating bottleneck features for batch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 46/194 [01:18<04:11,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 46 created and saved\n",
      "\n",
      "Batch 47 loaded\n",
      "Creating bottleneck features for batch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 47/194 [01:20<04:07,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 47 created and saved\n",
      "\n",
      "Batch 48 loaded\n",
      "Creating bottleneck features for batch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 48/194 [01:21<04:06,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 48 created and saved\n",
      "\n",
      "Batch 49 loaded\n",
      "Creating bottleneck features for batch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 49/194 [01:23<04:05,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 49 created and saved\n",
      "\n",
      "Batch 50 loaded\n",
      "Creating bottleneck features for batch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 50/194 [01:25<04:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 50 created and saved\n",
      "\n",
      "Batch 51 loaded\n",
      "Creating bottleneck features for batch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 51/194 [01:27<04:03,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 51 created and saved\n",
      "\n",
      "Batch 52 loaded\n",
      "Creating bottleneck features for batch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 52/194 [01:28<04:01,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 52 created and saved\n",
      "\n",
      "Batch 53 loaded\n",
      "Creating bottleneck features for batch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 53/194 [01:30<03:59,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 53 created and saved\n",
      "\n",
      "Batch 54 loaded\n",
      "Creating bottleneck features for batch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 54/194 [01:32<03:55,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 54 created and saved\n",
      "\n",
      "Batch 55 loaded\n",
      "Creating bottleneck features for batch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 55/194 [01:33<03:57,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 55 created and saved\n",
      "\n",
      "Batch 56 loaded\n",
      "Creating bottleneck features for batch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 56/194 [01:35<03:57,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 56 created and saved\n",
      "\n",
      "Batch 57 loaded\n",
      "Creating bottleneck features for batch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 57/194 [01:37<03:54,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 57 created and saved\n",
      "\n",
      "Batch 58 loaded\n",
      "Creating bottleneck features for batch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 58/194 [01:38<03:51,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 58 created and saved\n",
      "\n",
      "Batch 59 loaded\n",
      "Creating bottleneck features for batch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 59/194 [01:40<03:49,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 59 created and saved\n",
      "\n",
      "Batch 60 loaded\n",
      "Creating bottleneck features for batch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 60/194 [01:42<03:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 60 created and saved\n",
      "\n",
      "Batch 61 loaded\n",
      "Creating bottleneck features for batch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 61/194 [01:44<03:49,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 61 created and saved\n",
      "\n",
      "Batch 62 loaded\n",
      "Creating bottleneck features for batch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 62/194 [01:45<03:49,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 62 created and saved\n",
      "\n",
      "Batch 63 loaded\n",
      "Creating bottleneck features for batch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 63/194 [01:47<03:47,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 63 created and saved\n",
      "\n",
      "Batch 64 loaded\n",
      "Creating bottleneck features for batch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 64/194 [01:49<03:42,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 64 created and saved\n",
      "\n",
      "Batch 65 loaded\n",
      "Creating bottleneck features for batch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 65/194 [01:50<03:39,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 65 created and saved\n",
      "\n",
      "Batch 66 loaded\n",
      "Creating bottleneck features for batch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 66/194 [01:53<03:59,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 66 created and saved\n",
      "\n",
      "Batch 67 loaded\n",
      "Creating bottleneck features for batch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 67/194 [01:55<03:53,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 67 created and saved\n",
      "\n",
      "Batch 68 loaded\n",
      "Creating bottleneck features for batch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 68/194 [01:56<03:45,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 68 created and saved\n",
      "\n",
      "Batch 69 loaded\n",
      "Creating bottleneck features for batch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 69/194 [01:58<03:43,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 69 created and saved\n",
      "\n",
      "Batch 70 loaded\n",
      "Creating bottleneck features for batch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 70/194 [02:00<03:41,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 70 created and saved\n",
      "\n",
      "Batch 71 loaded\n",
      "Creating bottleneck features for batch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 71/194 [02:01<03:34,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 71 created and saved\n",
      "\n",
      "Batch 72 loaded\n",
      "Creating bottleneck features for batch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 72/194 [02:03<03:32,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 72 created and saved\n",
      "\n",
      "Batch 73 loaded\n",
      "Creating bottleneck features for batch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 73/194 [02:05<03:29,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 73 created and saved\n",
      "\n",
      "Batch 74 loaded\n",
      "Creating bottleneck features for batch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 74/194 [02:07<03:26,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 74 created and saved\n",
      "\n",
      "Batch 75 loaded\n",
      "Creating bottleneck features for batch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 75/194 [02:08<03:22,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 75 created and saved\n",
      "\n",
      "Batch 76 loaded\n",
      "Creating bottleneck features for batch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 76/194 [02:10<03:20,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 76 created and saved\n",
      "\n",
      "Batch 77 loaded\n",
      "Creating bottleneck features for batch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 77/194 [02:12<03:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 77 created and saved\n",
      "\n",
      "Batch 78 loaded\n",
      "Creating bottleneck features for batch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 78/194 [02:13<03:19,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 78 created and saved\n",
      "\n",
      "Batch 79 loaded\n",
      "Creating bottleneck features for batch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 79/194 [02:15<03:18,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 79 created and saved\n",
      "\n",
      "Batch 80 loaded\n",
      "Creating bottleneck features for batch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 80/194 [02:17<03:16,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 80 created and saved\n",
      "\n",
      "Batch 81 loaded\n",
      "Creating bottleneck features for batch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 81/194 [02:18<03:12,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 81 created and saved\n",
      "\n",
      "Batch 82 loaded\n",
      "Creating bottleneck features for batch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 82/194 [02:20<03:11,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 82 created and saved\n",
      "\n",
      "Batch 83 loaded\n",
      "Creating bottleneck features for batch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 83/194 [02:22<03:09,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 83 created and saved\n",
      "\n",
      "Batch 84 loaded\n",
      "Creating bottleneck features for batch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 84/194 [02:24<03:07,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 84 created and saved\n",
      "\n",
      "Batch 85 loaded\n",
      "Creating bottleneck features for batch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 85/194 [02:25<03:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 85 created and saved\n",
      "\n",
      "Batch 86 loaded\n",
      "Creating bottleneck features for batch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 86/194 [02:27<03:04,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 86 created and saved\n",
      "\n",
      "Batch 87 loaded\n",
      "Creating bottleneck features for batch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 87/194 [02:29<03:02,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 87 created and saved\n",
      "\n",
      "Batch 88 loaded\n",
      "Creating bottleneck features for batch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 88/194 [02:30<03:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 88 created and saved\n",
      "\n",
      "Batch 89 loaded\n",
      "Creating bottleneck features for batch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 89/194 [02:32<02:58,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 89 created and saved\n",
      "\n",
      "Batch 90 loaded\n",
      "Creating bottleneck features for batch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 90/194 [02:34<02:56,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 90 created and saved\n",
      "\n",
      "Batch 91 loaded\n",
      "Creating bottleneck features for batch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 91/194 [02:35<02:53,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 91 created and saved\n",
      "\n",
      "Batch 92 loaded\n",
      "Creating bottleneck features for batch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 92/194 [02:37<02:51,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 92 created and saved\n",
      "\n",
      "Batch 93 loaded\n",
      "Creating bottleneck features for batch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 93/194 [02:39<02:49,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 93 created and saved\n",
      "\n",
      "Batch 94 loaded\n",
      "Creating bottleneck features for batch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 94/194 [02:41<02:51,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 94 created and saved\n",
      "\n",
      "Batch 95 loaded\n",
      "Creating bottleneck features for batch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 95/194 [02:42<02:51,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 95 created and saved\n",
      "\n",
      "Batch 96 loaded\n",
      "Creating bottleneck features for batch 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 96/194 [02:44<02:48,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 96 created and saved\n",
      "\n",
      "Batch 97 loaded\n",
      "Creating bottleneck features for batch 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 97/194 [02:46<02:46,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 97 created and saved\n",
      "\n",
      "Batch 98 loaded\n",
      "Creating bottleneck features for batch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 98/194 [02:47<02:42,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 98 created and saved\n",
      "\n",
      "Batch 99 loaded\n",
      "Creating bottleneck features for batch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 99/194 [02:49<02:39,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 99 created and saved\n",
      "\n",
      "Batch 100 loaded\n",
      "Creating bottleneck features for batch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 100/194 [02:51<02:37,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 100 created and saved\n",
      "\n",
      "Batch 101 loaded\n",
      "Creating bottleneck features for batch 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 101/194 [02:52<02:37,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 101 created and saved\n",
      "\n",
      "Batch 102 loaded\n",
      "Creating bottleneck features for batch 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 102/194 [02:54<02:34,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 102 created and saved\n",
      "\n",
      "Batch 103 loaded\n",
      "Creating bottleneck features for batch 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 103/194 [02:56<02:33,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 103 created and saved\n",
      "\n",
      "Batch 104 loaded\n",
      "Creating bottleneck features for batch 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 104/194 [02:58<02:33,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 104 created and saved\n",
      "\n",
      "Batch 105 loaded\n",
      "Creating bottleneck features for batch 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 105/194 [02:59<02:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 105 created and saved\n",
      "\n",
      "Batch 106 loaded\n",
      "Creating bottleneck features for batch 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 106/194 [03:02<02:48,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 106 created and saved\n",
      "\n",
      "Batch 107 loaded\n",
      "Creating bottleneck features for batch 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 107/194 [03:03<02:42,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 107 created and saved\n",
      "\n",
      "Batch 108 loaded\n",
      "Creating bottleneck features for batch 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 108/194 [03:05<02:36,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 108 created and saved\n",
      "\n",
      "Batch 109 loaded\n",
      "Creating bottleneck features for batch 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 109/194 [03:07<02:32,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 109 created and saved\n",
      "\n",
      "Batch 110 loaded\n",
      "Creating bottleneck features for batch 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 110/194 [03:09<02:26,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 110 created and saved\n",
      "\n",
      "Batch 111 loaded\n",
      "Creating bottleneck features for batch 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 111/194 [03:10<02:23,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 111 created and saved\n",
      "\n",
      "Batch 112 loaded\n",
      "Creating bottleneck features for batch 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 112/194 [03:12<02:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 112 created and saved\n",
      "\n",
      "Batch 113 loaded\n",
      "Creating bottleneck features for batch 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 113/194 [03:14<02:17,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 113 created and saved\n",
      "\n",
      "Batch 114 loaded\n",
      "Creating bottleneck features for batch 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 114/194 [03:15<02:18,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 114 created and saved\n",
      "\n",
      "Batch 115 loaded\n",
      "Creating bottleneck features for batch 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 115/194 [03:17<02:14,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 115 created and saved\n",
      "\n",
      "Batch 116 loaded\n",
      "Creating bottleneck features for batch 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 116/194 [03:19<02:12,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 116 created and saved\n",
      "\n",
      "Batch 117 loaded\n",
      "Creating bottleneck features for batch 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 117/194 [03:20<02:11,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 117 created and saved\n",
      "\n",
      "Batch 118 loaded\n",
      "Creating bottleneck features for batch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 118/194 [03:22<02:09,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 118 created and saved\n",
      "\n",
      "Batch 119 loaded\n",
      "Creating bottleneck features for batch 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████▏   | 119/194 [03:24<02:06,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 119 created and saved\n",
      "\n",
      "Batch 120 loaded\n",
      "Creating bottleneck features for batch 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 120/194 [03:25<02:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 120 created and saved\n",
      "\n",
      "Batch 121 loaded\n",
      "Creating bottleneck features for batch 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 121/194 [03:27<02:05,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 121 created and saved\n",
      "\n",
      "Batch 122 loaded\n",
      "Creating bottleneck features for batch 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 122/194 [03:29<02:02,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 122 created and saved\n",
      "\n",
      "Batch 123 loaded\n",
      "Creating bottleneck features for batch 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 123/194 [03:31<02:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 123 created and saved\n",
      "\n",
      "Batch 124 loaded\n",
      "Creating bottleneck features for batch 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 124/194 [03:32<01:58,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 124 created and saved\n",
      "\n",
      "Batch 125 loaded\n",
      "Creating bottleneck features for batch 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 125/194 [03:34<01:57,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 125 created and saved\n",
      "\n",
      "Batch 126 loaded\n",
      "Creating bottleneck features for batch 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 126/194 [03:36<01:55,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 126 created and saved\n",
      "\n",
      "Batch 127 loaded\n",
      "Creating bottleneck features for batch 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 127/194 [03:37<01:52,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 127 created and saved\n",
      "\n",
      "Batch 128 loaded\n",
      "Creating bottleneck features for batch 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 128/194 [03:39<01:50,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 128 created and saved\n",
      "\n",
      "Batch 129 loaded\n",
      "Creating bottleneck features for batch 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 129/194 [03:41<01:47,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 129 created and saved\n",
      "\n",
      "Batch 130 loaded\n",
      "Creating bottleneck features for batch 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 130/194 [03:42<01:47,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 130 created and saved\n",
      "\n",
      "Batch 131 loaded\n",
      "Creating bottleneck features for batch 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 131/194 [03:44<01:45,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 131 created and saved\n",
      "\n",
      "Batch 132 loaded\n",
      "Creating bottleneck features for batch 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 132/194 [03:46<01:44,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 132 created and saved\n",
      "\n",
      "Batch 133 loaded\n",
      "Creating bottleneck features for batch 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 133/194 [03:47<01:42,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 133 created and saved\n",
      "\n",
      "Batch 134 loaded\n",
      "Creating bottleneck features for batch 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 134/194 [03:49<01:41,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 134 created and saved\n",
      "\n",
      "Batch 135 loaded\n",
      "Creating bottleneck features for batch 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 135/194 [03:51<01:40,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 135 created and saved\n",
      "\n",
      "Batch 136 loaded\n",
      "Creating bottleneck features for batch 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 136/194 [03:53<01:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 136 created and saved\n",
      "\n",
      "Batch 137 loaded\n",
      "Creating bottleneck features for batch 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 137/194 [03:54<01:36,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 137 created and saved\n",
      "\n",
      "Batch 138 loaded\n",
      "Creating bottleneck features for batch 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 138/194 [03:56<01:35,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 138 created and saved\n",
      "\n",
      "Batch 139 loaded\n",
      "Creating bottleneck features for batch 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 139/194 [03:58<01:33,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 139 created and saved\n",
      "\n",
      "Batch 140 loaded\n",
      "Creating bottleneck features for batch 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 140/194 [03:59<01:31,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 140 created and saved\n",
      "\n",
      "Batch 141 loaded\n",
      "Creating bottleneck features for batch 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 141/194 [04:01<01:29,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 141 created and saved\n",
      "\n",
      "Batch 142 loaded\n",
      "Creating bottleneck features for batch 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 142/194 [04:03<01:27,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 142 created and saved\n",
      "\n",
      "Batch 143 loaded\n",
      "Creating bottleneck features for batch 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 143/194 [04:04<01:26,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 143 created and saved\n",
      "\n",
      "Batch 144 loaded\n",
      "Creating bottleneck features for batch 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 144/194 [04:06<01:24,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 144 created and saved\n",
      "\n",
      "Batch 145 loaded\n",
      "Creating bottleneck features for batch 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 145/194 [04:08<01:22,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 145 created and saved\n",
      "\n",
      "Batch 146 loaded\n",
      "Creating bottleneck features for batch 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 146/194 [04:09<01:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 146 created and saved\n",
      "\n",
      "Batch 147 loaded\n",
      "Creating bottleneck features for batch 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 147/194 [04:11<01:19,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 147 created and saved\n",
      "\n",
      "Batch 148 loaded\n",
      "Creating bottleneck features for batch 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 148/194 [04:13<01:17,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 148 created and saved\n",
      "\n",
      "Batch 149 loaded\n",
      "Creating bottleneck features for batch 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 149/194 [04:14<01:15,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 149 created and saved\n",
      "\n",
      "Batch 150 loaded\n",
      "Creating bottleneck features for batch 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 150/194 [04:16<01:14,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 150 created and saved\n",
      "\n",
      "Batch 151 loaded\n",
      "Creating bottleneck features for batch 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 151/194 [04:18<01:12,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 151 created and saved\n",
      "\n",
      "Batch 152 loaded\n",
      "Creating bottleneck features for batch 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 152/194 [04:19<01:10,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 152 created and saved\n",
      "\n",
      "Batch 153 loaded\n",
      "Creating bottleneck features for batch 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 153/194 [04:21<01:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 153 created and saved\n",
      "\n",
      "Batch 154 loaded\n",
      "Creating bottleneck features for batch 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 154/194 [04:23<01:07,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 154 created and saved\n",
      "\n",
      "Batch 155 loaded\n",
      "Creating bottleneck features for batch 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 155/194 [04:25<01:06,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 155 created and saved\n",
      "\n",
      "Batch 156 loaded\n",
      "Creating bottleneck features for batch 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 156/194 [04:26<01:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 156 created and saved\n",
      "\n",
      "Batch 157 loaded\n",
      "Creating bottleneck features for batch 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 157/194 [04:28<01:03,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 157 created and saved\n",
      "\n",
      "Batch 158 loaded\n",
      "Creating bottleneck features for batch 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 158/194 [04:30<01:01,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 158 created and saved\n",
      "\n",
      "Batch 159 loaded\n",
      "Creating bottleneck features for batch 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 159/194 [04:32<01:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 159 created and saved\n",
      "\n",
      "Batch 160 loaded\n",
      "Creating bottleneck features for batch 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 160/194 [04:33<00:58,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 160 created and saved\n",
      "\n",
      "Batch 161 loaded\n",
      "Creating bottleneck features for batch 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 161/194 [04:35<00:56,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 161 created and saved\n",
      "\n",
      "Batch 162 loaded\n",
      "Creating bottleneck features for batch 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 162/194 [04:37<00:55,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 162 created and saved\n",
      "\n",
      "Batch 163 loaded\n",
      "Creating bottleneck features for batch 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 163/194 [04:38<00:53,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 163 created and saved\n",
      "\n",
      "Batch 164 loaded\n",
      "Creating bottleneck features for batch 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 164/194 [04:40<00:51,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 164 created and saved\n",
      "\n",
      "Batch 165 loaded\n",
      "Creating bottleneck features for batch 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 165/194 [04:42<00:49,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 165 created and saved\n",
      "\n",
      "Batch 166 loaded\n",
      "Creating bottleneck features for batch 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 166/194 [04:44<00:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 166 created and saved\n",
      "\n",
      "Batch 167 loaded\n",
      "Creating bottleneck features for batch 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 167/194 [04:45<00:46,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 167 created and saved\n",
      "\n",
      "Batch 168 loaded\n",
      "Creating bottleneck features for batch 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 168/194 [04:47<00:44,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 168 created and saved\n",
      "\n",
      "Batch 169 loaded\n",
      "Creating bottleneck features for batch 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 169/194 [04:49<00:42,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 169 created and saved\n",
      "\n",
      "Batch 170 loaded\n",
      "Creating bottleneck features for batch 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 170/194 [04:50<00:40,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 170 created and saved\n",
      "\n",
      "Batch 171 loaded\n",
      "Creating bottleneck features for batch 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 171/194 [04:52<00:38,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 171 created and saved\n",
      "\n",
      "Batch 172 loaded\n",
      "Creating bottleneck features for batch 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 172/194 [04:54<00:37,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 172 created and saved\n",
      "\n",
      "Batch 173 loaded\n",
      "Creating bottleneck features for batch 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 173/194 [04:55<00:35,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 173 created and saved\n",
      "\n",
      "Batch 174 loaded\n",
      "Creating bottleneck features for batch 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 174/194 [04:57<00:33,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 174 created and saved\n",
      "\n",
      "Batch 175 loaded\n",
      "Creating bottleneck features for batch 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 175/194 [04:59<00:31,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 175 created and saved\n",
      "\n",
      "Batch 176 loaded\n",
      "Creating bottleneck features for batch 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 176/194 [05:00<00:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 176 created and saved\n",
      "\n",
      "Batch 177 loaded\n",
      "Creating bottleneck features for batch 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 177/194 [05:02<00:28,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 177 created and saved\n",
      "\n",
      "Batch 178 loaded\n",
      "Creating bottleneck features for batch 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 178/194 [05:04<00:27,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 178 created and saved\n",
      "\n",
      "Batch 179 loaded\n",
      "Creating bottleneck features for batch 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 179/194 [05:05<00:25,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 179 created and saved\n",
      "\n",
      "Batch 180 loaded\n",
      "Creating bottleneck features for batch 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 180/194 [05:07<00:23,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 180 created and saved\n",
      "\n",
      "Batch 181 loaded\n",
      "Creating bottleneck features for batch 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 181/194 [05:09<00:22,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 181 created and saved\n",
      "\n",
      "Batch 182 loaded\n",
      "Creating bottleneck features for batch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 182/194 [05:11<00:20,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 182 created and saved\n",
      "\n",
      "Batch 183 loaded\n",
      "Creating bottleneck features for batch 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 183/194 [05:12<00:18,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 183 created and saved\n",
      "\n",
      "Batch 184 loaded\n",
      "Creating bottleneck features for batch 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 184/194 [05:14<00:17,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 184 created and saved\n",
      "\n",
      "Batch 185 loaded\n",
      "Creating bottleneck features for batch 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 185/194 [05:16<00:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 185 created and saved\n",
      "\n",
      "Batch 186 loaded\n",
      "Creating bottleneck features for batch 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 186/194 [05:17<00:13,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 186 created and saved\n",
      "\n",
      "Batch 187 loaded\n",
      "Creating bottleneck features for batch 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 187/194 [05:19<00:11,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 187 created and saved\n",
      "\n",
      "Batch 188 loaded\n",
      "Creating bottleneck features for batch 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 188/194 [05:21<00:10,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 188 created and saved\n",
      "\n",
      "Batch 189 loaded\n",
      "Creating bottleneck features for batch 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 189/194 [05:22<00:08,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 189 created and saved\n",
      "\n",
      "Batch 190 loaded\n",
      "Creating bottleneck features for batch 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 190/194 [05:24<00:06,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 190 created and saved\n",
      "\n",
      "Batch 191 loaded\n",
      "Creating bottleneck features for batch 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 191/194 [05:26<00:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 191 created and saved\n",
      "\n",
      "Batch 192 loaded\n",
      "Creating bottleneck features for batch 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 192/194 [05:28<00:03,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 192 created and saved\n",
      "\n",
      "Batch 193 loaded\n",
      "Creating bottleneck features for batch 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 193/194 [05:29<00:01,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 193 created and saved\n",
      "\n",
      "Batch 194 loaded\n",
      "Creating bottleneck features for batch 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 194/194 [05:31<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck features for batch 194 created and saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#creating bottleneck features for train data using VGG-16- Image-net model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "SAVEDIR = \"./outputs_facedb/Bottleneck_Features_test/\"\n",
    "SAVEDIR_LABELS = \"./outputs_facedb/Bottleneck_Labels_test/\"\n",
    "batch_size = 10\n",
    "for i in tqdm(range(int(len(test_df)/batch_size)-1)):\n",
    "    #try:\n",
    "    x, y = loadCombinedTestBatch(batch_size)\n",
    "    print(\"Batch {} loaded\".format(i+1))\n",
    "\n",
    "    np.save(os.path.join(SAVEDIR_LABELS, \"bottleneck_labels_{}\".format(i+1)), y)\n",
    "\n",
    "    print(\"Creating bottleneck features for batch {}\". format(i+1))\n",
    "    bottleneck_features = model.predict(x)\n",
    "    np.save(os.path.join(SAVEDIR, \"bottleneck_{}\".format(i+1)), bottleneck_features)\n",
    "    print(\"Bottleneck features for batch {} created and saved\\n\".format(i+1))\n",
    "    #except:\n",
    "    #    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model for FER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 5\n",
    "\n",
    "#model architecture\n",
    "def model(input_shape):\n",
    "    model = Sequential()\n",
    "        \n",
    "    model.add(Dense(512, activation='relu', input_dim = input_shape))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(output_dim = no_of_classes, activation='softmax')) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 19:16:35.560767 140537857021696 deprecation.py:506] From /home/gpu1/anaconda3/envs/fer_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/home/gpu1/anaconda3/envs/fer_env/lib/python3.7/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5)`\n",
      "W0725 19:16:35.642517 140537857021696 deprecation_wrapper.py:119] From /home/gpu1/anaconda3/envs/fer_env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               26214912  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 26,388,229\n",
      "Trainable params: 26,387,973\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 19:16:35.712481 140537857021696 deprecation.py:323] From /home/gpu1/anaconda3/envs/fer_env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 1, CombTr_Loss: 1.76, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 2, CombTr_Loss: 1.64, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 3, CombTr_Loss: 2.26, CombTr_Acc: 0.0\n",
      "Epoch: 1, Step: 4, CombTr_Loss: 2.19, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 5, CombTr_Loss: 1.59, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 6, CombTr_Loss: 1.77, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 7, CombTr_Loss: 1.51, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 8, CombTr_Loss: 1.4, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 9, CombTr_Loss: 1.6, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 10, CombTr_Loss: 2.14, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 11, CombTr_Loss: 1.84, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 12, CombTr_Loss: 1.46, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 13, CombTr_Loss: 1.59, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 14, CombTr_Loss: 1.73, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 15, CombTr_Loss: 1.82, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 16, CombTr_Loss: 1.73, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 17, CombTr_Loss: 1.58, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 18, CombTr_Loss: 1.74, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 19, CombTr_Loss: 1.92, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 20, CombTr_Loss: 1.51, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 21, CombTr_Loss: 1.67, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 22, CombTr_Loss: 1.68, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 23, CombTr_Loss: 1.62, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 24, CombTr_Loss: 1.49, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 25, CombTr_Loss: 1.4, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 26, CombTr_Loss: 1.47, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 27, CombTr_Loss: 1.57, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 28, CombTr_Loss: 2.01, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 29, CombTr_Loss: 1.76, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 30, CombTr_Loss: 1.68, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 31, CombTr_Loss: 1.59, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 32, CombTr_Loss: 1.77, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 33, CombTr_Loss: 1.59, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 34, CombTr_Loss: 1.45, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 35, CombTr_Loss: 1.56, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 36, CombTr_Loss: 1.51, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 37, CombTr_Loss: 1.72, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 38, CombTr_Loss: 1.65, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 39, CombTr_Loss: 1.76, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 40, CombTr_Loss: 1.63, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 41, CombTr_Loss: 1.56, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 42, CombTr_Loss: 1.7, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 43, CombTr_Loss: 1.62, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 44, CombTr_Loss: 1.39, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 45, CombTr_Loss: 1.51, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 46, CombTr_Loss: 1.62, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 47, CombTr_Loss: 1.73, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 48, CombTr_Loss: 1.33, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 49, CombTr_Loss: 1.8, CombTr_Acc: 0.0\n",
      "Epoch: 1, Step: 50, CombTr_Loss: 1.58, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 51, CombTr_Loss: 1.33, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 52, CombTr_Loss: 1.56, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 53, CombTr_Loss: 1.69, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 54, CombTr_Loss: 1.47, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 55, CombTr_Loss: 1.43, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 56, CombTr_Loss: 1.72, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 57, CombTr_Loss: 1.37, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 58, CombTr_Loss: 1.31, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 59, CombTr_Loss: 1.6, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 60, CombTr_Loss: 1.4, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 61, CombTr_Loss: 1.94, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 62, CombTr_Loss: 1.75, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 63, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 64, CombTr_Loss: 1.39, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 65, CombTr_Loss: 1.47, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 66, CombTr_Loss: 1.44, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 67, CombTr_Loss: 1.52, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 68, CombTr_Loss: 1.74, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 69, CombTr_Loss: 1.75, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 70, CombTr_Loss: 1.65, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 71, CombTr_Loss: 1.37, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 72, CombTr_Loss: 1.59, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 73, CombTr_Loss: 1.35, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 74, CombTr_Loss: 1.58, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 75, CombTr_Loss: 1.8, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 76, CombTr_Loss: 1.77, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 77, CombTr_Loss: 1.38, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 78, CombTr_Loss: 1.6, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 79, CombTr_Loss: 1.74, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 80, CombTr_Loss: 1.26, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 81, CombTr_Loss: 1.5, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 82, CombTr_Loss: 1.52, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 83, CombTr_Loss: 1.49, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 84, CombTr_Loss: 1.36, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 85, CombTr_Loss: 1.29, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 86, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 87, CombTr_Loss: 1.7, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 88, CombTr_Loss: 1.45, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 89, CombTr_Loss: 1.26, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 90, CombTr_Loss: 1.73, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 91, CombTr_Loss: 1.61, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 92, CombTr_Loss: 1.33, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 93, CombTr_Loss: 1.65, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 94, CombTr_Loss: 1.1, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 95, CombTr_Loss: 1.24, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 96, CombTr_Loss: 1.5, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 97, CombTr_Loss: 1.27, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 98, CombTr_Loss: 1.2, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 99, CombTr_Loss: 1.77, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 100, CombTr_Loss: 1.32, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 101, CombTr_Loss: 1.31, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 102, CombTr_Loss: 1.47, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 103, CombTr_Loss: 1.62, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 104, CombTr_Loss: 1.54, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 105, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 106, CombTr_Loss: 1.29, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 107, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 108, CombTr_Loss: 1.58, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 109, CombTr_Loss: 1.26, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 110, CombTr_Loss: 1.47, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 111, CombTr_Loss: 1.51, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 112, CombTr_Loss: 1.18, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 113, CombTr_Loss: 1.27, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 114, CombTr_Loss: 1.24, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 115, CombTr_Loss: 1.27, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 116, CombTr_Loss: 1.48, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 117, CombTr_Loss: 1.31, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 118, CombTr_Loss: 1.28, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 119, CombTr_Loss: 1.58, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 120, CombTr_Loss: 1.53, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 121, CombTr_Loss: 1.28, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 122, CombTr_Loss: 1.23, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 123, CombTr_Loss: 1.37, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 124, CombTr_Loss: 1.11, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 125, CombTr_Loss: 1.1, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 126, CombTr_Loss: 1.39, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 127, CombTr_Loss: 1.82, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 128, CombTr_Loss: 1.33, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 129, CombTr_Loss: 1.41, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 130, CombTr_Loss: 1.7, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 131, CombTr_Loss: 0.93, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 132, CombTr_Loss: 1.56, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 133, CombTr_Loss: 1.17, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 134, CombTr_Loss: 1.35, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 135, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 136, CombTr_Loss: 1.38, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 137, CombTr_Loss: 1.01, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 138, CombTr_Loss: 1.27, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 139, CombTr_Loss: 0.99, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 140, CombTr_Loss: 1.02, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 141, CombTr_Loss: 1.52, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 142, CombTr_Loss: 1.2, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 143, CombTr_Loss: 1.31, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 144, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 145, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 146, CombTr_Loss: 1.4, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 147, CombTr_Loss: 1.45, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 148, CombTr_Loss: 1.43, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 149, CombTr_Loss: 1.14, CombTr_Acc: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 150, CombTr_Loss: 1.45, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 151, CombTr_Loss: 1.34, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 152, CombTr_Loss: 1.04, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 153, CombTr_Loss: 1.14, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 154, CombTr_Loss: 1.28, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 155, CombTr_Loss: 1.27, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 156, CombTr_Loss: 1.22, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 157, CombTr_Loss: 1.02, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 158, CombTr_Loss: 0.94, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 159, CombTr_Loss: 1.54, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 160, CombTr_Loss: 1.29, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 161, CombTr_Loss: 1.51, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 162, CombTr_Loss: 1.3, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 163, CombTr_Loss: 1.81, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 164, CombTr_Loss: 1.22, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 165, CombTr_Loss: 0.84, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 166, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 167, CombTr_Loss: 1.12, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 168, CombTr_Loss: 1.04, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 169, CombTr_Loss: 1.16, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 170, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 171, CombTr_Loss: 0.93, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 172, CombTr_Loss: 1.25, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 173, CombTr_Loss: 1.57, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 174, CombTr_Loss: 1.55, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 175, CombTr_Loss: 1.2, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 176, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 177, CombTr_Loss: 1.12, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 178, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 179, CombTr_Loss: 1.55, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 180, CombTr_Loss: 1.12, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 181, CombTr_Loss: 1.32, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 182, CombTr_Loss: 1.5, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 183, CombTr_Loss: 1.1, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 184, CombTr_Loss: 1.07, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 185, CombTr_Loss: 0.77, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 186, CombTr_Loss: 1.44, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 187, CombTr_Loss: 0.68, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 188, CombTr_Loss: 1.17, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 189, CombTr_Loss: 1.35, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 190, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 191, CombTr_Loss: 1.19, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 192, CombTr_Loss: 1.18, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 193, CombTr_Loss: 1.18, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 194, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 195, CombTr_Loss: 1.52, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 196, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 197, CombTr_Loss: 1.04, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 198, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 199, CombTr_Loss: 1.22, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 200, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 201, CombTr_Loss: 1.17, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 202, CombTr_Loss: 1.25, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 203, CombTr_Loss: 1.16, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 204, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 205, CombTr_Loss: 1.05, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 206, CombTr_Loss: 1.31, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 207, CombTr_Loss: 1.61, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 208, CombTr_Loss: 1.06, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 209, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 210, CombTr_Loss: 1.01, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 211, CombTr_Loss: 1.3, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 212, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 213, CombTr_Loss: 1.19, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 214, CombTr_Loss: 1.17, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 215, CombTr_Loss: 1.34, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 216, CombTr_Loss: 1.84, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 217, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 218, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 219, CombTr_Loss: 1.11, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 220, CombTr_Loss: 1.23, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 221, CombTr_Loss: 0.93, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 222, CombTr_Loss: 1.09, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 223, CombTr_Loss: 1.36, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 224, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 225, CombTr_Loss: 0.77, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 226, CombTr_Loss: 1.22, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 227, CombTr_Loss: 1.39, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 228, CombTr_Loss: 1.14, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 229, CombTr_Loss: 1.02, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 230, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 231, CombTr_Loss: 1.27, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 232, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 233, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 234, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 235, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 236, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 237, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 238, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 239, CombTr_Loss: 1.43, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 240, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 241, CombTr_Loss: 1.41, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 242, CombTr_Loss: 0.9, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 243, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 244, CombTr_Loss: 1.71, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 245, CombTr_Loss: 1.55, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 246, CombTr_Loss: 1.12, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 247, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 248, CombTr_Loss: 1.12, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 249, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 250, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 251, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 252, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 253, CombTr_Loss: 1.21, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 254, CombTr_Loss: 1.39, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 255, CombTr_Loss: 0.81, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 256, CombTr_Loss: 1.04, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 257, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 258, CombTr_Loss: 1.36, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 259, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 260, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 261, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 262, CombTr_Loss: 1.34, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 263, CombTr_Loss: 1.29, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 264, CombTr_Loss: 1.03, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 265, CombTr_Loss: 1.31, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 266, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 267, CombTr_Loss: 0.8, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 268, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 269, CombTr_Loss: 0.99, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 270, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 271, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 272, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 273, CombTr_Loss: 1.24, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 274, CombTr_Loss: 1.15, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 275, CombTr_Loss: 0.92, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 276, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 277, CombTr_Loss: 1.46, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 278, CombTr_Loss: 1.43, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 279, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 280, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 281, CombTr_Loss: 1.26, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 282, CombTr_Loss: 0.76, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 283, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 284, CombTr_Loss: 1.33, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 285, CombTr_Loss: 1.04, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 286, CombTr_Loss: 0.93, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 287, CombTr_Loss: 1.12, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 288, CombTr_Loss: 1.17, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 289, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 290, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 291, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 292, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 293, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 294, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 295, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 296, CombTr_Loss: 1.28, CombTr_Acc: 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 297, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 298, CombTr_Loss: 1.31, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 299, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 300, CombTr_Loss: 1.18, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 301, CombTr_Loss: 0.98, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 302, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 303, CombTr_Loss: 1.24, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 304, CombTr_Loss: 1.17, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 305, CombTr_Loss: 1.13, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 306, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 307, CombTr_Loss: 1.24, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 308, CombTr_Loss: 0.95, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 309, CombTr_Loss: 1.3, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 310, CombTr_Loss: 1.25, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 311, CombTr_Loss: 1.27, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 312, CombTr_Loss: 1.13, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 313, CombTr_Loss: 1.3, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 314, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 315, CombTr_Loss: 1.32, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 316, CombTr_Loss: 1.16, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 317, CombTr_Loss: 1.85, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 318, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 319, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 320, CombTr_Loss: 1.09, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 321, CombTr_Loss: 1.0, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 322, CombTr_Loss: 1.27, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 323, CombTr_Loss: 1.45, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 324, CombTr_Loss: 1.15, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 325, CombTr_Loss: 1.41, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 326, CombTr_Loss: 1.52, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 327, CombTr_Loss: 1.45, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 328, CombTr_Loss: 0.93, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 329, CombTr_Loss: 1.12, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 330, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 331, CombTr_Loss: 0.76, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 332, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 333, CombTr_Loss: 1.7, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 334, CombTr_Loss: 1.28, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 335, CombTr_Loss: 1.39, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 336, CombTr_Loss: 1.21, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 337, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 338, CombTr_Loss: 1.47, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 339, CombTr_Loss: 1.09, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 340, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 341, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 342, CombTr_Loss: 1.56, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 343, CombTr_Loss: 1.08, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 344, CombTr_Loss: 1.36, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 345, CombTr_Loss: 1.21, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 346, CombTr_Loss: 1.19, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 347, CombTr_Loss: 1.29, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 348, CombTr_Loss: 0.98, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 349, CombTr_Loss: 1.03, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 350, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 351, CombTr_Loss: 0.9, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 352, CombTr_Loss: 1.2, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 353, CombTr_Loss: 0.95, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 354, CombTr_Loss: 1.2, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 355, CombTr_Loss: 0.99, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 356, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 357, CombTr_Loss: 1.11, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 358, CombTr_Loss: 1.4, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 359, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 360, CombTr_Loss: 1.1, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 361, CombTr_Loss: 1.01, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 362, CombTr_Loss: 1.45, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 363, CombTr_Loss: 1.09, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 364, CombTr_Loss: 1.0, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 365, CombTr_Loss: 1.29, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 366, CombTr_Loss: 1.39, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 367, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 368, CombTr_Loss: 1.16, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 369, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 370, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 371, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 372, CombTr_Loss: 0.98, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 373, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 374, CombTr_Loss: 0.77, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 375, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 376, CombTr_Loss: 1.31, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 377, CombTr_Loss: 1.37, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 378, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 379, CombTr_Loss: 0.94, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 380, CombTr_Loss: 1.34, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 381, CombTr_Loss: 1.2, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 382, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 383, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 384, CombTr_Loss: 1.19, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 385, CombTr_Loss: 1.12, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 386, CombTr_Loss: 1.01, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 387, CombTr_Loss: 1.11, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 388, CombTr_Loss: 1.3, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 389, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 390, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 391, CombTr_Loss: 1.26, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 392, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 393, CombTr_Loss: 1.09, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 394, CombTr_Loss: 1.26, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 395, CombTr_Loss: 1.27, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 396, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 397, CombTr_Loss: 1.22, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 398, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 399, CombTr_Loss: 1.03, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 400, CombTr_Loss: 1.37, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 401, CombTr_Loss: 1.2, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 402, CombTr_Loss: 0.9, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 403, CombTr_Loss: 1.27, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 404, CombTr_Loss: 0.79, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 405, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 406, CombTr_Loss: 0.93, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 407, CombTr_Loss: 0.49, CombTr_Acc: 1.0\n",
      "Epoch: 1, Step: 408, CombTr_Loss: 1.29, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 409, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 410, CombTr_Loss: 1.34, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 411, CombTr_Loss: 1.35, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 412, CombTr_Loss: 1.5, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 413, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 414, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 415, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 416, CombTr_Loss: 0.9, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 417, CombTr_Loss: 0.79, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 418, CombTr_Loss: 1.17, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 419, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 420, CombTr_Loss: 1.26, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 421, CombTr_Loss: 0.75, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 422, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 423, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 424, CombTr_Loss: 1.13, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 425, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 426, CombTr_Loss: 1.15, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 427, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 428, CombTr_Loss: 0.95, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 429, CombTr_Loss: 0.8, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 430, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 431, CombTr_Loss: 1.54, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 432, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 433, CombTr_Loss: 0.96, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 434, CombTr_Loss: 1.12, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 435, CombTr_Loss: 0.99, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 436, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 437, CombTr_Loss: 1.22, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 438, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 439, CombTr_Loss: 1.39, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 440, CombTr_Loss: 1.19, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 441, CombTr_Loss: 0.93, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 442, CombTr_Loss: 0.99, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 443, CombTr_Loss: 0.9, CombTr_Acc: 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 444, CombTr_Loss: 1.32, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 445, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 446, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 447, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 448, CombTr_Loss: 0.98, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 449, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 450, CombTr_Loss: 1.23, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 451, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 452, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 453, CombTr_Loss: 1.11, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 454, CombTr_Loss: 1.35, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 455, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 456, CombTr_Loss: 1.43, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 457, CombTr_Loss: 1.64, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 458, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 459, CombTr_Loss: 1.49, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 460, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 461, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 462, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 463, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 464, CombTr_Loss: 1.15, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 465, CombTr_Loss: 0.73, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 466, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 467, CombTr_Loss: 0.82, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 468, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 469, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 470, CombTr_Loss: 0.68, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 471, CombTr_Loss: 1.63, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 472, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 473, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 474, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 475, CombTr_Loss: 0.69, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 476, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 477, CombTr_Loss: 0.91, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 478, CombTr_Loss: 0.8, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 479, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 480, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 481, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 482, CombTr_Loss: 1.17, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 483, CombTr_Loss: 1.01, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 484, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 485, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 486, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 487, CombTr_Loss: 1.04, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 488, CombTr_Loss: 1.29, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 489, CombTr_Loss: 0.41, CombTr_Acc: 1.0\n",
      "Epoch: 1, Step: 490, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 491, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 492, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 493, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 494, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 495, CombTr_Loss: 1.19, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 496, CombTr_Loss: 1.34, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 497, CombTr_Loss: 0.67, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 498, CombTr_Loss: 0.84, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 499, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 500, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 501, CombTr_Loss: 1.79, CombTr_Acc: 0.1\n",
      "Epoch: 1, Step: 502, CombTr_Loss: 1.09, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 503, CombTr_Loss: 1.52, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 504, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 505, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 506, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 507, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 508, CombTr_Loss: 1.37, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 509, CombTr_Loss: 1.01, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 510, CombTr_Loss: 0.94, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 511, CombTr_Loss: 0.95, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 512, CombTr_Loss: 0.82, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 513, CombTr_Loss: 1.21, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 514, CombTr_Loss: 0.87, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 515, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 516, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 517, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 518, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 519, CombTr_Loss: 0.85, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 520, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 521, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 522, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 523, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 524, CombTr_Loss: 1.13, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 525, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 526, CombTr_Loss: 1.36, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 527, CombTr_Loss: 1.16, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 528, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 529, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 530, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 531, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 532, CombTr_Loss: 0.86, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 533, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 534, CombTr_Loss: 0.99, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 535, CombTr_Loss: 0.77, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 536, CombTr_Loss: 1.21, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 537, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 538, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 539, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 540, CombTr_Loss: 1.16, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 541, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 542, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 543, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 544, CombTr_Loss: 1.31, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 545, CombTr_Loss: 1.08, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 546, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 547, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 548, CombTr_Loss: 0.51, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 549, CombTr_Loss: 0.37, CombTr_Acc: 1.0\n",
      "Epoch: 1, Step: 550, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 551, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 552, CombTr_Loss: 1.38, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 553, CombTr_Loss: 1.06, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 554, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 555, CombTr_Loss: 1.0, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 556, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 557, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 558, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 559, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 560, CombTr_Loss: 1.08, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 561, CombTr_Loss: 1.28, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 562, CombTr_Loss: 0.95, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 563, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 564, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 565, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 566, CombTr_Loss: 0.82, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 567, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 568, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 569, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 570, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 571, CombTr_Loss: 1.01, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 572, CombTr_Loss: 1.28, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 573, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 574, CombTr_Loss: 0.89, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 575, CombTr_Loss: 0.78, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 576, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 577, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 578, CombTr_Loss: 1.1, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 579, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 580, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 581, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 582, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 583, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 584, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 585, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 586, CombTr_Loss: 1.1, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 587, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 588, CombTr_Loss: 1.89, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 589, CombTr_Loss: 0.97, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 590, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 591, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 592, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 593, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 594, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 595, CombTr_Loss: 1.15, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 596, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 597, CombTr_Loss: 1.18, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 598, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 599, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 600, CombTr_Loss: 1.03, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 601, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 602, CombTr_Loss: 0.78, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 603, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 604, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 605, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 606, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 607, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 608, CombTr_Loss: 1.01, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 609, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 610, CombTr_Loss: 1.15, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 611, CombTr_Loss: 0.8, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 612, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 613, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 614, CombTr_Loss: 0.8, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 615, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 616, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 617, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 618, CombTr_Loss: 0.97, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 619, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 620, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 621, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 622, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 623, CombTr_Loss: 1.76, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 624, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 625, CombTr_Loss: 0.83, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 626, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 627, CombTr_Loss: 1.27, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 628, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 629, CombTr_Loss: 0.79, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 630, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 631, CombTr_Loss: 0.59, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 632, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 633, CombTr_Loss: 1.13, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 634, CombTr_Loss: 1.11, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 635, CombTr_Loss: 1.53, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 636, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 637, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 638, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 639, CombTr_Loss: 1.27, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 640, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 641, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 642, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 643, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 644, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 645, CombTr_Loss: 1.09, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 646, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 647, CombTr_Loss: 0.69, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 648, CombTr_Loss: 0.88, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 649, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 650, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 651, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 652, CombTr_Loss: 1.13, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 653, CombTr_Loss: 1.43, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 654, CombTr_Loss: 1.02, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 655, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 656, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 657, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 658, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 659, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 660, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 661, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 662, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 663, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 664, CombTr_Loss: 0.61, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 665, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 666, CombTr_Loss: 1.21, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 667, CombTr_Loss: 0.93, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 668, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 669, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 670, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 671, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 672, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 673, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 674, CombTr_Loss: 1.05, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 675, CombTr_Loss: 1.32, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 676, CombTr_Loss: 0.66, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 677, CombTr_Loss: 0.74, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 678, CombTr_Loss: 0.64, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 679, CombTr_Loss: 1.35, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 680, CombTr_Loss: 0.47, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 681, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 682, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 683, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 684, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 685, CombTr_Loss: 0.69, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 686, CombTr_Loss: 1.68, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 687, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 688, CombTr_Loss: 1.41, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 689, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 690, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 691, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 692, CombTr_Loss: 1.04, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 693, CombTr_Loss: 1.17, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 694, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 695, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 696, CombTr_Loss: 1.59, CombTr_Acc: 0.2\n",
      "Epoch: 1, Step: 697, CombTr_Loss: 1.27, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 698, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 699, CombTr_Loss: 1.22, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 700, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 701, CombTr_Loss: 1.5, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 702, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 703, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 704, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 705, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 706, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 707, CombTr_Loss: 0.83, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 708, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 709, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 710, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 711, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 712, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 713, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 714, CombTr_Loss: 0.98, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 715, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 716, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 717, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 718, CombTr_Loss: 0.95, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 719, CombTr_Loss: 0.95, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 720, CombTr_Loss: 1.18, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 721, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 722, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 723, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 724, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 725, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 726, CombTr_Loss: 0.57, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 727, CombTr_Loss: 0.88, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 728, CombTr_Loss: 0.96, CombTr_Acc: 0.4\n",
      "Epoch: 1, Step: 729, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 730, CombTr_Loss: 0.95, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 731, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 732, CombTr_Loss: 0.92, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 733, CombTr_Loss: 1.07, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 734, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 735, CombTr_Loss: 1.55, CombTr_Acc: 0.3\n",
      "Epoch: 1, Step: 736, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 737, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 738, CombTr_Loss: 1.33, CombTr_Acc: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 739, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 740, CombTr_Loss: 1.37, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 741, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 742, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 743, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 744, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 745, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 746, CombTr_Loss: 1.33, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 747, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 748, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 749, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 750, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 751, CombTr_Loss: 0.87, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 752, CombTr_Loss: 0.47, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 753, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 754, CombTr_Loss: 0.3, CombTr_Acc: 1.0\n",
      "Epoch: 1, Step: 755, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 756, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 757, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 758, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 759, CombTr_Loss: 1.13, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 760, CombTr_Loss: 0.66, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 761, CombTr_Loss: 0.79, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 762, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 763, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 764, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 765, CombTr_Loss: 0.65, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 766, CombTr_Loss: 0.75, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 767, CombTr_Loss: 1.5, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 768, CombTr_Loss: 1.1, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 769, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 770, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 771, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 772, CombTr_Loss: 1.01, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 773, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 1, Step: 774, CombTr_Loss: 0.63, CombTr_Acc: 0.9\n",
      "Epoch: 1, Step: 775, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 776, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 777, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 778, CombTr_Loss: 0.92, CombTr_Acc: 0.5\n",
      "Epoch: 1, Step: 779, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 1, Step: 780, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 781, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 1, Step: 782, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Avg_CombTrain_Loss: 1.07, Avg_CombTrain_Acc: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [02:39<50:33, 159.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 1\n",
      "Epoch: 2, Step: 783, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 784, CombTr_Loss: 0.79, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 785, CombTr_Loss: 0.86, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 786, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 787, CombTr_Loss: 1.28, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 788, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 789, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 790, CombTr_Loss: 1.25, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 791, CombTr_Loss: 0.77, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 792, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 793, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 794, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 795, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 796, CombTr_Loss: 1.22, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 797, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 798, CombTr_Loss: 2.07, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 799, CombTr_Loss: 0.6, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 800, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 801, CombTr_Loss: 1.41, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 802, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 803, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 804, CombTr_Loss: 0.6, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 805, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 806, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 807, CombTr_Loss: 1.19, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 808, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 809, CombTr_Loss: 0.56, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 810, CombTr_Loss: 1.05, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 811, CombTr_Loss: 1.37, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 812, CombTr_Loss: 0.66, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 813, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 814, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 815, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 816, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 817, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 818, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 819, CombTr_Loss: 1.02, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 820, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 821, CombTr_Loss: 1.0, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 822, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 823, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 824, CombTr_Loss: 1.25, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 825, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 826, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 827, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 828, CombTr_Loss: 1.21, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 829, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 830, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 831, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 832, CombTr_Loss: 0.79, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 833, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 834, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 835, CombTr_Loss: 1.1, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 836, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 837, CombTr_Loss: 1.32, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 838, CombTr_Loss: 0.82, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 839, CombTr_Loss: 1.25, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 840, CombTr_Loss: 0.76, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 841, CombTr_Loss: 0.58, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 842, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 843, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 844, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 845, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 846, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 847, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 848, CombTr_Loss: 1.03, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 849, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 850, CombTr_Loss: 1.49, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 851, CombTr_Loss: 0.99, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 852, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 853, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 854, CombTr_Loss: 0.62, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 855, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 856, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 857, CombTr_Loss: 1.25, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 858, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 859, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 860, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 861, CombTr_Loss: 0.99, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 862, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 863, CombTr_Loss: 0.5, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 864, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 865, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 866, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 867, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 868, CombTr_Loss: 1.2, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 869, CombTr_Loss: 1.43, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 870, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 871, CombTr_Loss: 0.87, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 872, CombTr_Loss: 0.69, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 873, CombTr_Loss: 1.17, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 874, CombTr_Loss: 0.56, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 875, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 876, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 877, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 878, CombTr_Loss: 1.03, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 879, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 880, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 881, CombTr_Loss: 1.59, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 882, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 883, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 884, CombTr_Loss: 1.18, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 885, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 886, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 887, CombTr_Loss: 0.47, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 888, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 889, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 890, CombTr_Loss: 1.22, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 891, CombTr_Loss: 0.97, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 892, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 893, CombTr_Loss: 0.61, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 894, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 895, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 896, CombTr_Loss: 1.25, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 897, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 898, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 899, CombTr_Loss: 1.13, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 900, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 901, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 902, CombTr_Loss: 1.29, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 903, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 904, CombTr_Loss: 1.35, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 905, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 906, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 907, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 908, CombTr_Loss: 1.65, CombTr_Acc: 0.2\n",
      "Epoch: 2, Step: 909, CombTr_Loss: 0.99, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 910, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 911, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 912, CombTr_Loss: 1.62, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 913, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 914, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 915, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 916, CombTr_Loss: 0.93, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 917, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 918, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 919, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 920, CombTr_Loss: 0.88, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 921, CombTr_Loss: 1.03, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 922, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 923, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 924, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 925, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 926, CombTr_Loss: 0.88, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 927, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 928, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Step: 929, CombTr_Loss: 1.42, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 930, CombTr_Loss: 1.28, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 931, CombTr_Loss: 0.59, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 932, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 933, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 934, CombTr_Loss: 0.9, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 935, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 936, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 937, CombTr_Loss: 1.21, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 938, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 939, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 940, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 941, CombTr_Loss: 1.23, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 942, CombTr_Loss: 1.35, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 943, CombTr_Loss: 1.37, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 944, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 945, CombTr_Loss: 1.24, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 946, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 947, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 948, CombTr_Loss: 0.89, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 949, CombTr_Loss: 0.69, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 950, CombTr_Loss: 1.14, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 951, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 952, CombTr_Loss: 0.78, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 953, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 954, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 955, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 956, CombTr_Loss: 1.49, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 957, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 958, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 959, CombTr_Loss: 0.97, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 960, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 961, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 962, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 963, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 964, CombTr_Loss: 1.35, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 965, CombTr_Loss: 1.28, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 966, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 967, CombTr_Loss: 0.67, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 968, CombTr_Loss: 1.33, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 969, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 970, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 971, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 972, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 973, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 974, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 975, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 976, CombTr_Loss: 0.69, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 977, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 978, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 979, CombTr_Loss: 0.57, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 980, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 981, CombTr_Loss: 0.9, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 982, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 983, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 984, CombTr_Loss: 1.19, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 985, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 986, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 987, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 988, CombTr_Loss: 1.31, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 989, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 990, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 991, CombTr_Loss: 0.89, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 992, CombTr_Loss: 1.07, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 993, CombTr_Loss: 1.32, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 994, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 995, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 996, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 997, CombTr_Loss: 1.25, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 998, CombTr_Loss: 1.74, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 999, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1000, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1001, CombTr_Loss: 0.8, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1002, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1003, CombTr_Loss: 0.6, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1004, CombTr_Loss: 0.78, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1005, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1006, CombTr_Loss: 0.46, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1007, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1008, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1009, CombTr_Loss: 1.1, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1010, CombTr_Loss: 0.83, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1011, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1012, CombTr_Loss: 0.64, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1013, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1014, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1015, CombTr_Loss: 0.69, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1016, CombTr_Loss: 0.39, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1017, CombTr_Loss: 1.04, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1018, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1019, CombTr_Loss: 1.26, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1020, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1021, CombTr_Loss: 1.81, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1022, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1023, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1024, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1025, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1026, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1027, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1028, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1029, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1030, CombTr_Loss: 0.85, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1031, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1032, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1033, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1034, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1035, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1036, CombTr_Loss: 0.82, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1037, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1038, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1039, CombTr_Loss: 0.29, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1040, CombTr_Loss: 1.09, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1041, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1042, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1043, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1044, CombTr_Loss: 1.07, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1045, CombTr_Loss: 1.41, CombTr_Acc: 0.2\n",
      "Epoch: 2, Step: 1046, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1047, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1048, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1049, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1050, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1051, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1052, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1053, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1054, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1055, CombTr_Loss: 1.01, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1056, CombTr_Loss: 1.2, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1057, CombTr_Loss: 1.06, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1058, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1059, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1060, CombTr_Loss: 1.34, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1061, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1062, CombTr_Loss: 1.25, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1063, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1064, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1065, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1066, CombTr_Loss: 1.39, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1067, CombTr_Loss: 1.06, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1068, CombTr_Loss: 1.01, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1069, CombTr_Loss: 0.61, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1070, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1071, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1072, CombTr_Loss: 0.79, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1073, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1074, CombTr_Loss: 0.65, CombTr_Acc: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Step: 1075, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1076, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1077, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1078, CombTr_Loss: 1.43, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1079, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1080, CombTr_Loss: 1.19, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1081, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1082, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1083, CombTr_Loss: 0.51, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1084, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1085, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1086, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1087, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1088, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1089, CombTr_Loss: 1.04, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1090, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1091, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1092, CombTr_Loss: 1.3, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1093, CombTr_Loss: 1.27, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 1094, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1095, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1096, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1097, CombTr_Loss: 1.42, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1098, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1099, CombTr_Loss: 0.62, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1100, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1101, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1102, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1103, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1104, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1105, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1106, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1107, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1108, CombTr_Loss: 1.57, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1109, CombTr_Loss: 0.73, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1110, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1111, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1112, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1113, CombTr_Loss: 0.54, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1114, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1115, CombTr_Loss: 0.99, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1116, CombTr_Loss: 0.87, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1117, CombTr_Loss: 0.73, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1118, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1119, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1120, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1121, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1122, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1123, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1124, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1125, CombTr_Loss: 1.09, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1126, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1127, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1128, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1129, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1130, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1131, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1132, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1133, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1134, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1135, CombTr_Loss: 0.44, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1136, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1137, CombTr_Loss: 0.97, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1138, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1139, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1140, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1141, CombTr_Loss: 1.0, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1142, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1143, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1144, CombTr_Loss: 1.25, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1145, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1146, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1147, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1148, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1149, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1150, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1151, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1152, CombTr_Loss: 1.25, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1153, CombTr_Loss: 0.8, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1154, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1155, CombTr_Loss: 1.16, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1156, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1157, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1158, CombTr_Loss: 0.69, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1159, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1160, CombTr_Loss: 0.65, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1161, CombTr_Loss: 0.8, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1162, CombTr_Loss: 0.76, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1163, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1164, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1165, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1166, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1167, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1168, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1169, CombTr_Loss: 1.08, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1170, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1171, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1172, CombTr_Loss: 0.78, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1173, CombTr_Loss: 0.69, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1174, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1175, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1176, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1177, CombTr_Loss: 0.69, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1178, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1179, CombTr_Loss: 0.98, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1180, CombTr_Loss: 0.47, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1181, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1182, CombTr_Loss: 1.01, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1183, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1184, CombTr_Loss: 0.8, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1185, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1186, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1187, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1188, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1189, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1190, CombTr_Loss: 1.11, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1191, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1192, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1193, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1194, CombTr_Loss: 1.64, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1195, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1196, CombTr_Loss: 1.35, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1197, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1198, CombTr_Loss: 1.22, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1199, CombTr_Loss: 0.42, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1200, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1201, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1202, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1203, CombTr_Loss: 0.88, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1204, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1205, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1206, CombTr_Loss: 1.51, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1207, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1208, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1209, CombTr_Loss: 1.19, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1210, CombTr_Loss: 1.01, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1211, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1212, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1213, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1214, CombTr_Loss: 1.06, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1215, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1216, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1217, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1218, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Step: 1219, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1220, CombTr_Loss: 1.02, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1221, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1222, CombTr_Loss: 1.07, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1223, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1224, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1225, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1226, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1227, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1228, CombTr_Loss: 0.35, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1229, CombTr_Loss: 1.3, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1230, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1231, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1232, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1233, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1234, CombTr_Loss: 0.97, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1235, CombTr_Loss: 1.07, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1236, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1237, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1238, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1239, CombTr_Loss: 1.69, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1240, CombTr_Loss: 0.69, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1241, CombTr_Loss: 1.24, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1242, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1243, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1244, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1245, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1246, CombTr_Loss: 0.85, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1247, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1248, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1249, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1250, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1251, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1252, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1253, CombTr_Loss: 1.13, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1254, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1255, CombTr_Loss: 0.62, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1256, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1257, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1258, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1259, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1260, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1261, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1262, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1263, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1264, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1265, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1266, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1267, CombTr_Loss: 0.77, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1268, CombTr_Loss: 0.63, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1269, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1270, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1271, CombTr_Loss: 0.32, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1272, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1273, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1274, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1275, CombTr_Loss: 1.46, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 1276, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1277, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1278, CombTr_Loss: 1.26, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1279, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1280, CombTr_Loss: 1.22, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1281, CombTr_Loss: 0.28, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1282, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1283, CombTr_Loss: 2.39, CombTr_Acc: 0.1\n",
      "Epoch: 2, Step: 1284, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1285, CombTr_Loss: 0.95, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1286, CombTr_Loss: 0.68, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1287, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1288, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1289, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1290, CombTr_Loss: 1.13, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1291, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1292, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1293, CombTr_Loss: 1.01, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1294, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1295, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1296, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1297, CombTr_Loss: 1.15, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1298, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1299, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1300, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1301, CombTr_Loss: 0.4, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1302, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1303, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1304, CombTr_Loss: 0.82, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1305, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1306, CombTr_Loss: 1.34, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1307, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1308, CombTr_Loss: 1.31, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 1309, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1310, CombTr_Loss: 1.46, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1311, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1312, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1313, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1314, CombTr_Loss: 0.6, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1315, CombTr_Loss: 0.95, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1316, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1317, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1318, CombTr_Loss: 1.27, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1319, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1320, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1321, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1322, CombTr_Loss: 1.47, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1323, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1324, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1325, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1326, CombTr_Loss: 1.11, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1327, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1328, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1329, CombTr_Loss: 1.45, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1330, CombTr_Loss: 0.85, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1331, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1332, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1333, CombTr_Loss: 1.27, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1334, CombTr_Loss: 1.18, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1335, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1336, CombTr_Loss: 1.38, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 1337, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1338, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1339, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1340, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1341, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1342, CombTr_Loss: 0.97, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1343, CombTr_Loss: 0.99, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1344, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1345, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1346, CombTr_Loss: 0.39, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1347, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1348, CombTr_Loss: 0.69, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1349, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1350, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1351, CombTr_Loss: 1.19, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1352, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1353, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1354, CombTr_Loss: 0.73, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1355, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1356, CombTr_Loss: 0.93, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1357, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1358, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1359, CombTr_Loss: 0.66, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1360, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1361, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1362, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1363, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1364, CombTr_Loss: 0.4, CombTr_Acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Step: 1365, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1366, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1367, CombTr_Loss: 1.26, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1368, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1369, CombTr_Loss: 0.91, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1370, CombTr_Loss: 1.47, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1371, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1372, CombTr_Loss: 1.04, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1373, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1374, CombTr_Loss: 0.88, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1375, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1376, CombTr_Loss: 0.63, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1377, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1378, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1379, CombTr_Loss: 1.38, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1380, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1381, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1382, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1383, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1384, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1385, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1386, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1387, CombTr_Loss: 0.3, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1388, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1389, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1390, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1391, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1392, CombTr_Loss: 1.0, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1393, CombTr_Loss: 0.59, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1394, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1395, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1396, CombTr_Loss: 0.47, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1397, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1398, CombTr_Loss: 0.77, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1399, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1400, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1401, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1402, CombTr_Loss: 0.59, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1403, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1404, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1405, CombTr_Loss: 1.76, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1406, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1407, CombTr_Loss: 1.1, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1408, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1409, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1410, CombTr_Loss: 0.92, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1411, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1412, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1413, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1414, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1415, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1416, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1417, CombTr_Loss: 1.52, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1418, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1419, CombTr_Loss: 0.68, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1420, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1421, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1422, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1423, CombTr_Loss: 0.28, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1424, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1425, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1426, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1427, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1428, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1429, CombTr_Loss: 1.19, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1430, CombTr_Loss: 1.11, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1431, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1432, CombTr_Loss: 0.94, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1433, CombTr_Loss: 1.02, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1434, CombTr_Loss: 1.24, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1435, CombTr_Loss: 1.35, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1436, CombTr_Loss: 1.62, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 1437, CombTr_Loss: 0.54, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1438, CombTr_Loss: 0.67, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1439, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1440, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1441, CombTr_Loss: 0.95, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1442, CombTr_Loss: 0.93, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1443, CombTr_Loss: 1.33, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1444, CombTr_Loss: 0.69, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1445, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1446, CombTr_Loss: 1.05, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1447, CombTr_Loss: 0.95, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1448, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1449, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1450, CombTr_Loss: 1.0, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1451, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1452, CombTr_Loss: 0.84, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1453, CombTr_Loss: 0.99, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1454, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1455, CombTr_Loss: 0.59, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1456, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1457, CombTr_Loss: 1.36, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1458, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1459, CombTr_Loss: 0.64, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1460, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1461, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1462, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1463, CombTr_Loss: 0.81, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1464, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1465, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1466, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1467, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1468, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1469, CombTr_Loss: 0.86, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1470, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1471, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1472, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1473, CombTr_Loss: 1.07, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1474, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1475, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1476, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1477, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1478, CombTr_Loss: 1.45, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1479, CombTr_Loss: 1.1, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1480, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1481, CombTr_Loss: 0.86, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1482, CombTr_Loss: 1.0, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1483, CombTr_Loss: 1.6, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1484, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1485, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1486, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1487, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1488, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1489, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1490, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1491, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1492, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1493, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1494, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1495, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1496, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1497, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1498, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1499, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1500, CombTr_Loss: 1.47, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1501, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1502, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1503, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1504, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1505, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1506, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1507, CombTr_Loss: 0.56, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1508, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1509, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Step: 1510, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1511, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1512, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1513, CombTr_Loss: 1.11, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1514, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1515, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1516, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1517, CombTr_Loss: 1.48, CombTr_Acc: 0.3\n",
      "Epoch: 2, Step: 1518, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1519, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1520, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1521, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1522, CombTr_Loss: 1.72, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1523, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1524, CombTr_Loss: 0.41, CombTr_Acc: 1.0\n",
      "Epoch: 2, Step: 1525, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1526, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1527, CombTr_Loss: 1.31, CombTr_Acc: 0.4\n",
      "Epoch: 2, Step: 1528, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1529, CombTr_Loss: 0.94, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1530, CombTr_Loss: 1.23, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1531, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1532, CombTr_Loss: 1.17, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1533, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1534, CombTr_Loss: 0.84, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1535, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1536, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1537, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1538, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1539, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1540, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1541, CombTr_Loss: 1.0, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1542, CombTr_Loss: 0.46, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1543, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 2, Step: 1544, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1545, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1546, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1547, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1548, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1549, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1550, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1551, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1552, CombTr_Loss: 0.67, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1553, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1554, CombTr_Loss: 0.51, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1555, CombTr_Loss: 0.9, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1556, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1557, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1558, CombTr_Loss: 0.42, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1559, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 2, Step: 1560, CombTr_Loss: 1.31, CombTr_Acc: 0.7\n",
      "Epoch: 2, Step: 1561, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1562, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 2, Step: 1563, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 2, Step: 1564, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Avg_CombTrain_Loss: 0.82, Avg_CombTrain_Acc: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [05:33<49:09, 163.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 2\n",
      "Epoch: 3, Step: 1565, CombTr_Loss: 0.92, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1566, CombTr_Loss: 1.07, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1567, CombTr_Loss: 0.38, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1568, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1569, CombTr_Loss: 1.22, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1570, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1571, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1572, CombTr_Loss: 1.02, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1573, CombTr_Loss: 1.19, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1574, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1575, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1576, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1577, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1578, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1579, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1580, CombTr_Loss: 1.57, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1581, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1582, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1583, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1584, CombTr_Loss: 0.91, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1585, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1586, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1587, CombTr_Loss: 0.9, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1588, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1589, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1590, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1591, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1592, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1593, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1594, CombTr_Loss: 0.76, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1595, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1596, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1597, CombTr_Loss: 0.73, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1598, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1599, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1600, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1601, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1602, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1603, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1604, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1605, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1606, CombTr_Loss: 1.06, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1607, CombTr_Loss: 1.34, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1608, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1609, CombTr_Loss: 1.05, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1610, CombTr_Loss: 0.93, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1611, CombTr_Loss: 1.23, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1612, CombTr_Loss: 0.92, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1613, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1614, CombTr_Loss: 1.26, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1615, CombTr_Loss: 1.14, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1616, CombTr_Loss: 1.01, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1617, CombTr_Loss: 1.52, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1618, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1619, CombTr_Loss: 0.94, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1620, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1621, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1622, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1623, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1624, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1625, CombTr_Loss: 1.03, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1626, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1627, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1628, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1629, CombTr_Loss: 0.86, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1630, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1631, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1632, CombTr_Loss: 0.98, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1633, CombTr_Loss: 0.54, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1634, CombTr_Loss: 1.25, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1635, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1636, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1637, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1638, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1639, CombTr_Loss: 0.95, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1640, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1641, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1642, CombTr_Loss: 0.66, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1643, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1644, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1645, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1646, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1647, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1648, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1649, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1650, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1651, CombTr_Loss: 1.11, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1652, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1653, CombTr_Loss: 0.89, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1654, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1655, CombTr_Loss: 1.2, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1656, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1657, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1658, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1659, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1660, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1661, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1662, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1663, CombTr_Loss: 1.22, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1664, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1665, CombTr_Loss: 0.57, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1666, CombTr_Loss: 0.91, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1667, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1668, CombTr_Loss: 0.63, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1669, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1670, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1671, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1672, CombTr_Loss: 0.94, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1673, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1674, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1675, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1676, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1677, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1678, CombTr_Loss: 1.33, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1679, CombTr_Loss: 0.27, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1680, CombTr_Loss: 0.26, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1681, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1682, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1683, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1684, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1685, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1686, CombTr_Loss: 1.11, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1687, CombTr_Loss: 1.31, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1688, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1689, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1690, CombTr_Loss: 0.93, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1691, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1692, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1693, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1694, CombTr_Loss: 1.47, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1695, CombTr_Loss: 0.69, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1696, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1697, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1698, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1699, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1700, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1701, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1702, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1703, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1704, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1705, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1706, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1707, CombTr_Loss: 1.35, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1708, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Step: 1709, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1710, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1711, CombTr_Loss: 1.52, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1712, CombTr_Loss: 1.38, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1713, CombTr_Loss: 0.28, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1714, CombTr_Loss: 1.18, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1715, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1716, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1717, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1718, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1719, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1720, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1721, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1722, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1723, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1724, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1725, CombTr_Loss: 0.79, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1726, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1727, CombTr_Loss: 1.09, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1728, CombTr_Loss: 1.1, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1729, CombTr_Loss: 0.68, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1730, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1731, CombTr_Loss: 0.47, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1732, CombTr_Loss: 1.2, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1733, CombTr_Loss: 1.08, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1734, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1735, CombTr_Loss: 1.04, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1736, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1737, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1738, CombTr_Loss: 1.12, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1739, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1740, CombTr_Loss: 1.22, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1741, CombTr_Loss: 1.4, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1742, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1743, CombTr_Loss: 1.04, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1744, CombTr_Loss: 1.16, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1745, CombTr_Loss: 1.87, CombTr_Acc: 0.3\n",
      "Epoch: 3, Step: 1746, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1747, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1748, CombTr_Loss: 1.64, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1749, CombTr_Loss: 0.65, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1750, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1751, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1752, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1753, CombTr_Loss: 0.68, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1754, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1755, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1756, CombTr_Loss: 1.01, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1757, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1758, CombTr_Loss: 0.58, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1759, CombTr_Loss: 0.87, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1760, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1761, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1762, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1763, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1764, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1765, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1766, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1767, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1768, CombTr_Loss: 0.62, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1769, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1770, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1771, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1772, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1773, CombTr_Loss: 0.52, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1774, CombTr_Loss: 1.38, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1775, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1776, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1777, CombTr_Loss: 0.93, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1778, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1779, CombTr_Loss: 1.04, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1780, CombTr_Loss: 1.9, CombTr_Acc: 0.3\n",
      "Epoch: 3, Step: 1781, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1782, CombTr_Loss: 1.05, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1783, CombTr_Loss: 1.24, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1784, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1785, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1786, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1787, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1788, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1789, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1790, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1791, CombTr_Loss: 1.26, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1792, CombTr_Loss: 0.83, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1793, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1794, CombTr_Loss: 0.71, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1795, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1796, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1797, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1798, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1799, CombTr_Loss: 1.01, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1800, CombTr_Loss: 1.15, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1801, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1802, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1803, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1804, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1805, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1806, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1807, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1808, CombTr_Loss: 0.97, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1809, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1810, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1811, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1812, CombTr_Loss: 0.76, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1813, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1814, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1815, CombTr_Loss: 1.34, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1816, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1817, CombTr_Loss: 1.01, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1818, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1819, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1820, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1821, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1822, CombTr_Loss: 1.41, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1823, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1824, CombTr_Loss: 0.65, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1825, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1826, CombTr_Loss: 0.61, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1827, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1828, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1829, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1830, CombTr_Loss: 0.27, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1831, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1832, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1833, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1834, CombTr_Loss: 0.87, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1835, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1836, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1837, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1838, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1839, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1840, CombTr_Loss: 0.86, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1841, CombTr_Loss: 1.02, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1842, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1843, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1844, CombTr_Loss: 1.94, CombTr_Acc: 0.3\n",
      "Epoch: 3, Step: 1845, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1846, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1847, CombTr_Loss: 0.99, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1848, CombTr_Loss: 0.8, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1849, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1850, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1851, CombTr_Loss: 1.14, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1852, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1853, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Step: 1854, CombTr_Loss: 0.83, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1855, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1856, CombTr_Loss: 0.68, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1857, CombTr_Loss: 0.84, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1858, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1859, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1860, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1861, CombTr_Loss: 0.47, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1862, CombTr_Loss: 1.51, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1863, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1864, CombTr_Loss: 0.77, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1865, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1866, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1867, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1868, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1869, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1870, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1871, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1872, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1873, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1874, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1875, CombTr_Loss: 0.84, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1876, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1877, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1878, CombTr_Loss: 0.91, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1879, CombTr_Loss: 1.28, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1880, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1881, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1882, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1883, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1884, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1885, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1886, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1887, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1888, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1889, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1890, CombTr_Loss: 1.07, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1891, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1892, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1893, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1894, CombTr_Loss: 0.41, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1895, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1896, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1897, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1898, CombTr_Loss: 1.24, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1899, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1900, CombTr_Loss: 0.78, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1901, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1902, CombTr_Loss: 0.93, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1903, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1904, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1905, CombTr_Loss: 1.38, CombTr_Acc: 0.3\n",
      "Epoch: 3, Step: 1906, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1907, CombTr_Loss: 0.75, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1908, CombTr_Loss: 1.09, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1909, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1910, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1911, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1912, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1913, CombTr_Loss: 0.59, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1914, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1915, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1916, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1917, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1918, CombTr_Loss: 1.19, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1919, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1920, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1921, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1922, CombTr_Loss: 1.21, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1923, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1924, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1925, CombTr_Loss: 0.84, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1926, CombTr_Loss: 1.01, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1927, CombTr_Loss: 0.38, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1928, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1929, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1930, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1931, CombTr_Loss: 0.29, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1932, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1933, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1934, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1935, CombTr_Loss: 1.19, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1936, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1937, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1938, CombTr_Loss: 1.88, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1939, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1940, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1941, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1942, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1943, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1944, CombTr_Loss: 1.64, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1945, CombTr_Loss: 1.61, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1946, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1947, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1948, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1949, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1950, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1951, CombTr_Loss: 0.71, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1952, CombTr_Loss: 1.46, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1953, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1954, CombTr_Loss: 0.94, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1955, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1956, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1957, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1958, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1959, CombTr_Loss: 1.23, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1960, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1961, CombTr_Loss: 0.67, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1962, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1963, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1964, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1965, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1966, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1967, CombTr_Loss: 1.19, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1968, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1969, CombTr_Loss: 0.34, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1970, CombTr_Loss: 0.39, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1971, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1972, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1973, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1974, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1975, CombTr_Loss: 0.78, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1976, CombTr_Loss: 1.48, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 1977, CombTr_Loss: 0.47, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1978, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1979, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1980, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 1981, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1982, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1983, CombTr_Loss: 0.28, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 1984, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1985, CombTr_Loss: 0.78, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1986, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1987, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1988, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1989, CombTr_Loss: 0.93, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1990, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1991, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1992, CombTr_Loss: 1.74, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1993, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 1994, CombTr_Loss: 1.61, CombTr_Acc: 0.3\n",
      "Epoch: 3, Step: 1995, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 1996, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 1997, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 1998, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Step: 1999, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2000, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2001, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2002, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2003, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2004, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2005, CombTr_Loss: 0.56, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2006, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2007, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2008, CombTr_Loss: 1.34, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2009, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2010, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2011, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2012, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2013, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2014, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2015, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2016, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2017, CombTr_Loss: 0.94, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2018, CombTr_Loss: 0.66, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2019, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2020, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2021, CombTr_Loss: 0.9, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2022, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2023, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2024, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2025, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2026, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2027, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2028, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2029, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2030, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2031, CombTr_Loss: 1.02, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2032, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2033, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2034, CombTr_Loss: 0.6, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2035, CombTr_Loss: 1.12, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2036, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2037, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2038, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2039, CombTr_Loss: 0.51, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2040, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2041, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2042, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2043, CombTr_Loss: 0.54, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2044, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2045, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2046, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2047, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2048, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2049, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2050, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2051, CombTr_Loss: 0.92, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2052, CombTr_Loss: 1.32, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 2053, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2054, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2055, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2056, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2057, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2058, CombTr_Loss: 0.51, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2059, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2060, CombTr_Loss: 1.5, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 2061, CombTr_Loss: 0.32, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2062, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2063, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2064, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2065, CombTr_Loss: 1.39, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2066, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2067, CombTr_Loss: 1.25, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2068, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2069, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2070, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2071, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2072, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2073, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2074, CombTr_Loss: 0.42, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2075, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2076, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2077, CombTr_Loss: 0.55, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2078, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2079, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2080, CombTr_Loss: 0.2, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2081, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2082, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2083, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2084, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2085, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2086, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2087, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2088, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2089, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2090, CombTr_Loss: 0.98, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2091, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2092, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2093, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2094, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2095, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2096, CombTr_Loss: 0.76, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2097, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2098, CombTr_Loss: 0.43, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2099, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2100, CombTr_Loss: 0.87, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2101, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2102, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2103, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2104, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2105, CombTr_Loss: 0.69, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2106, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2107, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2108, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2109, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2110, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2111, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2112, CombTr_Loss: 1.12, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2113, CombTr_Loss: 0.61, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2114, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2115, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2116, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2117, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2118, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2119, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2120, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2121, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2122, CombTr_Loss: 1.39, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2123, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2124, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2125, CombTr_Loss: 1.09, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2126, CombTr_Loss: 0.63, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2127, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2128, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2129, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2130, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2131, CombTr_Loss: 0.4, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2132, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2133, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2134, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2135, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2136, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2137, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2138, CombTr_Loss: 0.92, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2139, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2140, CombTr_Loss: 0.58, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2141, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2142, CombTr_Loss: 1.06, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2143, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Step: 2144, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2145, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2146, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2147, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2148, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2149, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2150, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2151, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2152, CombTr_Loss: 1.05, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 2153, CombTr_Loss: 0.43, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2154, CombTr_Loss: 0.69, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2155, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2156, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2157, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2158, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2159, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2160, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2161, CombTr_Loss: 1.35, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2162, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2163, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2164, CombTr_Loss: 0.85, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2165, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2166, CombTr_Loss: 0.38, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2167, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2168, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2169, CombTr_Loss: 0.96, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2170, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2171, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2172, CombTr_Loss: 0.51, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2173, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2174, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2175, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2176, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2177, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2178, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2179, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2180, CombTr_Loss: 0.28, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2181, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2182, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2183, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2184, CombTr_Loss: 0.81, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2185, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2186, CombTr_Loss: 0.98, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2187, CombTr_Loss: 1.46, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 2188, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2189, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2190, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2191, CombTr_Loss: 1.46, CombTr_Acc: 0.3\n",
      "Epoch: 3, Step: 2192, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2193, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2194, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2195, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2196, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2197, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2198, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2199, CombTr_Loss: 1.48, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2200, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2201, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2202, CombTr_Loss: 0.57, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2203, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2204, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2205, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2206, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2207, CombTr_Loss: 0.97, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2208, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2209, CombTr_Loss: 0.26, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2210, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2211, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2212, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2213, CombTr_Loss: 0.98, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2214, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2215, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2216, CombTr_Loss: 1.4, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 2217, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2218, CombTr_Loss: 0.65, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2219, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2220, CombTr_Loss: 0.8, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2221, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2222, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2223, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2224, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2225, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2226, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2227, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2228, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2229, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2230, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2231, CombTr_Loss: 1.04, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2232, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2233, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2234, CombTr_Loss: 0.8, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2235, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2236, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2237, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2238, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2239, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2240, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2241, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2242, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2243, CombTr_Loss: 1.02, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2244, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2245, CombTr_Loss: 1.09, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2246, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2247, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2248, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2249, CombTr_Loss: 1.05, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2250, CombTr_Loss: 1.08, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2251, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2252, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2253, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2254, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2255, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2256, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2257, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2258, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2259, CombTr_Loss: 0.33, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2260, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2261, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2262, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2263, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2264, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2265, CombTr_Loss: 1.48, CombTr_Acc: 0.4\n",
      "Epoch: 3, Step: 2266, CombTr_Loss: 0.54, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2267, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2268, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2269, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2270, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2271, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2272, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2273, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2274, CombTr_Loss: 0.49, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2275, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2276, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2277, CombTr_Loss: 1.16, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2278, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2279, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2280, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2281, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2282, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2283, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2284, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2285, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2286, CombTr_Loss: 0.3, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2287, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2288, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Step: 2289, CombTr_Loss: 0.34, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2290, CombTr_Loss: 0.84, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2291, CombTr_Loss: 1.26, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2292, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2293, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2294, CombTr_Loss: 0.38, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2295, CombTr_Loss: 0.84, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2296, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2297, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2298, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2299, CombTr_Loss: 1.35, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2300, CombTr_Loss: 0.66, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2301, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2302, CombTr_Loss: 1.1, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2303, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2304, CombTr_Loss: 1.15, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2305, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2306, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2307, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2308, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2309, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2310, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2311, CombTr_Loss: 0.73, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2312, CombTr_Loss: 0.98, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2313, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2314, CombTr_Loss: 0.69, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2315, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2316, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2317, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2318, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2319, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2320, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2321, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2322, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2323, CombTr_Loss: 0.67, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2324, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2325, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2326, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2327, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2328, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2329, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2330, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2331, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2332, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2333, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 3, Step: 2334, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2335, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2336, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2337, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2338, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2339, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2340, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2341, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 3, Step: 2342, CombTr_Loss: 0.92, CombTr_Acc: 0.5\n",
      "Epoch: 3, Step: 2343, CombTr_Loss: 0.2, CombTr_Acc: 1.0\n",
      "Epoch: 3, Step: 2344, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 3, Step: 2345, CombTr_Loss: 0.68, CombTr_Acc: 0.6\n",
      "Epoch: 3, Step: 2346, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Avg_CombTrain_Loss: 0.7, Avg_CombTrain_Acc: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [08:11<45:58, 162.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 3\n",
      "Epoch: 4, Step: 2347, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2348, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2349, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2350, CombTr_Loss: 0.44, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2351, CombTr_Loss: 1.1, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2352, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2353, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2354, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2355, CombTr_Loss: 0.86, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2356, CombTr_Loss: 1.41, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2357, CombTr_Loss: 0.3, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2358, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2359, CombTr_Loss: 1.02, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2360, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2361, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2362, CombTr_Loss: 1.4, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2363, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2364, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2365, CombTr_Loss: 1.17, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2366, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2367, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2368, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2369, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2370, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2371, CombTr_Loss: 0.85, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2372, CombTr_Loss: 0.47, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2373, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2374, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2375, CombTr_Loss: 0.5, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2376, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2377, CombTr_Loss: 0.33, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2378, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2379, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2380, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2381, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2382, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2383, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2384, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2385, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2386, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2387, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2388, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2389, CombTr_Loss: 0.51, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2390, CombTr_Loss: 1.41, CombTr_Acc: 0.3\n",
      "Epoch: 4, Step: 2391, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2392, CombTr_Loss: 1.08, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2393, CombTr_Loss: 0.85, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2394, CombTr_Loss: 1.31, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2395, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2396, CombTr_Loss: 1.62, CombTr_Acc: 0.3\n",
      "Epoch: 4, Step: 2397, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2398, CombTr_Loss: 0.91, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2399, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2400, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2401, CombTr_Loss: 0.91, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2402, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2403, CombTr_Loss: 1.04, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2404, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2405, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2406, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2407, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2408, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2409, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2410, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2411, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2412, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2413, CombTr_Loss: 0.95, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2414, CombTr_Loss: 0.68, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2415, CombTr_Loss: 0.31, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2416, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2417, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2418, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2419, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2420, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2421, CombTr_Loss: 0.38, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2422, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2423, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2424, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2425, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2426, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2427, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2428, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2429, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2430, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2431, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2432, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2433, CombTr_Loss: 1.12, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2434, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2435, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2436, CombTr_Loss: 0.47, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2437, CombTr_Loss: 0.79, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2438, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2439, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2440, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2441, CombTr_Loss: 0.29, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2442, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2443, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2444, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2445, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2446, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2447, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2448, CombTr_Loss: 0.4, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2449, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2450, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2451, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2452, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2453, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2454, CombTr_Loss: 1.11, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2455, CombTr_Loss: 0.93, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2456, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2457, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2458, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2459, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2460, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2461, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2462, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2463, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2464, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2465, CombTr_Loss: 0.38, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2466, CombTr_Loss: 0.92, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2467, CombTr_Loss: 0.87, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2468, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2469, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2470, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2471, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2472, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2473, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2474, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2475, CombTr_Loss: 0.62, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2476, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2477, CombTr_Loss: 0.36, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2478, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2479, CombTr_Loss: 0.71, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2480, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2481, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2482, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2483, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2484, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2485, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2486, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2487, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2488, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2489, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2490, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Step: 2491, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2492, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2493, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2494, CombTr_Loss: 1.11, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2495, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2496, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2497, CombTr_Loss: 0.56, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2498, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2499, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2500, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2501, CombTr_Loss: 0.26, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2502, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2503, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2504, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2505, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2506, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2507, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2508, CombTr_Loss: 0.3, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2509, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2510, CombTr_Loss: 1.43, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2511, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2512, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2513, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2514, CombTr_Loss: 1.04, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2515, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2516, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2517, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2518, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2519, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2520, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2521, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2522, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2523, CombTr_Loss: 0.98, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2524, CombTr_Loss: 0.49, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2525, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2526, CombTr_Loss: 0.58, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2527, CombTr_Loss: 0.37, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2528, CombTr_Loss: 2.27, CombTr_Acc: 0.2\n",
      "Epoch: 4, Step: 2529, CombTr_Loss: 0.51, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2530, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2531, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2532, CombTr_Loss: 1.35, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2533, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2534, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2535, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2536, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2537, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2538, CombTr_Loss: 0.83, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2539, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2540, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2541, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2542, CombTr_Loss: 0.83, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2543, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2544, CombTr_Loss: 0.9, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2545, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2546, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2547, CombTr_Loss: 0.49, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2548, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2549, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2550, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2551, CombTr_Loss: 0.64, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2552, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2553, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2554, CombTr_Loss: 0.7, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2555, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2556, CombTr_Loss: 0.81, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2557, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2558, CombTr_Loss: 0.38, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2559, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2560, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2561, CombTr_Loss: 1.3, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2562, CombTr_Loss: 1.04, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2563, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2564, CombTr_Loss: 1.03, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2565, CombTr_Loss: 0.84, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2566, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2567, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2568, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2569, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2570, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2571, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2572, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2573, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2574, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2575, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2576, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2577, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2578, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2579, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2580, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2581, CombTr_Loss: 0.49, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2582, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2583, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2584, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2585, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2586, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2587, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2588, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2589, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2590, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2591, CombTr_Loss: 0.71, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2592, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2593, CombTr_Loss: 0.49, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2594, CombTr_Loss: 0.51, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2595, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2596, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2597, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2598, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2599, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2600, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2601, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2602, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2603, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2604, CombTr_Loss: 1.45, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2605, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2606, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2607, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2608, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2609, CombTr_Loss: 0.43, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2610, CombTr_Loss: 0.45, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2611, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2612, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2613, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2614, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2615, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2616, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2617, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2618, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2619, CombTr_Loss: 0.44, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2620, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2621, CombTr_Loss: 1.19, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2622, CombTr_Loss: 0.96, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2623, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2624, CombTr_Loss: 0.6, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2625, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2626, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2627, CombTr_Loss: 0.44, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2628, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2629, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2630, CombTr_Loss: 1.27, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2631, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2632, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2633, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2634, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2635, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Step: 2636, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2637, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2638, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2639, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2640, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2641, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2642, CombTr_Loss: 0.78, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2643, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2644, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2645, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2646, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2647, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2648, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2649, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2650, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2651, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2652, CombTr_Loss: 0.15, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2653, CombTr_Loss: 0.31, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2654, CombTr_Loss: 0.29, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2655, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2656, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2657, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2658, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2659, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2660, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2661, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2662, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2663, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2664, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2665, CombTr_Loss: 0.75, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2666, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2667, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2668, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2669, CombTr_Loss: 0.51, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2670, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2671, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2672, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2673, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2674, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2675, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2676, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2677, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2678, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2679, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2680, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2681, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2682, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2683, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2684, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2685, CombTr_Loss: 1.06, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2686, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2687, CombTr_Loss: 1.1, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2688, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2689, CombTr_Loss: 0.49, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2690, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2691, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2692, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2693, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2694, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2695, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2696, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2697, CombTr_Loss: 0.78, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2698, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2699, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2700, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2701, CombTr_Loss: 1.73, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2702, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2703, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2704, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2705, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2706, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2707, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2708, CombTr_Loss: 1.06, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2709, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2710, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2711, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2712, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2713, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2714, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2715, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2716, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2717, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2718, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2719, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2720, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2721, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2722, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2723, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2724, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2725, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2726, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2727, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2728, CombTr_Loss: 0.28, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2729, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2730, CombTr_Loss: 0.63, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2731, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2732, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2733, CombTr_Loss: 0.51, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2734, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2735, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2736, CombTr_Loss: 0.3, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2737, CombTr_Loss: 0.51, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2738, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2739, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2740, CombTr_Loss: 0.95, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2741, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2742, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2743, CombTr_Loss: 0.89, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2744, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2745, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2746, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2747, CombTr_Loss: 0.71, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2748, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2749, CombTr_Loss: 0.61, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2750, CombTr_Loss: 0.43, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2751, CombTr_Loss: 0.26, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2752, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2753, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2754, CombTr_Loss: 0.55, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2755, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2756, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2757, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2758, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2759, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2760, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2761, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2762, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2763, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2764, CombTr_Loss: 0.83, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2765, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2766, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2767, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2768, CombTr_Loss: 0.42, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2769, CombTr_Loss: 0.68, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2770, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2771, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2772, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2773, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2774, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2775, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2776, CombTr_Loss: 0.82, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2777, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2778, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2779, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2780, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Step: 2781, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2782, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2783, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2784, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2785, CombTr_Loss: 0.71, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2786, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2787, CombTr_Loss: 0.31, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2788, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2789, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2790, CombTr_Loss: 1.41, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2791, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2792, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2793, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2794, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2795, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2796, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2797, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2798, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2799, CombTr_Loss: 0.86, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2800, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2801, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2802, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2803, CombTr_Loss: 0.79, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2804, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2805, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2806, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2807, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2808, CombTr_Loss: 0.74, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2809, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2810, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2811, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2812, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2813, CombTr_Loss: 0.94, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2814, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2815, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2816, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2817, CombTr_Loss: 0.9, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2818, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2819, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2820, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2821, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2822, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2823, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2824, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2825, CombTr_Loss: 0.33, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2826, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2827, CombTr_Loss: 0.84, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2828, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2829, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2830, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2831, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2832, CombTr_Loss: 0.43, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2833, CombTr_Loss: 0.29, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2834, CombTr_Loss: 0.97, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2835, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2836, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2837, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2838, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2839, CombTr_Loss: 1.0, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2840, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2841, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2842, CombTr_Loss: 0.61, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2843, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2844, CombTr_Loss: 0.64, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2845, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2846, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2847, CombTr_Loss: 1.28, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2848, CombTr_Loss: 0.84, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2849, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2850, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2851, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2852, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2853, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2854, CombTr_Loss: 1.09, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2855, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2856, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2857, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2858, CombTr_Loss: 0.26, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2859, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2860, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2861, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2862, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2863, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2864, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2865, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2866, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2867, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2868, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2869, CombTr_Loss: 0.41, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2870, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2871, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2872, CombTr_Loss: 0.97, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2873, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2874, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2875, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2876, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2877, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2878, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2879, CombTr_Loss: 0.4, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2880, CombTr_Loss: 0.26, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2881, CombTr_Loss: 0.58, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2882, CombTr_Loss: 1.5, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2883, CombTr_Loss: 0.98, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2884, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2885, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2886, CombTr_Loss: 0.93, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2887, CombTr_Loss: 1.06, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2888, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2889, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2890, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2891, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2892, CombTr_Loss: 0.29, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2893, CombTr_Loss: 0.68, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2894, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2895, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2896, CombTr_Loss: 0.32, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2897, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2898, CombTr_Loss: 0.99, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2899, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2900, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2901, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2902, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2903, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2904, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2905, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2906, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2907, CombTr_Loss: 0.63, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2908, CombTr_Loss: 0.98, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2909, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2910, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2911, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2912, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2913, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2914, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2915, CombTr_Loss: 0.45, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2916, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2917, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2918, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2919, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2920, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2921, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2922, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2923, CombTr_Loss: 0.56, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2924, CombTr_Loss: 0.63, CombTr_Acc: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Step: 2925, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2926, CombTr_Loss: 0.41, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2927, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2928, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2929, CombTr_Loss: 0.5, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2930, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2931, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2932, CombTr_Loss: 0.32, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2933, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2934, CombTr_Loss: 0.9, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2935, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2936, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2937, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2938, CombTr_Loss: 0.73, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2939, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2940, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2941, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2942, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2943, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2944, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2945, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2946, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2947, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2948, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2949, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2950, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2951, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2952, CombTr_Loss: 0.5, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2953, CombTr_Loss: 0.32, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2954, CombTr_Loss: 1.31, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2955, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2956, CombTr_Loss: 1.16, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2957, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2958, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2959, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2960, CombTr_Loss: 0.43, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2961, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2962, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2963, CombTr_Loss: 0.51, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2964, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2965, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2966, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2967, CombTr_Loss: 0.28, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2968, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2969, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2970, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2971, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2972, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2973, CombTr_Loss: 0.92, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2974, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2975, CombTr_Loss: 0.32, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2976, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2977, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2978, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2979, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2980, CombTr_Loss: 0.82, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2981, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2982, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2983, CombTr_Loss: 0.03, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2984, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 2985, CombTr_Loss: 0.92, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2986, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2987, CombTr_Loss: 0.2, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2988, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2989, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2990, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2991, CombTr_Loss: 0.56, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 2992, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2993, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2994, CombTr_Loss: 1.41, CombTr_Acc: 0.4\n",
      "Epoch: 4, Step: 2995, CombTr_Loss: 1.0, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 2996, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 2997, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 2998, CombTr_Loss: 1.05, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 2999, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3000, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3001, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3002, CombTr_Loss: 1.03, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3003, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3004, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3005, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3006, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3007, CombTr_Loss: 0.58, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3008, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3009, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3010, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3011, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3012, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3013, CombTr_Loss: 1.38, CombTr_Acc: 0.4\n",
      "Epoch: 4, Step: 3014, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3015, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3016, CombTr_Loss: 0.46, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3017, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3018, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3019, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3020, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3021, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3022, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3023, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3024, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3025, CombTr_Loss: 1.83, CombTr_Acc: 0.4\n",
      "Epoch: 4, Step: 3026, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3027, CombTr_Loss: 0.28, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3028, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3029, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3030, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3031, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3032, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3033, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3034, CombTr_Loss: 0.27, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3035, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3036, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3037, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3038, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3039, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3040, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3041, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3042, CombTr_Loss: 1.12, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3043, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3044, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3045, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3046, CombTr_Loss: 0.62, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3047, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3048, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3049, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3050, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3051, CombTr_Loss: 0.13, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3052, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3053, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3054, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3055, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3056, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3057, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3058, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3059, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3060, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3061, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3062, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3063, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3064, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3065, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3066, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3067, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3068, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3069, CombTr_Loss: 0.4, CombTr_Acc: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Step: 3070, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3071, CombTr_Loss: 0.38, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3072, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3073, CombTr_Loss: 0.37, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3074, CombTr_Loss: 0.58, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3075, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3076, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3077, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3078, CombTr_Loss: 1.08, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3079, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3080, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3081, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3082, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3083, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3084, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3085, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3086, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3087, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3088, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3089, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3090, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3091, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3092, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3093, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3094, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3095, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3096, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3097, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3098, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3099, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3100, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3101, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3102, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3103, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3104, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3105, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3106, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3107, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3108, CombTr_Loss: 0.29, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3109, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3110, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3111, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3112, CombTr_Loss: 0.5, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3113, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3114, CombTr_Loss: 0.97, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3115, CombTr_Loss: 0.41, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3116, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3117, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3118, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3119, CombTr_Loss: 1.07, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3120, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3121, CombTr_Loss: 0.56, CombTr_Acc: 0.7\n",
      "Epoch: 4, Step: 3122, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 4, Step: 3123, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3124, CombTr_Loss: 1.13, CombTr_Acc: 0.5\n",
      "Epoch: 4, Step: 3125, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 4, Step: 3126, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 4, Step: 3127, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 4, Step: 3128, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Avg_CombTrain_Loss: 0.5, Avg_CombTrain_Acc: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [11:09<44:31, 166.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 4\n",
      "Epoch: 5, Step: 3129, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3130, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3131, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3132, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3133, CombTr_Loss: 0.84, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3134, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3135, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3136, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3137, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3138, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3139, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3140, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3141, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3142, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3143, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3144, CombTr_Loss: 1.22, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3145, CombTr_Loss: 0.2, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3146, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3147, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3148, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3149, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3150, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3151, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3152, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3153, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3154, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3155, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3156, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3157, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3158, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3159, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3160, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3161, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3162, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3163, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3164, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3165, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3166, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3167, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3168, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3169, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3170, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3171, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3172, CombTr_Loss: 0.69, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3173, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3174, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3175, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3176, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3177, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3178, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3179, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3180, CombTr_Loss: 0.92, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3181, CombTr_Loss: 1.25, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3182, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3183, CombTr_Loss: 0.87, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3184, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3185, CombTr_Loss: 0.86, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3186, CombTr_Loss: 0.97, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3187, CombTr_Loss: 0.32, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3188, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3189, CombTr_Loss: 0.47, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3190, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3191, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3192, CombTr_Loss: 0.8, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3193, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3194, CombTr_Loss: 0.76, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3195, CombTr_Loss: 0.76, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3196, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3197, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3198, CombTr_Loss: 1.05, CombTr_Acc: 0.5\n",
      "Epoch: 5, Step: 3199, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3200, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3201, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3202, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3203, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3204, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3205, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3206, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3207, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3208, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3209, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3210, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3211, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3212, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3213, CombTr_Loss: 0.39, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3214, CombTr_Loss: 0.5, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3215, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3216, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3217, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3218, CombTr_Loss: 0.34, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3219, CombTr_Loss: 0.61, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3220, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3221, CombTr_Loss: 0.79, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3222, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3223, CombTr_Loss: 0.06, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3224, CombTr_Loss: 0.77, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3225, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3226, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3227, CombTr_Loss: 1.13, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3228, CombTr_Loss: 0.88, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3229, CombTr_Loss: 0.29, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3230, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3231, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3232, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3233, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3234, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3235, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3236, CombTr_Loss: 1.03, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3237, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3238, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3239, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3240, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3241, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3242, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3243, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3244, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3245, CombTr_Loss: 0.49, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3246, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3247, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3248, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3249, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3250, CombTr_Loss: 0.7, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3251, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3252, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3253, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3254, CombTr_Loss: 0.89, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3255, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3256, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3257, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3258, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3259, CombTr_Loss: 0.47, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3260, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3261, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3262, CombTr_Loss: 0.23, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3263, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3264, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3265, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3266, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3267, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3268, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3269, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3270, CombTr_Loss: 0.62, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3271, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3272, CombTr_Loss: 0.92, CombTr_Acc: 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Step: 3273, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3274, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3275, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3276, CombTr_Loss: 0.87, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3277, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3278, CombTr_Loss: 1.16, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3279, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3280, CombTr_Loss: 0.67, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3281, CombTr_Loss: 0.2, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3282, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3283, CombTr_Loss: 0.76, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3284, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3285, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3286, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3287, CombTr_Loss: 0.73, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3288, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3289, CombTr_Loss: 0.29, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3290, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3291, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3292, CombTr_Loss: 1.52, CombTr_Acc: 0.5\n",
      "Epoch: 5, Step: 3293, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3294, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3295, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3296, CombTr_Loss: 0.94, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3297, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3298, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3299, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3300, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3301, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3302, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3303, CombTr_Loss: 0.26, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3304, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3305, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3306, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3307, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3308, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3309, CombTr_Loss: 0.82, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3310, CombTr_Loss: 0.95, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3311, CombTr_Loss: 0.28, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3312, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3313, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3314, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3315, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3316, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3317, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3318, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3319, CombTr_Loss: 0.06, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3320, CombTr_Loss: 0.4, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3321, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3322, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3323, CombTr_Loss: 0.71, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3324, CombTr_Loss: 0.28, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3325, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3326, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3327, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3328, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3329, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3330, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3331, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3332, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3333, CombTr_Loss: 0.32, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3334, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3335, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3336, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3337, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3338, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3339, CombTr_Loss: 0.6, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3340, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3341, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3342, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3343, CombTr_Loss: 0.65, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3344, CombTr_Loss: 0.82, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3345, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3346, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3347, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3348, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3349, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3350, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3351, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3352, CombTr_Loss: 0.45, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3353, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3354, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3355, CombTr_Loss: 1.35, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3356, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3357, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3358, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3359, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3360, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3361, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3362, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3363, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3364, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3365, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3366, CombTr_Loss: 0.15, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3367, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3368, CombTr_Loss: 0.04, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3369, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3370, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3371, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3372, CombTr_Loss: 0.78, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3373, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3374, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3375, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3376, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3377, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3378, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3379, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3380, CombTr_Loss: 0.6, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3381, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3382, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3383, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3384, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3385, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3386, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3387, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3388, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3389, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3390, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3391, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3392, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3393, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3394, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3395, CombTr_Loss: 0.27, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3396, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3397, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3398, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3399, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3400, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3401, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3402, CombTr_Loss: 0.7, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3403, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3404, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3405, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3406, CombTr_Loss: 0.96, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3407, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3408, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3409, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3410, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3411, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3412, CombTr_Loss: 1.27, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3413, CombTr_Loss: 1.17, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3414, CombTr_Loss: 0.27, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3415, CombTr_Loss: 0.46, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3416, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Step: 3417, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3418, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3419, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3420, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3421, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3422, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3423, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3424, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3425, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3426, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3427, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3428, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3429, CombTr_Loss: 0.06, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3430, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3431, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3432, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3433, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3434, CombTr_Loss: 0.26, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3435, CombTr_Loss: 0.48, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3436, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3437, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3438, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3439, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3440, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3441, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3442, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3443, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3444, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3445, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3446, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3447, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3448, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3449, CombTr_Loss: 0.46, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3450, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3451, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3452, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3453, CombTr_Loss: 0.06, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3454, CombTr_Loss: 0.77, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3455, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3456, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3457, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3458, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3459, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3460, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3461, CombTr_Loss: 0.26, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3462, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3463, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3464, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3465, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3466, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3467, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3468, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3469, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3470, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3471, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3472, CombTr_Loss: 0.29, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3473, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3474, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3475, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3476, CombTr_Loss: 0.24, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3477, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3478, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3479, CombTr_Loss: 0.2, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3480, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3481, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3482, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3483, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3484, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3485, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3486, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3487, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3488, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3489, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3490, CombTr_Loss: 0.85, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3491, CombTr_Loss: 0.25, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3492, CombTr_Loss: 0.03, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3493, CombTr_Loss: 0.73, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3494, CombTr_Loss: 0.35, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3495, CombTr_Loss: 0.28, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3496, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3497, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3498, CombTr_Loss: 0.53, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3499, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3500, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3501, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3502, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3503, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3504, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3505, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3506, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3507, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3508, CombTr_Loss: 0.56, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3509, CombTr_Loss: 0.79, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3510, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3511, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3512, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3513, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3514, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3515, CombTr_Loss: 0.81, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3516, CombTr_Loss: 1.29, CombTr_Acc: 0.5\n",
      "Epoch: 5, Step: 3517, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3518, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3519, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3520, CombTr_Loss: 0.38, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3521, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3522, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3523, CombTr_Loss: 0.6, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3524, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3525, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3526, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3527, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3528, CombTr_Loss: 1.34, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3529, CombTr_Loss: 0.74, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3530, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3531, CombTr_Loss: 0.63, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3532, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3533, CombTr_Loss: 0.59, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3534, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3535, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3536, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3537, CombTr_Loss: 0.13, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3538, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3539, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3540, CombTr_Loss: 1.24, CombTr_Acc: 0.5\n",
      "Epoch: 5, Step: 3541, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3542, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3543, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3544, CombTr_Loss: 0.52, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3545, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3546, CombTr_Loss: 0.88, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3547, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3548, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3549, CombTr_Loss: 0.04, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3550, CombTr_Loss: 0.89, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3551, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3552, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3553, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3554, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3555, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3556, CombTr_Loss: 0.32, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3557, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3558, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3559, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3560, CombTr_Loss: 0.14, CombTr_Acc: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Step: 3561, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3562, CombTr_Loss: 0.42, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3563, CombTr_Loss: 0.37, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3564, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3565, CombTr_Loss: 0.74, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3566, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3567, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3568, CombTr_Loss: 0.91, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3569, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3570, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3571, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3572, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3573, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3574, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3575, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3576, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3577, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3578, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3579, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3580, CombTr_Loss: 1.13, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3581, CombTr_Loss: 0.72, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3582, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3583, CombTr_Loss: 0.59, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3584, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3585, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3586, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3587, CombTr_Loss: 0.81, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3588, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3589, CombTr_Loss: 0.27, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3590, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3591, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3592, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3593, CombTr_Loss: 0.34, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3594, CombTr_Loss: 0.39, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3595, CombTr_Loss: 0.5, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3596, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3597, CombTr_Loss: 0.15, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3598, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3599, CombTr_Loss: 0.85, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3600, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3601, CombTr_Loss: 0.31, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3602, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3603, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3604, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3605, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3606, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3607, CombTr_Loss: 0.64, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3608, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3609, CombTr_Loss: 0.52, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3610, CombTr_Loss: 0.56, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3611, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3612, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3613, CombTr_Loss: 0.2, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3614, CombTr_Loss: 1.01, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3615, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3616, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3617, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3618, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3619, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3620, CombTr_Loss: 0.65, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3621, CombTr_Loss: 1.03, CombTr_Acc: 0.5\n",
      "Epoch: 5, Step: 3622, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3623, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3624, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3625, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3626, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3627, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3628, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3629, CombTr_Loss: 0.62, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3630, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3631, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3632, CombTr_Loss: 0.33, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3633, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3634, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3635, CombTr_Loss: 0.44, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3636, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3637, CombTr_Loss: 0.4, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3638, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3639, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3640, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3641, CombTr_Loss: 1.0, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3642, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3643, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3644, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3645, CombTr_Loss: 0.54, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3646, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3647, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3648, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3649, CombTr_Loss: 0.5, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3650, CombTr_Loss: 0.22, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3651, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3652, CombTr_Loss: 0.52, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3653, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3654, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3655, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3656, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3657, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3658, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3659, CombTr_Loss: 0.35, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3660, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3661, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3662, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3663, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3664, CombTr_Loss: 0.93, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3665, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3666, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3667, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3668, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3669, CombTr_Loss: 0.89, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3670, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3671, CombTr_Loss: 0.32, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3672, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3673, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3674, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3675, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3676, CombTr_Loss: 0.21, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3677, CombTr_Loss: 0.06, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3678, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3679, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3680, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3681, CombTr_Loss: 0.54, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3682, CombTr_Loss: 0.54, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3683, CombTr_Loss: 0.47, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3684, CombTr_Loss: 0.66, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3685, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3686, CombTr_Loss: 1.39, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3687, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3688, CombTr_Loss: 0.49, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3689, CombTr_Loss: 0.57, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3690, CombTr_Loss: 0.92, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3691, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3692, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3693, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3694, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3695, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3696, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3697, CombTr_Loss: 0.24, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3698, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3699, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3700, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3701, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3702, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3703, CombTr_Loss: 0.43, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3704, CombTr_Loss: 0.55, CombTr_Acc: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Step: 3705, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3706, CombTr_Loss: 0.76, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3707, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3708, CombTr_Loss: 0.72, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3709, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3710, CombTr_Loss: 0.43, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3711, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3712, CombTr_Loss: 0.75, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3713, CombTr_Loss: 0.28, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3714, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3715, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3716, CombTr_Loss: 0.89, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3717, CombTr_Loss: 0.34, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3718, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3719, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3720, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3721, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3722, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3723, CombTr_Loss: 0.62, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3724, CombTr_Loss: 0.1, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3725, CombTr_Loss: 0.44, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3726, CombTr_Loss: 0.64, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3727, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3728, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3729, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3730, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3731, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3732, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3733, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3734, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3735, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3736, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3737, CombTr_Loss: 0.4, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3738, CombTr_Loss: 0.42, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3739, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3740, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3741, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3742, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3743, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3744, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3745, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3746, CombTr_Loss: 0.57, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3747, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3748, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3749, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3750, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3751, CombTr_Loss: 1.16, CombTr_Acc: 0.5\n",
      "Epoch: 5, Step: 3752, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3753, CombTr_Loss: 0.45, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3754, CombTr_Loss: 0.41, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3755, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3756, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3757, CombTr_Loss: 0.14, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3758, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3759, CombTr_Loss: 0.01, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3760, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3761, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3762, CombTr_Loss: 0.04, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3763, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3764, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3765, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3766, CombTr_Loss: 0.6, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3767, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3768, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3769, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3770, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3771, CombTr_Loss: 0.36, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3772, CombTr_Loss: 0.4, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3773, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3774, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3775, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3776, CombTr_Loss: 0.5, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3777, CombTr_Loss: 0.58, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3778, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3779, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3780, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3781, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3782, CombTr_Loss: 0.67, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3783, CombTr_Loss: 0.0, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3784, CombTr_Loss: 0.32, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3785, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3786, CombTr_Loss: 0.87, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3787, CombTr_Loss: 0.65, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3788, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3789, CombTr_Loss: 0.25, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3790, CombTr_Loss: 0.04, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3791, CombTr_Loss: 0.09, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3792, CombTr_Loss: 0.44, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3793, CombTr_Loss: 0.51, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3794, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3795, CombTr_Loss: 0.67, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3796, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3797, CombTr_Loss: 0.32, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3798, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3799, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3800, CombTr_Loss: 0.15, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3801, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3802, CombTr_Loss: 0.48, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3803, CombTr_Loss: 0.02, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3804, CombTr_Loss: 0.53, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3805, CombTr_Loss: 0.23, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3806, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3807, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3808, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3809, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3810, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3811, CombTr_Loss: 0.16, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3812, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3813, CombTr_Loss: 0.17, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3814, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3815, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3816, CombTr_Loss: 0.15, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3817, CombTr_Loss: 0.3, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3818, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3819, CombTr_Loss: 0.27, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3820, CombTr_Loss: 0.24, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3821, CombTr_Loss: 0.33, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3822, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3823, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3824, CombTr_Loss: 1.46, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3825, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3826, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3827, CombTr_Loss: 0.19, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3828, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3829, CombTr_Loss: 0.43, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3830, CombTr_Loss: 0.13, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3831, CombTr_Loss: 0.06, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3832, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3833, CombTr_Loss: 0.18, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3834, CombTr_Loss: 0.24, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3835, CombTr_Loss: 0.25, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3836, CombTr_Loss: 0.61, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3837, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3838, CombTr_Loss: 0.07, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3839, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3840, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3841, CombTr_Loss: 0.72, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3842, CombTr_Loss: 0.82, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3843, CombTr_Loss: 0.45, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3844, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3845, CombTr_Loss: 0.78, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3846, CombTr_Loss: 0.65, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3847, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3848, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3849, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Step: 3850, CombTr_Loss: 0.2, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3851, CombTr_Loss: 0.3, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3852, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3853, CombTr_Loss: 0.16, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3854, CombTr_Loss: 0.11, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3855, CombTr_Loss: 0.37, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3856, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3857, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3858, CombTr_Loss: 0.36, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3859, CombTr_Loss: 0.75, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3860, CombTr_Loss: 0.45, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3861, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3862, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3863, CombTr_Loss: 0.77, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3864, CombTr_Loss: 0.32, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3865, CombTr_Loss: 0.22, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3866, CombTr_Loss: 0.63, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3867, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3868, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3869, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3870, CombTr_Loss: 0.48, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3871, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3872, CombTr_Loss: 0.31, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3873, CombTr_Loss: 0.35, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3874, CombTr_Loss: 0.15, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3875, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3876, CombTr_Loss: 0.41, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3877, CombTr_Loss: 0.27, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3878, CombTr_Loss: 0.42, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3879, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3880, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3881, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3882, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3883, CombTr_Loss: 0.34, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3884, CombTr_Loss: 0.21, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3885, CombTr_Loss: 0.38, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3886, CombTr_Loss: 0.06, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3887, CombTr_Loss: 0.53, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3888, CombTr_Loss: 0.28, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3889, CombTr_Loss: 0.37, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3890, CombTr_Loss: 0.11, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3891, CombTr_Loss: 0.23, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3892, CombTr_Loss: 0.12, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3893, CombTr_Loss: 0.39, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3894, CombTr_Loss: 0.15, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3895, CombTr_Loss: 0.24, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3896, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3897, CombTr_Loss: 0.55, CombTr_Acc: 0.7\n",
      "Epoch: 5, Step: 3898, CombTr_Loss: 0.19, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3899, CombTr_Loss: 0.02, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3900, CombTr_Loss: 0.17, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3901, CombTr_Loss: 0.68, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3902, CombTr_Loss: 0.18, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3903, CombTr_Loss: 0.66, CombTr_Acc: 0.8\n",
      "Epoch: 5, Step: 3904, CombTr_Loss: 0.08, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3905, CombTr_Loss: 0.29, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3906, CombTr_Loss: 0.63, CombTr_Acc: 0.6\n",
      "Epoch: 5, Step: 3907, CombTr_Loss: 0.26, CombTr_Acc: 0.9\n",
      "Epoch: 5, Step: 3908, CombTr_Loss: 0.05, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3909, CombTr_Loss: 0.13, CombTr_Acc: 1.0\n",
      "Epoch: 5, Step: 3910, CombTr_Loss: 0.14, CombTr_Acc: 1.0\n",
      "Avg_CombTrain_Loss: 0.38, Avg_CombTrain_Acc: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [14:05<42:21, 169.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and weights saved at epoch 5\n",
      "Epoch: 6, Step: 3911, CombTr_Loss: 0.39, CombTr_Acc: 0.9\n",
      "Epoch: 6, Step: 3912, CombTr_Loss: 0.25, CombTr_Acc: 0.9\n",
      "Epoch: 6, Step: 3913, CombTr_Loss: 0.55, CombTr_Acc: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "SAVEDIR_COMB_TRAIN = \"./outputs_facedb/Bottleneck_Features/\"\n",
    "SAVEDIR_COMB_TRAIN_LABELS = \"./outputs_facedb/Bottleneck_Labels/\"\n",
    "\n",
    "\n",
    "SAVER = \"./outputs_facedb/Model_Save/\"\n",
    "\n",
    "input_shape = 10*10*512   #this is the shape of bottleneck feature of each image which comes after passing the image through VGG-16\n",
    "\n",
    "model = model(input_shape)\n",
    "# model.load_weights(os.path.join(SAVER, \"model.h5\"))\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 10\n",
    "step = 0\n",
    "combTrain_bottleneck_files = int(len(train_df) / batch_size)-1\n",
    "\n",
    "epoch_number, CombTrain_loss, CombTrain_acc = [], [], []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    avg_epoch_CombTr_loss, avg_epoch_CombTr_acc, avg_epoch_CombTe_loss, avg_epoch_CombTe_acc = 0, 0, 0, 0\n",
    "    epoch_number.append(epoch + 1)\n",
    "    \n",
    "    for i in range(combTrain_bottleneck_files):\n",
    "        \n",
    "        #try:\n",
    "        step += 1\n",
    "\n",
    "        #loading batch of train bottleneck features for training MLP.\n",
    "        X_CombTrain_load = np.load(os.path.join(SAVEDIR_COMB_TRAIN, \"bottleneck_{}.npy\".format(i+1)))\n",
    "        X_CombTrain = X_CombTrain_load.reshape(X_CombTrain_load.shape[0],\n",
    "                                               X_CombTrain_load.shape[1]*X_CombTrain_load.shape[2]*X_CombTrain_load.shape[3])\n",
    "        Y_CombTrain = np.load(os.path.join(SAVEDIR_COMB_TRAIN_LABELS, \"bottleneck_labels_{}.npy\".format(i+1)))\n",
    "\n",
    "\n",
    "        CombTrain_Loss, CombTrain_Accuracy = model.train_on_batch(X_CombTrain, Y_CombTrain) #train the model on batch\n",
    "\n",
    "        print(\"Epoch: {}, Step: {}, CombTr_Loss: {}, CombTr_Acc: {}\".format(epoch+1, step,\n",
    "                                                                            np.round(float(CombTrain_Loss), 2), \n",
    "                                                                            np.round(float(CombTrain_Accuracy),2)))\n",
    "\n",
    "        avg_epoch_CombTr_loss += CombTrain_Loss / combTrain_bottleneck_files\n",
    "        avg_epoch_CombTr_acc += CombTrain_Accuracy / combTrain_bottleneck_files\n",
    "        #except:\n",
    "        #    continue\n",
    "        \n",
    "    print(\"Avg_CombTrain_Loss: {}, Avg_CombTrain_Acc: {}\".format(np.round(float(avg_epoch_CombTr_loss), 2),\n",
    "                                                                 np.round(float(avg_epoch_CombTr_acc), 2)))\n",
    "\n",
    "    CombTrain_loss.append(avg_epoch_CombTr_loss)\n",
    "    CombTrain_acc.append(avg_epoch_CombTr_acc)\n",
    "    \n",
    "    model.save(os.path.join(SAVER, \"model.h5\"))  #saving the model on each epoc\n",
    "    model.save_weights(os.path.join(SAVER, \"model_weights.h5\")) #saving the weights of model on each epoch\n",
    "    print(\"Model and weights saved at epoch {}\".format(epoch + 1))\n",
    "          \n",
    "log_train = pd.DataFrame(columns = [\"Epoch\", \"Comb_Train_Loss\", \"Comb_Train_Accuracy\"])\n",
    "log_train[\"Epoch\"] = epoch_number\n",
    "log_train[\"Comb_Train_Loss\"] = CombTrain_loss\n",
    "log_train[\"Comb_Train_Accuracy\"] = CombTrain_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_train.to_csv(\"./outputs_facedb/Log1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(epoch, train_loss, title):\n",
    "    fig, axes = plt.subplots(1,1, figsize = (12, 8))\n",
    "    axes.plot(epoch, train_loss, color = 'red', label = \"Test\")\n",
    "    axes.set_title(title, fontsize = 25)\n",
    "    axes.set_xlabel(\"Epochs\", fontsize = 20)\n",
    "    axes.set_ylabel(\"Loss\", fontsize = 20)\n",
    "    axes.grid()\n",
    "    axes.legend(fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotting(list(log_train[\"Epoch\"]), list(log_train[\"Comb_Train_Loss\"]), \"EPOCH VS LOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotting(list(log_train[\"Epoch\"]), list(log_train[\"Comb_Train_Accuracy\"]), \"EPOCH VS ACCURACY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 512)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Human Test Data = 85.34%\n"
     ]
    }
   ],
   "source": [
    "#model = load_model(\"./outputs_facedb/Model_Save/model.h5\")\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "batch_size = 10\n",
    "total_files = int(len(test_df) / batch_size) - 1 #here, I have added 2 because there are 30 files in Test_Humans\n",
    "for i in range(1, total_files, 1):\n",
    "    img_load = np.load(\"./outputs_facedb/Bottleneck_Features_test/bottleneck_{}.npy\".format(i))\n",
    "    img_label = np.load(\"./outputs_facedb/Bottleneck_Labels_test/bottleneck_labels_{}.npy\".format(i))\n",
    "    img_bundle = img_load.reshape(img_load.shape[0], img_load.shape[1]*img_load.shape[2]*img_load.shape[3])\n",
    "    for j in range(img_bundle.shape[0]):\n",
    "        img = img_bundle[j]\n",
    "        img = img.reshape(1, img_bundle.shape[1])\n",
    "        pred = model.predict(img)\n",
    "        predicted_labels.append(pred[0].argmax())\n",
    "        true_labels.append(img_label[j].argmax())\n",
    "acc = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy on Human Test Data = {}%\".format(np.round(float(acc*100), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusionMatrix(Y_TestLabels, PredictedLabels):\n",
    "    confusionMatx = confusion_matrix(Y_TestLabels, PredictedLabels)\n",
    "    \n",
    "    precision = confusionMatx/confusionMatx.sum(axis = 0)\n",
    "    \n",
    "    recall = (confusionMatx.T/confusionMatx.sum(axis = 1)).T\n",
    "    \n",
    "    sns.set(font_scale=1.5)\n",
    "    \n",
    "    # confusionMatx = [[1, 2],\n",
    "    #                  [3, 4]]\n",
    "    # confusionMatx.T = [[1, 3],\n",
    "    #                   [2, 4]]\n",
    "    # confusionMatx.sum(axis = 1)  axis=0 corresponds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # confusionMatx.sum(axix =1) = [[3, 7]]\n",
    "    # (confusionMatx.T)/(confusionMatx.sum(axis=1)) = [[1/3, 3/7]\n",
    "    #                                                  [2/3, 4/7]]\n",
    "\n",
    "    # (confusionMatx.T)/(confusionMatx.sum(axis=1)).T = [[1/3, 2/3]\n",
    "    #                                                    [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    labels = [\"NEUTRAL\", \"HAPPY\", \"SAD\", \"SURPRISE\", \"ANGRY\", \"DISGUST\", \"FEAR\"]\n",
    "    \n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.heatmap(confusionMatx, cmap = \"Blues\", annot = True, fmt = \".1f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Confusion Matrix\", fontsize = 30)\n",
    "    plt.xlabel('Predicted Class', fontsize = 20)\n",
    "    plt.ylabel('Original Class', fontsize = 20)\n",
    "    plt.tick_params(labelsize = 15)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*125)\n",
    "    \n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.heatmap(precision, cmap = \"Blues\", annot = True, fmt = \".2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Precision Matrix\", fontsize = 30)\n",
    "    plt.xlabel('Predicted Class', fontsize = 20)\n",
    "    plt.ylabel('Original Class', fontsize = 20)\n",
    "    plt.tick_params(labelsize = 15)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*125)\n",
    "    \n",
    "    plt.figure(figsize=(16,7))\n",
    "    sns.heatmap(recall, cmap = \"Blues\", annot = True, fmt = \".2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Recall Matrix\", fontsize = 30)\n",
    "    plt.xlabel('Predicted Class', fontsize = 20)\n",
    "    plt.ylabel('Original Class', fontsize = 20)\n",
    "    plt.tick_params(labelsize = 15)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_confusionMatrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-neutral, 1-happy, 2-sad, 3-surprise, 4-angry, 5-disguest, 6-fear "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real world testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_DICT = {0:\"neutral\", 1:\"happy\", 2:\"sad\", 3:\"surprise\", 4:\"angry\"}#, 5:\"disguest\", 6:\"fear\"}\n",
    "model_VGG = VGG16(weights='imagenet', include_top=False)\n",
    "model_top = load_model(\"./outputs_facedb/Model_Save/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(path):\n",
    "    #converting image to gray scale and save it\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(path, gray)\n",
    "    \n",
    "    #detect face in image, crop it then resize it then save it\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_clip = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(path, cv2.resize(face_clip, (350, 350)))\n",
    "    if(len(faces)==0):\n",
    "        cv2.imwrite(path, cv2.resize(img, (350, 350)))  #resizing image then saving it\n",
    "    \n",
    "    #read the processed image then make prediction and display the result\n",
    "    read_image = cv2.imread(path)\n",
    "    read_image = read_image.reshape(1, read_image.shape[0], read_image.shape[1], read_image.shape[2])\n",
    "    read_image_final = read_image/255.0  #normalizing the image\n",
    "    VGG_Pred = model_VGG.predict(read_image_final)  #creating bottleneck features of image using VGG-16.\n",
    "    print(VGG_Pred.shape[1],VGG_Pred.shape[2],VGG_Pred.shape[3])\n",
    "    VGG_Pred = VGG_Pred.reshape(1, VGG_Pred.shape[1]*VGG_Pred.shape[2]*VGG_Pred.shape[3])\n",
    "    \n",
    "    #VGG_Pred = VGG_Pred.reshape(1, 1*1*VGG_Pred.shape[3])\n",
    "    \n",
    "    top_pred = model_top.predict(VGG_Pred)  #making prediction from our own model.\n",
    "    emotion_label = top_pred[0].argmax() \n",
    "    print(\"Predicted Expression Probabilities\")\n",
    "#     print(\"neutral: {}\\nhappy: {}\\nsad: {}\\nsurprise: {}\\nangry: {}\\ndisguest: {}\\nfear: {}\\n\\n\".format(top_pred[0][0], top_pred[0][1], top_pred[0][2], top_pred[0][3], top_pred[0][4], top_pred[0][5], top_pred[0][6]))\n",
    "#     print(\"Dominant Probability = \"+str(EMOTION_DICT[emotion_label])+\": \"+str(max(top_pred[0])))\n",
    "\n",
    "    print(\"neutral: {}\\nhappy: {}\\nsad: {}\\nsurprise: {}\\nangry: {}\\n\\n\".format(top_pred[0][0], top_pred[0][1], top_pred[0][2], top_pred[0][3], top_pred[0][4]))\n",
    "    print(\"Dominant Probability = \"+str(EMOTION_DICT[emotion_label])+\": \"+str(max(top_pred[0])))\n",
    "    \n",
    "    return emotion_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction('./test_images/6dfb5660c821203ebfc479951993a0a3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realtime image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test_images_all/anger/human_angry_faces/huma...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test_images_all/anger/human_angry_faces/huma...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test_images_all/anger/human_angry_faces/huma...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test_images_all/anger/human_angry_faces/huma...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test_images_all/anger/human_angry_faces/huma...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location  labels\n",
       "0  ./test_images_all/anger/human_angry_faces/huma...       4\n",
       "1  ./test_images_all/anger/human_angry_faces/huma...       4\n",
       "2  ./test_images_all/anger/human_angry_faces/huma...       4\n",
       "3  ./test_images_all/anger/human_angry_faces/huma...       4\n",
       "4  ./test_images_all/anger/human_angry_faces/huma...       4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df = pd.DataFrame()\n",
    "\n",
    "for i in range(1,39):\n",
    "    human_reaction = glob.glob(\"./test_images_all/*/*/*\")\n",
    "    tmp = pd.DataFrame({'location':human_reaction,\n",
    "                        'labels':[emotion_label2(human_reaction[i].split('/')[-3]) for i in range(len(human_reaction))]},\n",
    "                       index =range(len(human_reaction)) )\n",
    "    new_test_df = new_test_df.append(tmp)\n",
    "    \n",
    "new_test_df['labels'] = new_test_df.labels.astype('int')\n",
    "new_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.09659180790185928\n",
      "happy: 0.7283567190170288\n",
      "sad: 0.03731928765773773\n",
      "surprise: 0.002412597881630063\n",
      "angry: 0.13531963527202606\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.7283567\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06196824461221695\n",
      "happy: 0.06746752560138702\n",
      "sad: 0.19266840815544128\n",
      "surprise: 0.0017942998092621565\n",
      "angry: 0.6761015057563782\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.6761015\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00015845318557694554\n",
      "happy: 2.199030717520145e-07\n",
      "sad: 0.0001891995925689116\n",
      "surprise: 9.50634628793523e-08\n",
      "angry: 0.9996520280838013\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.999652\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.8959125280380249\n",
      "happy: 0.0033025292214006186\n",
      "sad: 0.06822580844163895\n",
      "surprise: 0.016324026510119438\n",
      "angry: 0.01623520627617836\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8959125\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.07089453190565109\n",
      "happy: 1.0981469131365884e-05\n",
      "sad: 0.02920500375330448\n",
      "surprise: 4.7223929868778214e-05\n",
      "angry: 0.8998422026634216\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8998422\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.3271302878856659\n",
      "happy: 0.1875200718641281\n",
      "sad: 0.053635865449905396\n",
      "surprise: 0.00274332775734365\n",
      "angry: 0.4289705455303192\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.42897055\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.001166516332887113\n",
      "happy: 0.00010325042967451736\n",
      "sad: 0.001690845238044858\n",
      "surprise: 5.564428647630848e-06\n",
      "angry: 0.9970338344573975\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99703383\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.2433747947216034\n",
      "happy: 0.33588504791259766\n",
      "sad: 0.01011471264064312\n",
      "surprise: 0.053012315183877945\n",
      "angry: 0.35761314630508423\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.35761315\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.5737849707875284e-06\n",
      "happy: 0.9999934434890747\n",
      "sad: 1.09431361750012e-07\n",
      "surprise: 1.9441888099436255e-09\n",
      "angry: 4.912446001981152e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999344\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.21374444663524628\n",
      "happy: 0.06775075942277908\n",
      "sad: 0.18515482544898987\n",
      "surprise: 0.025173133239150047\n",
      "angry: 0.5081768035888672\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5081768\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 1.6880725706158728e-09\n",
      "happy: 1.0\n",
      "sad: 1.1825936063747378e-10\n",
      "surprise: 8.31310497870219e-13\n",
      "angry: 1.0796995297823742e-08\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.06819973140954971\n",
      "happy: 0.12320594489574432\n",
      "sad: 0.06420604139566422\n",
      "surprise: 0.19801542162895203\n",
      "angry: 0.5463727712631226\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.5463728\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.085531545821141e-07\n",
      "happy: 0.999991774559021\n",
      "sad: 4.6201407144508266e-08\n",
      "surprise: 1.5754940407841644e-10\n",
      "angry: 7.836312761355657e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999918\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0002187944483011961\n",
      "happy: 0.9989608526229858\n",
      "sad: 8.980504162536818e-07\n",
      "surprise: 0.0008169021457433701\n",
      "angry: 2.473798076607636e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99896085\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0003769948671106249\n",
      "happy: 3.3548578358022496e-05\n",
      "sad: 0.0003974476712755859\n",
      "surprise: 5.387010446611384e-07\n",
      "angry: 0.9991914629936218\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.99919146\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.353129149123561e-06\n",
      "happy: 0.999987006187439\n",
      "sad: 6.366142315528123e-07\n",
      "surprise: 1.0560499674738821e-07\n",
      "angry: 4.865176379098557e-06\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.999987\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.386287764646113e-05\n",
      "happy: 0.014751824550330639\n",
      "sad: 2.4278410393208105e-08\n",
      "surprise: 0.9852043390274048\n",
      "angry: 5.6288371297341655e-08\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.98520434\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.0908614993095398\n",
      "happy: 0.0037573562003672123\n",
      "sad: 0.07713588327169418\n",
      "surprise: 0.0031449112575501204\n",
      "angry: 0.8251003623008728\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.82510036\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.01946137845516205\n",
      "happy: 0.8204516768455505\n",
      "sad: 0.01004188135266304\n",
      "surprise: 0.00017703713092487305\n",
      "angry: 0.14986805617809296\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.8204517\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9318063259124756\n",
      "happy: 0.0401509627699852\n",
      "sad: 0.004218545742332935\n",
      "surprise: 0.0002924890723079443\n",
      "angry: 0.023531606420874596\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9318063\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9999234676361084\n",
      "happy: 1.8964762205087027e-07\n",
      "sad: 1.1941618140554056e-05\n",
      "surprise: 6.405724707292393e-05\n",
      "angry: 3.3978167834902706e-07\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99992347\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9832361340522766\n",
      "happy: 0.00010163820843445137\n",
      "sad: 0.005867515690624714\n",
      "surprise: 0.004388773813843727\n",
      "angry: 0.006406037136912346\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.98323613\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.893193781375885\n",
      "happy: 2.025698086072225e-05\n",
      "sad: 0.00024542302708141506\n",
      "surprise: 0.10652327537536621\n",
      "angry: 1.7289508832618594e-05\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.8931938\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9141446352005005\n",
      "happy: 0.0061026401817798615\n",
      "sad: 0.04836209863424301\n",
      "surprise: 0.018764397129416466\n",
      "angry: 0.012626111507415771\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.91414464\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.022339824587106705\n",
      "happy: 0.0004908462287858129\n",
      "sad: 0.10852961987257004\n",
      "surprise: 0.0009120870381593704\n",
      "angry: 0.8677276968955994\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.8677277\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.9946348667144775\n",
      "happy: 0.00021213207219261676\n",
      "sad: 0.00229352293536067\n",
      "surprise: 0.002201474504545331\n",
      "angry: 0.0006580397603102028\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.99463487\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.12785521149635315\n",
      "happy: 0.01632464863359928\n",
      "sad: 0.34138360619544983\n",
      "surprise: 0.01040178444236517\n",
      "angry: 0.5040347576141357\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.50403476\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4844880998134613\n",
      "happy: 0.017210209742188454\n",
      "sad: 0.00436645420268178\n",
      "surprise: 0.49262535572052\n",
      "angry: 0.0013097577029839158\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.49262536\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.00220974488183856\n",
      "happy: 0.09468233585357666\n",
      "sad: 0.0017811350990086794\n",
      "surprise: 1.4199767974787392e-06\n",
      "angry: 0.9013253450393677\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.90132535\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5451885461807251\n",
      "happy: 0.0034346820320934057\n",
      "sad: 0.4319113492965698\n",
      "surprise: 0.0109958341345191\n",
      "angry: 0.00846958626061678\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.54518855\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.515373945236206\n",
      "happy: 0.01983563043177128\n",
      "sad: 0.12577399611473083\n",
      "surprise: 0.039354532957077026\n",
      "angry: 0.2996618449687958\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.51537395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.000922679144423455\n",
      "happy: 2.7250616767560132e-05\n",
      "sad: 0.00027568251243792474\n",
      "surprise: 3.0579724352719495e-07\n",
      "angry: 0.9987741112709045\n",
      "\n",
      "\n",
      "Dominant Probability = angry: 0.9987741\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 6.217220516191446e-09\n",
      "happy: 0.9999997615814209\n",
      "sad: 4.1386061244708117e-10\n",
      "surprise: 1.1005261372348807e-12\n",
      "angry: 1.987266387004638e-07\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.99999976\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 4.630508101399755e-06\n",
      "happy: 1.7423368262825534e-05\n",
      "sad: 5.067023067795162e-08\n",
      "surprise: 0.9999758005142212\n",
      "angry: 2.141726554327761e-06\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.9999758\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.5416132807731628\n",
      "happy: 0.30376699566841125\n",
      "sad: 0.041967589408159256\n",
      "surprise: 0.06168954819440842\n",
      "angry: 0.05096258595585823\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.5416133\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.986497700214386\n",
      "happy: 0.000278572115348652\n",
      "sad: 0.00632221857085824\n",
      "surprise: 0.004069949500262737\n",
      "angry: 0.002831413410604\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.9864977\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 7.829776222934015e-06\n",
      "happy: 4.944063675793586e-06\n",
      "sad: 9.749380296852905e-06\n",
      "surprise: 0.9999774694442749\n",
      "angry: 1.1984075953819229e-09\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.99997747\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 2.3396913746698278e-12\n",
      "happy: 4.32492486268643e-09\n",
      "sad: 1.977910870298253e-15\n",
      "surprise: 1.0\n",
      "angry: 6.921287544828236e-13\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 1.0\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.042477626353502274\n",
      "happy: 0.017361469566822052\n",
      "sad: 0.002897537313401699\n",
      "surprise: 0.9275524616241455\n",
      "angry: 0.009710913524031639\n",
      "\n",
      "\n",
      "Dominant Probability = surprise: 0.92755246\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 0.4780912399291992\n",
      "happy: 0.20865975320339203\n",
      "sad: 0.06036830693483353\n",
      "surprise: 0.008488115854561329\n",
      "angry: 0.24439258873462677\n",
      "\n",
      "\n",
      "Dominant Probability = neutral: 0.47809124\n",
      "10 10 512\n",
      "Predicted Expression Probabilities\n",
      "neutral: 3.999042746727355e-06\n",
      "happy: 0.9999821186065674\n",
      "sad: 5.309405537445855e-07\n",
      "surprise: 1.1099720254037493e-08\n",
      "angry: 1.3372887224250007e-05\n",
      "\n",
      "\n",
      "Dominant Probability = happy: 0.9999821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     798\n",
       "False    760\n",
       "Name: evaluation, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = []\n",
    "for i in range(len(new_test_df)):\n",
    "    path = new_test_df.location.iloc[i]\n",
    "    pred_labels.append(make_prediction(path)) \n",
    "    \n",
    "new_test_df['pred_labels'] = pred_labels\n",
    "\n",
    "error = new_test_df.labels==new_test_df.pred_labels\n",
    "new_test_df['evaluation'] = error\n",
    "new_test_df.evaluation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Accuracy =  0.5121951219512195\n"
     ]
    }
   ],
   "source": [
    "a = new_test_df.evaluation.value_counts()\n",
    "print('-I- Accuracy = ',a[True]/(a[True]+a[False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fer_env]",
   "language": "python",
   "name": "conda-env-fer_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
